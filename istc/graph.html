<html>
<head>
<link href="ihpsc.css" rel="stylesheet" type="text/css">
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/css/bootstrap.min.css" integrity="sha384-Gn5384xqQ1aoWXA+058RXPxPg6fy4IWvTNh0E263XmFcJlSAwiGgFAW/dAiS6JXm" crossorigin="anonymous">

  <script src="https://code.jquery.com/jquery-3.2.1.slim.min.js" integrity="sha384-KJ3o2DKtIkvYIK3UENzmM7KCkRr/rE9/Qpg6aAZGJwFDMVNA/GpGFF93hXpG5KkN" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.12.9/umd/popper.min.js" integrity="sha384-ApNbgh9B+Y1QKtv3Rn7W3mgPxhU9K/ScQsAP7hUibX39j7fakFPskvXusvfa0b4Q" crossorigin="anonymous"></script>
  <script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/js/bootstrap.min.js" integrity="sha384-JZR6Spejh4U02d8jOt6vLEHfe/JQGiRRSQQxSfFWpi1MquVdAyjUar5+76PVCmYl" crossorigin="anonymous"></script>

  <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

  <script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {inlineMath: [['$','$']]}
  });
  MathJax.Hub.Config({
    TeX: { equationNumbers: { autoNumber: "AMS" } }
  });
  </script>

  <link rel="stylesheet"
      href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.13.1/styles/default.min.css">
  <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.13.1/highlight.min.js"></script>
  <script>hljs.initHighlightingOnLoad();</script>
</head>

<script type="application/javascript">
  // First we declare some metadata, primarily to describe
  // the container environment.
  var ccrsApiNamespace = "org.xsede.jobrunner.model.ModelApi";
  var mpiExampleMetaJson = {
    // CHANGE: for now, leave the appended string as .SysJobMetaData;
    //         other options will be supported in the future
    "$type": ccrsApiNamespace + ".SysJobMetaData",
    // CHANGE: shell to use implicitly when running commands in the container
    "shell": ["bash"],
    // CHANGE: should currently be one of: .NixOS, .Singularity
    "containerType": {
      "$type":  ccrsApiNamespace + ".NixOS"
    },
    // CHANGE: Specify for NixOS for all jobs, or for Singularity when resuming existing jobs
    "containerId": ["vicOpenMPI"],
    // CHANGE: Specify the singularity image name
    "image": [],
    // Directories on the host to mount in the container, if any:
    "binds": [],
    // Only for singularity:
    "overlay": [],
    // CHANGE: should be filled in dynamically to contain the (student) user,
    //         but this is a demo, so we use a static user name:
    "user": "test0",
    "address": [],
    "hostname": [],
    "url": window.location.href
  };
  var mpiExampleMeta = CCRS.sysJobMetaData(mpiExampleMetaJson);
</script>

<div class="container">
  <div class="row">
    <div class="col-12">
      <div class="pagehead">
        <h1>Graph theory</h1>
        <h5>Experimental html version of downloadable textbook, see https://www.tacc.utexas.edu/~eijkhout/istc/istc.html</h5>
      </div>
    </div>
  </div>
  <div>

\[
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%
%%%% This text file is part of the source of 
%%%% `Introduction to High-Performance Scientific Computing'
%%%% by Victor Eijkhout, copyright 2012-2020
%%%%
%%%% mathjax.tex : macros to facility mathjax use in html version
%%%%
%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\newcommand\inv{^{-1}}\newcommand\invt{^{-t}}
\newcommand\bbP{\mathbb{P}}
\newcommand\bbR{\mathbb{R}}
\newcommand\defined{
  \mathrel{\lower 5pt \hbox{${\equiv\atop\mathrm{\scriptstyle D}}$}}}
\newcommand\macro[1]{$\langle$#1$\rangle$}
\newcommand\dtdxx{\frac{\alpha\Delta t}{\Delta x^2}}
\]


19.1 : <a href="graph.html#Definitions">Definitions</a><br>
19.2 : <a href="graph.html#Commontypesofgraphs">Common types of graphs</a><br>
19.2.1 : <a href="graph.html#DirectedAcyclicGraphs">Directed Acyclic Graphs</a><br>
19.2.2 : <a href="graph.html#Trees">Trees</a><br>
19.2.3 : <a href="graph.html#Separablegraphs">Separable graphs</a><br>
19.2.4 : <a href="graph.html#Bipartitegraphs">Bipartite graphs</a><br>
19.3 : <a href="graph.html#Graphcolouringandindependentsets">Graph colouring and independent sets</a><br>
19.4 : <a href="graph.html#Graphalgorithms">Graph algorithms</a><br>
19.5 : <a href="graph.html#Graphsandmatrices">Graphs and matrices</a><br>
19.5.1 : <a href="graph.html#Permutation">Permutation</a><br>
19.5.2 : <a href="graph.html#Irreducibility">Irreducibility</a><br>
19.5.3 : <a href="graph.html#Graphclosure">Graph closure</a><br>
19.6 : <a href="graph.html#Spectralgraphtheory">Spectral graph theory</a><br>
19.6.1 : <a href="graph.html#ThegraphLaplacian">The graph Laplacian</a><br>
19.6.2 : <a href="graph.html#DomaindecompositionthroughLaplacianmatrices">Domain decomposition through Laplacian matrices</a><br>
19.6.3 : <a href="graph.html#Cheeger'sinequality">Cheeger's inequality</a><br>
<a href="index.html">Back to Table of Contents</a>
<h1>19 Graph theory</h1>
<!-- TranslatingLineGenerator file ['file'] -->
<p name="switchToTextMode">

Graph theory is the branch of mathematics that studies pairwise
relations between objects. Graphs both appear as tools for analyzing
issues in 
<span title="acronym" ><i>HPC</i></span>
, and as objects of study themselves. This
appendix introduces the basic concepts and some relevant theory.
</p>

<h2><a id="Definitions">19.1</a> Definitions</h2>
<p name=crumbs>
crumb trail:  > <a href="graph.html">graph</a> > <a href="graph.html#Definitions">Definitions</a>
</p>
<p name="switchToTextMode">

A graph consists of a set of objects, and set of relations between them.
The objects, called the 
<i>nodes</i>
or 
<i>vertices</i>
 of the graph, usually form a finite set, so we
usually identify them with consecutive integers $1\ldots n$ or $0\ldots
n-1$. The relation that holds between nodes is described by the
<i>edges</i>
 of the graph: if $i$ and~$j$ are related, we say
that $( i,j)$ is an edge of the graph. This relation does not need to
be symmetric, take for instance the `less than' relation.
</p>

<p name="switchToTextMode">
Formally, then, a graph is a tuple $G=\langle V,E\rangle$ where
$V=\{1,\ldots n\}$ for some~$n$, and $E\subset\{(i,j)\colon 1\leq
i,j\leq n,\,i\not=j\}$.
</p>

<!-- environment: figure start embedded generator -->
<!-- TranslatingLineGenerator figure ['figure'] -->
<img src="graphics/graph1.jpg" width=800></img>
<p name="switchToTextMode">
    $
\begin{cases}
      V=\{1,2,3,4,5,6\}\\
      E=\{ (1,2),(2,6),(4,3),(4,4),(4,5)\}
\end{cases}
    $}
<p name="caption">
FIGURE 19.1: A simple graph
</p>

</float>
</figure>
<!-- environment: figure end embedded generator -->
<p name="switchToTextMode">

A graph is called an 
<i>undirected graph</i>
 if $(i,j)\in
E\Leftrightarrow (j,i)\in E$. The alternative is a
<i>directed graph</i>
, where we indicate an edge $(i,j)$ with
an arrow from $i$ to~$j$.
</p>

<p name="switchToTextMode">
Two concepts that often appear in graph theory are the
degree and the diameter of a graph.
</p>

<!-- environment: definition start embedded generator -->
<!-- TranslatingLineGenerator definition ['definition'] -->
The
<i>degree</i>
 denotes the maximum number of nodes that are
connected to any node:
\[
  d(G)\equiv \max_i
  \left|\{j\colon j\not=i\wedge (i,j)\in E\}\right|.
\]
</p name="definition">
</definition>
<!-- environment: definition end embedded generator -->
<p name="switchToTextMode">

<!-- environment: definition start embedded generator -->
</p>
<!-- TranslatingLineGenerator definition ['definition'] -->
The 
<i>diameter</i>
 of a graph is the length of the longest
shortest path
in the graph, where a 
<i>path</i>

<!-- index -->
is defined as a set of vertices
$v_1,\ldots, v_{k+1}$ such that $v_i\not=v_j$ for all $i\not=j$ and
\[
 \forall_{1\leq i\leq k}\colon (v_i,v_{i+1})\in E. 
\]
The length of this path is~$k$.
</p name="definition">
</definition>
<!-- environment: definition end embedded generator -->
<p name="switchToTextMode">
The concept of diameter is illustrated
in figure~
19.2
.
</p>

<!-- environment: figure start embedded generator -->
<!-- TranslatingLineGenerator figure ['figure'] -->
<img src="graphics/graph2a.jpg" width=800></img>
<p name="switchToTextMode">
    A graph}
<img src="graphics/graph2b.jpg" width=800></img>
    Two paths from 1 to 6; $\langle 1,4,6\rangle$ is the shorter}
<img src="graphics/graph2c.jpg" width=800></img>
    The longest shortest path of this graph}
<p name="caption">
FIGURE 19.2: Shortest paths
</p>

</float>
</figure>
<!-- environment: figure end embedded generator -->
<p name="switchToTextMode">

A~path where all nodes are disjoint
except for $v_1=v_{k+1}$ is called a 
<i>cycle</i>

<!-- index -->
.
</p>

<p name="switchToTextMode">
Sometimes we are only interested in the mere existence of an edge
$(i,j)$, at other times we attach a value or `weight' $w_{ij}$ to that
edge.
</p>

<!-- index -->
<p name="switchToTextMode">
.
Such a graph can be represented as a tuple
$G=\langle V,E,W\rangle$ where $E$ and $W$ have the same cardinality.
</p>

<!-- index -->
<p name="switchToTextMode">
has all weights the same value, in which case we omit mention of weights.
</p>

<h2><a id="Commontypesofgraphs">19.2</a> Common types of graphs</h2>
<p name=crumbs>
crumb trail:  > <a href="graph.html">graph</a> > <a href="graph.html#Commontypesofgraphs">Common types of graphs</a>
</p>
<p name="switchToTextMode">

<h3><a id="DirectedAcyclicGraphs">19.2.1</a> Directed Acyclic Graphs</h3>
<p name=crumbs>
crumb trail:  > <a href="graph.html">graph</a> > <a href="graph.html#Commontypesofgraphs">Common types of graphs</a> > <a href="graph.html#DirectedAcyclicGraphs">Directed Acyclic Graphs</a>
</p>
</p>

<p name="switchToTextMode">
A graph that does not have cycles is called an
<i>acyclic graph</i>
<!-- index -->
A special case of this type of graph is the 
<i>DAG</i>
.
This type of graph can for instance be
used to model dependencies between tasks:
if there is an edge from $i$ to~$j$,
it means that task $i$ has to be done before task~$j$.
</p>

<h3><a id="Trees">19.2.2</a> Trees</h3>
<p name=crumbs>
crumb trail:  > <a href="graph.html">graph</a> > <a href="graph.html#Commontypesofgraphs">Common types of graphs</a> > <a href="graph.html#Trees">Trees</a>
</p>
<p name="switchToTextMode">

One special case of 
<span title="acronym" ><i>DAGs</i></span>
 is the
<i>tree graph</i>
<!-- index -->
,
or for short a
<i>tree</i>
<!-- index -->
:
here any node can have multiple outgoing edges,
but only one incoming edge.
Nodes with no outgoing edges are 
<i>leaf nodes</i>
;
a~node with no incoming edges is called a root,
and all other nodes are called 
<i>interior nodes</i>
.
</p>

<!-- environment: exercise start embedded generator -->
<!-- TranslatingLineGenerator exercise ['exercise'] -->
 Can a tree have more than one root?
</p name="exercise">
</exercise>
<!-- environment: exercise end embedded generator -->
<!-- environment: answer start embedded generator -->

</answer>
<!-- environment: answer end embedded generator -->
<p name="switchToTextMode">

<h3><a id="Separablegraphs">19.2.3</a> Separable graphs</h3>
<p name=crumbs>
crumb trail:  > <a href="graph.html">graph</a> > <a href="graph.html#Commontypesofgraphs">Common types of graphs</a> > <a href="graph.html#Separablegraphs">Separable graphs</a>
</p>
</p>

<p name="switchToTextMode">
A
<i>separable graph</i>
<!-- index -->
is a graph consisting of two sets of nodes,
where all connections are inside either of the sets.
Such graph can obviously be processed in parallel,
so several parallelization algorithms are concerned
with transforming a graph to a separable one.
If a graph can be written as $V=V_1+V_2+S$,
where nodes in&nbsp;$V_1,V_2$ are only connected to&nbsp;$S$,
but not to the other set,
we call $S$&nbsp;a 
<i>separator</i>
.
</p>

<h3><a id="Bipartitegraphs">19.2.4</a> Bipartite graphs</h3>
<p name=crumbs>
crumb trail:  > <a href="graph.html">graph</a> > <a href="graph.html#Commontypesofgraphs">Common types of graphs</a> > <a href="graph.html#Bipartitegraphs">Bipartite graphs</a>
</p>

<p name="switchToTextMode">

If a graph can be partitioned into two sets of nodes,
where edges only run from the one set to the other,
but not inside a set,
we call this a 
<i>bipartite graph</i>
<!-- index -->
.
</p>

<h2><a id="Graphcolouringandindependentsets">19.3</a> Graph colouring and independent sets</h2>
<p name=crumbs>
crumb trail:  > <a href="graph.html">graph</a> > <a href="graph.html#Graphcolouringandindependentsets">Graph colouring and independent sets</a>
</p>

<!-- index -->
<p name="switchToTextMode">

We can assign labels to the nodes of a graph, which is equivalent to
partitioning the set of nodes into disjoint subsets. One type of
labeling that is of interest is 
<i>graph colouring</i>
: here the
labels (or `colours') are chosen so that, if nodes $i$ and&nbsp;$j$ have
the same colour, there is no edge connecting them: $(i,j)\not\in
E$.
</p>

<p name="switchToTextMode">
There is a trivial colouring of a graph, where each node has its own
colour. More interestingly,
the minimum number of colours with which you can colour a graph is
called the 
<i>colour number</i>
 of the graph.
</p>

<!-- environment: exercise start embedded generator -->
<!-- TranslatingLineGenerator exercise ['exercise'] -->
  Show that, if a graph has degree&nbsp;$d$, the colour number is at
  most&nbsp;$d+1$.
</p name="exercise">
</exercise>
<!-- environment: exercise end embedded generator -->
<p name="switchToTextMode">

A&nbsp;famous graph colouring problem is the `four colour theorem': if
a graph depicts countries on a two-dimensional map (a so-called
`planar' graph), then the colour number is at most four.
In general, finding the colour number is hard (in fact, NP-hard).
</p>

<p name="switchToTextMode">
The colour sets of a graph colouring are also called
<i>independent sets</i>
, since within each colour no node is
connected to a node of the same colour.
</p>

<p name="switchToTextMode">
There is a trivial way of finding independent sets: declare each node
to have its own unique colour. On the other hand, finding the `best'
division in independent sets, for instance through finding the colour
number of the graph, is difficult. However, often it is enough to find
a reasonable partitioning of the nodes into independent sets, for
instance in constructing paralell ILU preconditioners;
section&nbsp;
6.7.4
. The following algorithm does
that&nbsp;
<a href="https://pages.tacc.utexas.edu/~eijkhout/istc/html/bibliography.html#jopl94,Luby:parallel">[jopl94,Luby:parallel]</a>
:
<!-- environment: itemize start embedded generator -->
</p>
<!-- TranslatingLineGenerator itemize ['itemize'] -->
<li>
Give each node a unique random number.
<li>
Now find the set of nodes that have a higher number than all of
  their neighbours; call this the first independent set.
<li>
Remove this set from the graph, and find again the nodes with a
  higher number than all their neighbours; this will be the second
  set.
<li>
Repeat this procedure until all nodes are in an independent set.
</ul>
</itemize>
<!-- environment: itemize end embedded generator -->
<!-- environment: exercise start embedded generator -->
<!-- TranslatingLineGenerator exercise ['exercise'] -->
  Convince yourself that the sets found this way are indeed independent.
</p name="exercise">
</exercise>
<!-- environment: exercise end embedded generator -->
<!-- environment: answer start embedded generator -->

</answer>
<!-- environment: answer end embedded generator -->
<p name="switchToTextMode">

<!-- index -->
</p>

<h2><a id="Graphalgorithms">19.4</a> Graph algorithms</h2>
<p name=crumbs>
crumb trail:  > <a href="graph.html">graph</a> > <a href="graph.html#Graphalgorithms">Graph algorithms</a>
</p>
<p name="switchToTextMode">

In this section we only briefly touch on graph algorithms; a full
discussion can be found in section&nbsp;
9.2
.
</p>

<!-- environment: itemize start embedded generator -->
<!-- TranslatingLineGenerator itemize ['itemize'] -->
<li>
Distance algorithms. In applications such as traffic routing it
  is of interest to know the shortest distance from a given node to
  all others: the 
<i>single source shortest path</i>
 problem;
  or the shortest distance for any pair: the
<i>all-pairs shortest path</i>
 problem.
<li>
Connectivity algorithms. In social networks it is of interest to
  know if two people are connected at all, if the graph can be split
  up into unconnected subgraphs, or whether some person is the crucial
  bridge between two groups.
</ul>
</itemize>
<!-- environment: itemize end embedded generator -->
<p name="switchToTextMode">

<h2><a id="Graphsandmatrices">19.5</a> Graphs and matrices</h2>
<p name=crumbs>
crumb trail:  > <a href="graph.html">graph</a> > <a href="graph.html#Graphsandmatrices">Graphs and matrices</a>
</p>
<!-- index -->
<!-- index -->
</p>

<p name="switchToTextMode">
A graph can be rendered in a number of ways. You could of course just
list nodes and edges, but little insight can be derived that way.
Simple graphs can be  visualized by drawing vertices and edges, but
for large graphs this becomes unwieldy. Another option is to construct
the 
<i>adjacency matrix</i>
 of the graph.
For a graph $G=\langle V,E\rangle$,
the adjacency matrix $M$ (with a size $n$ equal to the
number of vertices&nbsp;$|V|$) is defined by
\[
  M_{ij}=
\begin{cases}
1&(i,j)\in E\\ 0&\mbox{otherwise}
\end{cases}
\]
Conversely, if you have a matrix, especially a
<i>sparse matrix</i>
, you can construct its
<i>adjacency graph</i>
.
This is illustrated in figure&nbsp;
19.3
 for
<!-- environment: figure start embedded generator -->
</p>
<!-- TranslatingLineGenerator figure ['figure'] -->
<img src="graphics/matrix-graph.jpg" width=800></img>
<p name="switchToTextMode">
  \caption{A dense and a sparse matrix, both with their adjacency
    graph}

</float>
</figure>
<!-- environment: figure end embedded generator -->
<p name="switchToTextMode">
both a dense and a sparse matrix. In this example, the matrices are
structurally symmetric, so we use lines instead of arrows in the
graphs. There is an edge on each vertex corresponding to the diagonal
element; this edge will often be left out of illustrations.
</p>

<p name="switchToTextMode">
For graphs with edge weights, we set the elements of the adjacency
matrix to the weights:
\[
  M_{ij}=
\begin{cases}
w_{ij}&(i,j)\in E\\ 0&\mbox{otherwise}
\end{cases}
\]
</p>

<p name="switchToTextMode">
If a matrix has no zero elements, its adjacency graph has an edge
between each pair of vertices. Such a graph is called a
<i>clique</i>
.
If the graph is undirected, the adjacency matrix is symmetric, and
conversely, if a matrix is 
<i>structurally symmetric</i>
, its
adjacency graph is undirected.
</p>

<h3><a id="Permutation">19.5.1</a> Permutation</h3>
<p name=crumbs>
crumb trail:  > <a href="graph.html">graph</a> > <a href="graph.html#Graphsandmatrices">Graphs and matrices</a> > <a href="graph.html#Permutation">Permutation</a>
</p>
<p name="switchToTextMode">

Graphs are often used to indicate relations between objects in the
real world. One example would be `friend-of' relations in Facebook.
In such cases, the nodes in a graph do not have a natural numbering:
they are identified by a name and any numbering is artificial.
Thus, we could wonder which graph properties remain invariant,
and which ones change, if we apply a different numbering.
</p>

<p name="switchToTextMode">
Renumbering a set of objects can be modeled algebraically by
applying a 
<i>permutation matrix</i>
.
<!-- environment: definition start embedded generator -->
</p>
<!-- TranslatingLineGenerator definition ['definition'] -->
A permutation matrix is a square matrix where each row and column
has exactly one element equal to&nbsp;one; all other elements are zero.
</p name="definition">
</definition>
<!-- environment: definition end embedded generator -->
<p name="switchToTextMode">

<!-- environment: exercise start embedded generator -->
</p>
<!-- TranslatingLineGenerator exercise ['exercise'] -->
Let a set of $N$ objects $x_1,&hellip;,x_N$ be given. What is the
permutation matrix that orders them as $x_1,x_3,&hellip;,x_2,x_4,&hellip;$?
That is, find the matrix $P$ such that
\[
\begin{pmatrix}
x_1\\x_3\\\vdots\\x_2\\x_4\\\vdots
\end{pmatrix}
 = P
\begin{pmatrix}
x_1\\\vdots\\x_N
\end{pmatrix}
\]
</p name="exercise">
</exercise>
<!-- environment: exercise end embedded generator -->
<p name="switchToTextMode">

<!-- environment: exercise start embedded generator -->
</p>
<!-- TranslatingLineGenerator exercise ['exercise'] -->
Show that the eigenvalues of a matrix are invariant under permutation.
</p name="exercise">
</exercise>
<!-- environment: exercise end embedded generator -->
<p name="switchToTextMode">

<h3><a id="Irreducibility">19.5.2</a> Irreducibility</h3>
<p name=crumbs>
crumb trail:  > <a href="graph.html">graph</a> > <a href="graph.html#Graphsandmatrices">Graphs and matrices</a> > <a href="graph.html#Irreducibility">Irreducibility</a>
</p>
</p>

<p name="switchToTextMode">
As an example of graph concepts that has an easy interpretation in the
adjacency matrix, consider reducibility.
</p>

<!-- environment: definition start embedded generator -->
<!-- TranslatingLineGenerator definition ['definition'] -->
A graph is called 
<i>irreducible</i>
 if for every pair $i,j$ of
nodes there is a path from $i$ to&nbsp;$j$ and from $j$ to&nbsp;$i$. A&nbsp;graph is
reducible if it is not irreducible.
</p name="definition">
</definition>
<!-- environment: definition end embedded generator -->
<p name="switchToTextMode">

<!-- environment: exercise start embedded generator -->
</p>
<!-- TranslatingLineGenerator exercise ['exercise'] -->
  Let $A$ be a matrix
<!-- environment: equation start embedded generator -->
</p>
    A=
\begin{pmatrix}
      B&C\\ \emptyset&D
\end{pmatrix}
\label{eq:reduct-u}
\end{equation}
</equation>
<!-- environment: equation end embedded generator -->
<p name="switchToTextMode">
  where $B$ and $D$ are square matrices. Prove the reducibility of the
  graph of which this is the adjacency matrix.
</p name="exercise">
</exercise>
<!-- environment: exercise end embedded generator -->
<p name="switchToTextMode">

The matrix in equation&nbsp;
eq:reduct-u
is block upper triangular matrix.
This means that solving a system $Ax=b$ is solved
in two steps, each of size&nbsp;$N/2$, if $N$&nbsp;is the size of&nbsp;$A$.
</p>

<!-- environment: exercise start embedded generator -->
<!-- TranslatingLineGenerator exercise ['exercise'] -->
  Show that this makes the arithmetic complexity
  of solving $Ax=b$ lower than for a general $N\times N$ matrix.
</p name="exercise">
</exercise>
<!-- environment: exercise end embedded generator -->
<!-- environment: answer start embedded generator -->

</answer>
<!-- environment: answer end embedded generator -->
<p name="switchToTextMode">

If we permute a graph, its reducibility or irreducibility is not
changed. However, it may now no longer be apparent from looking
at the adjacency matrix.
</p>

<h3><a id="Graphclosure">19.5.3</a> Graph closure</h3>
<p name=crumbs>
crumb trail:  > <a href="graph.html">graph</a> > <a href="graph.html#Graphsandmatrices">Graphs and matrices</a> > <a href="graph.html#Graphclosure">Graph closure</a>
</p>

<p name="switchToTextMode">

Here is another example of how adjacency matrices can simplify
reasoning about graphs.
<!-- environment: exercise start embedded generator -->
</p>
<!-- TranslatingLineGenerator exercise ['exercise'] -->
  Let $G=\langle V,E\rangle$ be an undirected graph, and let $G'=\langle
  V,E'\rangle$ be the graph with the same vertices, but with vertices
  defined by
\[
 (i,j)\in E'\Leftrightarrow \exists_k\colon (i,k)\in E\wedge
  (k,j)\in E. 
\]
  If $M$ is the adjacency matrix of&nbsp;$G$, show that $M^2$ is the
  adjacency matrix of&nbsp;$G'$, where we use boolean multiplication on the
  elements: $1\cdot1=1$, $1+1=1$.
</p name="exercise">
</exercise>
<!-- environment: exercise end embedded generator -->
<p name="switchToTextMode">

<h2><a id="Spectralgraphtheory">19.6</a> Spectral graph theory</h2>
<p name=crumbs>
crumb trail:  > <a href="graph.html">graph</a> > <a href="graph.html#Spectralgraphtheory">Spectral graph theory</a>
</p>

</p>

<p name="switchToTextMode">
With a graph $G$\footnote{This section owes much to Dan Spielman's course
on spectral graph theory&nbsp;
<a href=http://www.cs.yale.edu/homes/spielman/561/>http://www.cs.yale.edu/homes/spielman/561/</a>
.}
and its adjacency matrix&nbsp;$A_G$, we can define a
<i>stochastic matrix</i>
 or 
<i>Markov matrix</i>
 by scaling
$A_G$ to have unit row sums:
\[
 W_G = D_G\inv A_G\qquad \hbox{where $(D_G)_{ii}=\deg(i)$}. 
\]
To see how we interpret this, let's look at a simple example.
Let's take an unweighted graph with an adjacency matrix
\[
A_G = 
\begin{pmatrix}
1& &1&1\\
 & &1&1\\
1& &1&1\\
 &1&1& \\
\end{pmatrix}
\]
and look at the second row, which says that there are edges $(2,3)$
and $(2,4)$. This means that if you are on node&nbsp;2, you can go
to nodes 3 and&nbsp;4. Scaling this matrix we get
\[
W_G = 
\begin{pmatrix}
1/3&   &1/3&1/3\\
   &   &1/2&1/2\\
1/3&   &1/3&1/3\\
   &1/2&1/2&   \\
\end{pmatrix}
\]
and now the second row says that from node&nbsp;2 you can get
with equal probability to nodes 3 and&nbsp;4.
You can also derive this statement mathematically:
\[
\begin{pmatrix}
0&1&0&0
\end{pmatrix}
 W_G =
\begin{pmatrix}
  0&  0&1/2&1/2\\
\end{pmatrix}
\]
It is simple to extrapolate that: if $p$ is a vector where the $i$-th
component gives the probability of being in node&nbsp;$i$, then $(p^tW_G)_i$
is the probability of being in node&nbsp;$i$ if you take one more
step along a graph edge.
</p>

<!-- environment: exercise start embedded generator -->
<!-- TranslatingLineGenerator exercise ['exercise'] -->
Prove that $p^tW_G$ is indeed a vector of probabilities. Hint:
you can express that $p$ is a probability vector as $p^te=e$,
where $e$ is the vector of all ones.
</p name="exercise">
</exercise>
<!-- environment: exercise end embedded generator -->
<!-- environment: answer start embedded generator -->

</answer>
<!-- environment: answer end embedded generator -->
<p name="switchToTextMode">

<h3><a id="ThegraphLaplacian">19.6.1</a> The graph Laplacian</h3>
<p name=crumbs>
crumb trail:  > <a href="graph.html">graph</a> > <a href="graph.html#Spectralgraphtheory">Spectral graph theory</a> > <a href="graph.html#ThegraphLaplacian">The graph Laplacian</a>
</p>

</p>

<p name="switchToTextMode">
Another matrix to associate with a graph is the
<i>graph Laplacian</i>
\[
 L_G = D_G-A_G. 
\]
This matrix has zero rowsums and positive diagonal entries, so by the
Gershgorin theorem (section&nbsp;
13.5
 all its eigenvalues
are in the complex right half plane.
</p>

<!-- environment: exercise start embedded generator -->
<!-- TranslatingLineGenerator exercise ['exercise'] -->
  Show that the vector of all ones is an eigenvector with eigenvalue&nbsp;1.
</p name="exercise">
</exercise>
<!-- environment: exercise end embedded generator -->
<p name="switchToTextMode">

This Laplacian matrix gives us a quadratic form:
\[
 x^tL_Gx = \sum_{(i,j)\in E} (x_i-x_j)^2. 
\]
</p>

<h3><a id="DomaindecompositionthroughLaplacianmatrices">19.6.2</a> Domain decomposition through Laplacian matrices</h3>
<p name=crumbs>
crumb trail:  > <a href="graph.html">graph</a> > <a href="graph.html#Spectralgraphtheory">Spectral graph theory</a> > <a href="graph.html#DomaindecompositionthroughLaplacianmatrices">Domain decomposition through Laplacian matrices</a>
</p>

<p name="switchToTextMode">

There are various interesting theorems connected with the graph
adjacency and Laplacian matrix.
These have a very practical application to
<i>domain decomposition</i>
.
</p>

<p name="switchToTextMode">
We get our inspiration of elliptic 
<span title="acronym" ><i>PDEs</i></span>
.
</p>

<p name="switchToTextMode">
Connected with the 
<i>Laplace equation</i>
$-\Delta u=f$ is an operator ${\cal L}u=-\Delta u$.
On the unit interval $[0,1]$ the eigenfunctions
of this operator, that is, the functions for which ${\cal L}u=\lambda u$,
are $u_n(x)=\sin n\pi x$ for $n&gt;0$. These have the property that $u_n(x)$
has $n-1$ zeros in the interior of the interval, and they divide the interval
in $n$ connected regions where the function is positive of negative.
Thus, if you wanted to divide a domain $\Omega$ over $p$ processors, you could
consider the $p$-th eigenfunction of the Laplacian on&nbsp;$\Omega$, and find
the connected regions where it is positive or negative.
</p>

<p name="switchToTextMode">
This statement about 
<span title="acronym" ><i>PDE</i></span>
 has a graph equivalent in two versions
of 
<i>Fiedler's theorem</i>
. (We will not give any proofs
in this section;
see&nbsp;
<a href="https://pages.tacc.utexas.edu/~eijkhout/istc/html/bibliography.html#Spielman:spectral-graph-theory">[Spielman:spectral-graph-theory]</a>
.)
<!-- environment: theorem start embedded generator -->
</p>
<!-- TranslatingLineGenerator theorem ['theorem'] -->
  Let $G$ be a weighted path graph on $n$ vertices, let $L_P$ have
  eigenvalues $0 = \lambda_1 &lt; \lambda_2\leq&hellip;\leq\lambda_n$, and let
  $v_k$ be an eigenvector of&nbsp;$\lambda_k$. Then $v_k$ changes sign
  $k-1$ times.
</p name="theorem">
</theorem>
<!-- environment: theorem end embedded generator -->
<p name="switchToTextMode">

The second theorem is more useful&nbsp;
<a href="https://pages.tacc.utexas.edu/~eijkhout/istc/html/bibliography.html#Fiedler:75-property">[Fiedler:75-property]</a>
:
<!-- environment: theorem start embedded generator -->
</p>
<!-- TranslatingLineGenerator theorem ['theorem'] -->
  Let $G = (V,E,w)$ be a weighted connected graph, and let $L_G$ be
  its Laplacian matrix. Let $0 = \lambda_1 &lt; \lambda_2 \leq \cdots
  \leq \lambda_n$ be the eigenvalues of $L_G$ and let $v_1,&hellip;,v_n$
  be the corresponding eigenvectors. For any $k \geq 2$, let $W_k
  =\{i\in V\colon v_k(i)\geq0\}$. Then, the graph induced by $G$ on $W_k$
  has at most $k-1$ connected components.
</p name="theorem">
</theorem>
<!-- environment: theorem end embedded generator -->
<p name="switchToTextMode">

The important consequence of this is that the eigenvector to the first
nontrivial eigenvalue can be used to partition the graph in two
connected piecesone of nodes where the eigenvector is positive, and
one where the eigenvector is negative. This eigenvector is known as
the 
<i>Fiedler vector</i>
.
The adjacency matrix is nonnegative, and there is an extensive theory
for this type of matrix&nbsp;
<a href="https://pages.tacc.utexas.edu/~eijkhout/istc/html/bibliography.html#BePl:book">[BePl:book]</a>
; see the Perron-Frobenius
theorem in section&nbsp;
13.4
.
</p>

<p name="switchToTextMode">
In general there are no guarantees for how good a decomposition this
is, measured by the ratio of the numbers of edges, but in practice it
can be shown that the behaviour is pretty
good&nbsp;
<a href="https://pages.tacc.utexas.edu/~eijkhout/istc/html/bibliography.html#Spielman96spectralpartitioning">[Spielman96spectralpartitioning]</a>
.
</p>

<p name="switchToTextMode">
\begin{lemma}
\[
 \alpha_1\leq d_{\max}. 
\]
\end{lemma}
</p>

<h3><a id="Cheeger'sinequality">19.6.3</a> Cheeger's inequality</h3>
<p name=crumbs>
crumb trail:  > <a href="graph.html">graph</a> > <a href="graph.html#Spectralgraphtheory">Spectral graph theory</a> > <a href="graph.html#Cheeger'sinequality">Cheeger's inequality</a>
</p>
<p name="switchToTextMode">

Above we remarked that the first non-trivial eigenvalue of the graph
Laplacian has a relation to partitioning a graph in two parts. The
<i>Cheeger's constant</i>
 and
<i>Cheeger's inequality</i>
 relate this eigenvalue to a
certain quality measure of partitionings.
</p>

<p name="switchToTextMode">
Let $V$ be the set of vertices and $S\subset V$, then Cheeger's
constant of a graph is defined as
\[
 C=\min_S \frac{e(S,V-S)}
        {\min{\mathord{\mathrm{vol}}(S),\mathord{\mathrm{vol}}(V-S)}}
\]
where $e(S,V-S)$ denotes the number of edges connecting $S$ to $V-S$,
and the volume of a set of nodes is defined as
\[
 \mathord{\mathrm{vol}}(S) = \sum_{e\in S}d(e). 
\]
</p>

<p name="switchToTextMode">
Cheeger's inequality then states
\[
 2C \geq \lambda \geq \frac{C^2}2 
\]
where $\lambda$ is the first nontrivial eigenvalue of the graph
Laplacian.
</p>

</div>
<a href="index.html">Back to Table of Contents</a>
