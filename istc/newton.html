<html>
<head>
<link href="ihpsc.css" rel="stylesheet" type="text/css">
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/css/bootstrap.min.css" integrity="sha384-Gn5384xqQ1aoWXA+058RXPxPg6fy4IWvTNh0E263XmFcJlSAwiGgFAW/dAiS6JXm" crossorigin="anonymous">

  <script src="https://code.jquery.com/jquery-3.2.1.slim.min.js" integrity="sha384-KJ3o2DKtIkvYIK3UENzmM7KCkRr/rE9/Qpg6aAZGJwFDMVNA/GpGFF93hXpG5KkN" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.12.9/umd/popper.min.js" integrity="sha384-ApNbgh9B+Y1QKtv3Rn7W3mgPxhU9K/ScQsAP7hUibX39j7fakFPskvXusvfa0b4Q" crossorigin="anonymous"></script>
  <script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/js/bootstrap.min.js" integrity="sha384-JZR6Spejh4U02d8jOt6vLEHfe/JQGiRRSQQxSfFWpi1MquVdAyjUar5+76PVCmYl" crossorigin="anonymous"></script>

  <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

  <script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {inlineMath: [['$','$']]}
  });
  MathJax.Hub.Config({
    TeX: { equationNumbers: { autoNumber: "AMS" } }
  });
  </script>

  <link rel="stylesheet"
      href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.13.1/styles/default.min.css">
  <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.13.1/highlight.min.js"></script>
  <script>hljs.initHighlightingOnLoad();</script>
</head>

<script type="application/javascript">
  // First we declare some metadata, primarily to describe
  // the container environment.
  var ccrsApiNamespace = "org.xsede.jobrunner.model.ModelApi";
  var mpiExampleMetaJson = {
    // CHANGE: for now, leave the appended string as .SysJobMetaData;
    //         other options will be supported in the future
    "$type": ccrsApiNamespace + ".SysJobMetaData",
    // CHANGE: shell to use implicitly when running commands in the container
    "shell": ["bash"],
    // CHANGE: should currently be one of: .NixOS, .Singularity
    "containerType": {
      "$type":  ccrsApiNamespace + ".NixOS"
    },
    // CHANGE: Specify for NixOS for all jobs, or for Singularity when resuming existing jobs
    "containerId": ["vicOpenMPI"],
    // CHANGE: Specify the singularity image name
    "image": [],
    // Directories on the host to mount in the container, if any:
    "binds": [],
    // Only for singularity:
    "overlay": [],
    // CHANGE: should be filled in dynamically to contain the (student) user,
    //         but this is a demo, so we use a static user name:
    "user": "test0",
    "address": [],
    "hostname": [],
    "url": window.location.href
  };
  var mpiExampleMeta = CCRS.sysJobMetaData(mpiExampleMetaJson);
</script>

<div class="container">
  <div class="row">
    <div class="col-12">
      <div class="pagehead">
        <h1>Minimization</h1>
        <h5>Experimental html version of downloadable textbook, see https://www.tacc.utexas.edu/~eijkhout/istc/istc.html</h5>
      </div>
    </div>
  </div>
  <div>

\[
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%
%%%% This text file is part of the source of 
%%%% `Introduction to High-Performance Scientific Computing'
%%%% by Victor Eijkhout, copyright 2012-2020
%%%%
%%%% mathjax.tex : macros to facility mathjax use in html version
%%%%
%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\newcommand\inv{^{-1}}\newcommand\invt{^{-t}}
\newcommand\bbP{\mathbb{P}}
\newcommand\bbR{\mathbb{R}}
\newcommand\defined{
  \mathrel{\lower 5pt \hbox{${\equiv\atop\mathrm{\scriptstyle D}}$}}}
\newcommand\macro[1]{$\langle$#1$\rangle$}
\newcommand\dtdxx{\frac{\alpha\Delta t}{\Delta x^2}}
\]


17.1 : <a href="newton.html#Descentmethods">Descent methods</a><br>
17.1.1 : <a href="newton.html#Steepestdescent">Steepest descent</a><br>
17.1.2 : <a href="newton.html#Stochasticgradientdescent">Stochastic gradient descent</a><br>
17.1.3 : <a href="newton.html#Code">Code</a><br>
17.1.3.1 : <a href="newton.html#Preliminaries">Preliminaries</a><br>
17.1.3.2 : <a href="newton.html#Framework">Framework</a><br>
17.1.3.3 : <a href="newton.html#Sanitytests">Sanity tests</a><br>
17.2 : <a href="newton.html#Newton'smethod">Newton's method</a><br>
17.2.1 : <a href="newton.html#InexactNewton'smethod">Inexact Newton's method</a><br>
<a href="index.html">Back to Table of Contents</a>
<h1>17 Minimization</h1>
<!-- TranslatingLineGenerator file ['file'] -->
<p name="switchToTextMode">

<h2><a id="Descentmethods">17.1</a> Descent methods</h2>
<p name=crumbs>
crumb trail:  > <a href="newton.html">newton</a> > <a href="newton.html#Descentmethods">Descent methods</a>
</p>

</p>

<p name="switchToTextMode">
We consider a multivariate function~$f\colon R^N\rightarrow $ and the
problem of finding the vector~$\bar x$ for which is attains its
minimum. Even for smooth functions we are immediately faced with the
fact that there are local and global minima; for now we satisfy
ourselves with finding a local minimum.
</p>

<p name="switchToTextMode">
Rather than finding the minimum in one large calculation, we use an
iterative strategy where we start with a point~$\bar x$,
updating it to $\bar x+\bar h$, and repeating this process.
The update vector~$\bar h$ is found through a 
<i>line search</i>
strategy:
we settle on a 
<i>search direction</i>
~$\bar h$,
find a 
<i>step size</i>
~$\tau$ along that direction, and update
\[
 \bar x\leftarrow \bar x+\tau \bar h. 
\]
</p>

<h3><a id="Steepestdescent">17.1.1</a> Steepest descent</h3>
<p name=crumbs>
crumb trail:  > <a href="newton.html">newton</a> > <a href="newton.html#Descentmethods">Descent methods</a> > <a href="newton.html#Steepestdescent">Steepest descent</a>
</p>
<p name="switchToTextMode">

Using the multi-dimensional form of the Taylor expansion formula
(section~
app:taylor
) we can write any sufficiently smooth
function as
\[
 f(\bar x+\bar h) = f(\bar x) + \bar h^t \nabla f +\cdots. 
\]
it is not hard to see that choosing $\bar h=-\nabla f$ gives the most
minimization, so we set
\[
 x_{\scriptstyle\mathrm{new}}\equiv x-\tau \nabla f. 
\]
This method is called 
<i>gradient descent</i>
or
<i>steepest descent</i>
<!-- index -->
.
</p>

<p name="switchToTextMode">
For the new function value this gives
\[
 f(\bar x - \tau \nabla f ) \approx f(\bar x) - \tau \| \nabla f \|^2 
\]
so for $\tau$ small enough this makes the new function value both
positive, and less than~$f(\bar x)$.
</p>

<p name="switchToTextMode">
The 
<i>step size</i>
 $\tau$ can be computed for quadratic
functions~$f$, and approximated otherwise:
\[
 f(\bar x+\tau\bar h) = f(\bar x) + \tau\bar h^t \nabla f +
\frac{\tau^2}2 h^t (\nabla\cdot\nabla f) h +\cdots. 
\]
Ignoring higher order terms and setting
$\delta f/\delta\tau=0$
gives
\[
 \tau = - \bar h^t \nabla f / h^t (\nabla\cdot\nabla f) h. 
\]
</p>

<p name="switchToTextMode">
Another strategy for finding a suitable step size is known as
<i>backtracking</i>
:
<!-- environment: itemize start embedded generator -->
</p>
<!-- TranslatingLineGenerator itemize ['itemize'] -->
<li>
Start with a default step size, for instance $\tau\equiv1$.
<li>
Then until $f(\bar x+\tau\bar h)<f(\bar x)$ do
\[
 \tau\leftarrow\tau/2. 
\]
</ul>
</itemize>
<!-- environment: itemize end embedded generator -->
<p name="switchToTextMode">

<h3><a id="Stochasticgradientdescent">17.1.2</a> Stochastic gradient descent</h3>
<p name=crumbs>
crumb trail:  > <a href="newton.html">newton</a> > <a href="newton.html#Descentmethods">Descent methods</a> > <a href="newton.html#Stochasticgradientdescent">Stochastic gradient descent</a>
</p>
</p>

<p name="switchToTextMode">
While the gradient is the optimal search direction in any given step,
overall it need not be the best. For instance, for quadratic problems,
which includes many problems from 
<span title="acronym" ><i>PDEs</i></span>
, a~better choice is to
orthogonalize search directions. On the other hand, in 
<span title="acronym" ><i>ML</i></span>
applications, 
<i>SGD</i>
 is a good choice, where the coordinate
directions are used as search directions. In this case
\[
 f(x+\tau e_i) = f(x) + \tau \frac{df}{de_i} +
\frac{\tau^2}2 \frac{\delta^2f}{\delta e_i^2} 
\]
Then:
\[
 \tau = - (\nabla f)_i / \frac{ \delta^2 f }{ \delta e_i^2 }. 
\]
</p>

<h3><a id="Code">17.1.3</a> Code</h3>
<p name=crumbs>
crumb trail:  > <a href="newton.html">newton</a> > <a href="newton.html#Descentmethods">Descent methods</a> > <a href="newton.html#Code">Code</a>
</p>
<p name="switchToTextMode">

<h4><a id="Preliminaries">17.1.3.1</a> Preliminaries</h4>
<p name=crumbs>
crumb trail:  > <a href="newton.html">newton</a> > <a href="newton.html#Descentmethods">Descent methods</a> > <a href="newton.html#Code">Code</a> > <a href="newton.html#Preliminaries">Preliminaries</a>
</p>
</p>

<p name="switchToTextMode">
We declare a 
<tt>vector</tt>
 class that is a standard vector, with
operations defined on it such as addition, but also rotation.
</p>

<p name="switchToTextMode">
There is a derived class 
<tt>unit_vector</tt>
 that does the obvious.
</p>

<h4><a id="Framework">17.1.3.2</a> Framework</h4>
<p name=crumbs>
crumb trail:  > <a href="newton.html">newton</a> > <a href="newton.html#Descentmethods">Descent methods</a> > <a href="newton.html#Code">Code</a> > <a href="newton.html#Framework">Framework</a>
</p>
<p name="switchToTextMode">

We start by defining functions as a pure virtual class, meaning that
any function needs to support the methods mentioned here:
</p>

<div class="card">
  <div class="card-header" id="headingOne">
    <h5 class="mb-0">
      <button class="btn btn-link" data-toggle="collapse" data-target="#functiondef" aria-expanded="false" aria-controls="functiondef">
        C Code: functiondef
      </button>
    </h5>
  </div>
  <div id="functiondef" class="collapse">
  <pre>
// minimlib.h
class function {
public:
  virtual double eval( const valuevector& coordinate ) const = 0;
  virtual valuevector grad( const valuevector& coordinate ) const = 0;
  virtual std::shared_ptr&lt;matrix&gt; delta( const valuevector& coordinate ) const = 0;
  virtual int dimension() const = 0;
};
</pre>
</div>
</div>
<p name="switchToTextMode">

Using such a function it becomes possible to define various update
steps. For instance, the steepest descent step uses the gradient:
</p>

<div class="card">
  <div class="card-header" id="headingOne">
    <h5 class="mb-0">
      <button class="btn btn-link" data-toggle="collapse" data-target="#steepestdescentstep" aria-expanded="false" aria-controls="steepestdescentstep">
        C Code: steepestdescentstep
      </button>
    </h5>
  </div>
  <div id="steepestdescentstep" class="collapse">
  <pre>
// minimlib.cxx
valuevector steepest_descent_step
    ( const function& objective,const valuevector& point ) {
  auto grad = objective.grad(point);
  auto delta = objective.delta(point);

  auto search_direction( grad );
  auto hf = grad.inprod(search_direction);
  auto hfh = search_direction.inprod( delta-&gt;mvp(search_direction) );
  auto tau = - hf / hfh;
  auto new_point = point + ( search_direction * tau );
  return new_point;
};
</pre>
</div>
</div>
<p name="switchToTextMode">

On the other hand, stochastic descent is based on unit vectors:
</p>

<div class="card">
  <div class="card-header" id="headingOne">
    <h5 class="mb-0">
      <button class="btn btn-link" data-toggle="collapse" data-target="#stochasticdescentstep" aria-expanded="false" aria-controls="stochasticdescentstep">
        C Code: stochasticdescentstep
      </button>
    </h5>
  </div>
  <div id="stochasticdescentstep" class="collapse">
  <pre>
valuevector stochastic_descent_step
    ( const function& objective,const valuevector& point, int idim,
      double damp) {
  int dim = objective.dimension();
  auto grad = objective.grad(point);
  auto delta = objective.delta(point);

  auto search_direction( unit_valuevector(dim,idim) );
  auto gradfi = grad.at(idim);
  auto hf = gradfi;
  auto hfh = delta-&gt;d2fdxi2(idim);
  auto tau = - hf / hfh;
  auto new_point = point + ( search_direction * (tau * damp) );

  return new_point;
};
</pre>
</div>
</div>
<p name="switchToTextMode">

<h4><a id="Sanitytests">17.1.3.3</a> Sanity tests</h4>
<p name=crumbs>
crumb trail:  > <a href="newton.html">newton</a> > <a href="newton.html#Descentmethods">Descent methods</a> > <a href="newton.html#Code">Code</a> > <a href="newton.html#Sanitytests">Sanity tests</a>
</p>
</p>

<p name="switchToTextMode">
Using steepest descent on a circle gives convergence in one step:
\snippetwithoutput{descentcircle}{minimization}{descentcircle}
</p>

<p name="switchToTextMode">
On the other hand, steepest descent on an ellipse takes a number of
iterations:
\snippetwithoutput{descentellipse}{minimization}{descentellipse}
</p>

<h2><a id="Newton'smethod">17.2</a> Newton's method</h2>
<p name=crumbs>
crumb trail:  > <a href="newton.html">newton</a> > <a href="newton.html#Newton'smethod">Newton's method</a>
</p>

<p name="switchToTextMode">

<i>Newton's method</i>
<!-- index -->
(or the
<i>Newton-Raphson method</i>
<!-- index -->
)
is an iterative
procedure for finding a 
<i>zero of a function</i>
, that is, a
value~$x$ for which~$f(x)=0$. It requires knowledge of the derivative~$f'$
of the function, and it can be justified from figures such
as~
17.1
.
</p>

<p name="switchToTextMode">
Another justification comes from minimization: if a function~$f$ is
twice differentiable, we can write
\[
 f(x+h) = f(x) + h^t\nabla f + \frac12 h^t(\nabla^2f) h 
\]
and the minimum is attained at
\[
 x_{\scriptstyle\mathrm{new}} = x - (\nabla^2f)\inv \nabla f. 
\]
This equivalent to finding a zero of the gradient:
\[
 0=\nabla f(x+h) = \nabla f(x)+h^t(\nabla^2f(x))h. 
\]
</p>

<!-- environment: exercise start embedded generator -->
<!-- TranslatingLineGenerator exercise ['exercise'] -->
  Let $f(x_1,x_2) = (10x_1^2+x_2^2)/2 + 5\log(1+e^{-x_1-x_2})$.
  How fast do gradient descent and the Newton's method converge?
  To get insight in their differing behaviors, plot a number of
  iterates against level curves of the function.
</p name="exercise">
</exercise>
<!-- environment: exercise end embedded generator -->
<p name="switchToTextMode">

This exercise gives some idea of that is wrong with gradient descent:
it always steps perpendicular to the current level curve. However, the
minimum does not necessarily lie in that direction.
</p>

<!-- environment: figure start embedded generator -->
<!-- TranslatingLineGenerator figure ['figure'] -->
<img src="graphics/newton1d.png" width=800></img>
<p name="caption">
FIGURE 17.1: One step in the one-dimensional Newton method
</p>

</float>
</figure>
<!-- environment: figure end embedded generator -->
<p name="switchToTextMode">

Iteratively:
\[
 x_{n+1} = x_n-f(x_n)/f'(x_n) 
\]
</p>

<p name="switchToTextMode">
Without proof we state:
<!-- environment: itemize start embedded generator -->
</p>
<!-- TranslatingLineGenerator itemize ['itemize'] -->
<li>
The Newton method will converge to the zero if the starting
  point of the iteration is close enough to the zero, and if the
  function is differentiable in the zero.
<li>
For many functions Newton's method will not converge, but it is
  possible to obtain convergence by introducing damping,
  or doing an inexact update:
\[
 x_{n+1} = x_n-\alpha f(x_n)/f'(x_n) 
\]
  where $\alpha<1$.
</ul>
</itemize>
<!-- environment: itemize end embedded generator -->
<p name="switchToTextMode">

<!-- environment: exercise start embedded generator -->
</p>
<!-- TranslatingLineGenerator exercise ['exercise'] -->
  It is possible for Newton's method to be in a cycle. Suppose this is
  a cycle of length two: 
\[
 x_0\rightarrow x_1 \rightarrow x_2=x_0. 
\]
  If you write out the equations for this cycle you'll find a
  differential equation for~$f$. What is the solution? Why doesn't the
  Newton method converge for this function?
</p name="exercise">
</exercise>
<!-- environment: exercise end embedded generator -->
<!-- environment: answer start embedded generator -->

</answer>
<!-- environment: answer end embedded generator -->
<p name="switchToTextMode">

In multiple dimensions, that is, with a function
$f\colon\mathbb{R}^N\rightarrow\mathbb{R}$
Newton's method becomes an iterated
<i>linear system solution</i>
<!-- index -->
<!-- index -->
:
\[
 \bar x_{n+1} = \bar x_n-F(\bar x_n)\inv f(\bar x_n) 
\]
where $F$ is the 
<i>Jacobian</i>
 of&nbsp;$f$.
</p>

<p name="switchToTextMode">
Since Newton's method is an iterative process we do not need the
solution of this linear system to full accuracy, so inexact solutions,
for instance through
<i>iterative solution</i>
<!-- index -->
,
is often feasible.
</p>

<h3><a id="InexactNewton'smethod">17.2.1</a> Inexact Newton's method</h3>
<p name=crumbs>
crumb trail:  > <a href="newton.html">newton</a> > <a href="newton.html#Newton'smethod">Newton's method</a> > <a href="newton.html#InexactNewton'smethod">Inexact Newton's method</a>
</p>
<p name="switchToTextMode">

There is a variety of reasons why Newton's method would not converge.
(In fact, plotting the regions from where it does converge will, for
suitable functions, give nice 
<i>fractals</i>
.)
For this reason, in practice an
<i>inexact Newton's method</i>
 is used. The inexactness comes
in two ways:
<!-- environment: itemize start embedded generator -->
</p>
<!-- TranslatingLineGenerator itemize ['itemize'] -->
<li>
Instead of the `optimal' step length we use a fraction. This is
  often chosen through `backtracking', and a choice is adopted for
  which at least some decrease in function value is observed.
<li>
Instead of the inverse of the Jacobian we use an approximation
  of that operator. For instance, we could compute the Jacobian (often
  an expensive process) and then use it for multiple Newton steps.
</ul>
</itemize>
<!-- environment: itemize end embedded generator -->
<p name="switchToTextMode">
A combination of these techniques can be shown to give guaranteed
converence&nbsp;
<a href="https://pages.tacc.utexas.edu/~eijkhout/istc/html/bibliography.html#zhwa94">[zhwa94]</a>
.
</div>
<a href="index.html">Back to Table of Contents</a>
