<html>
<head>
<link href="ihpsc.css" rel="stylesheet" type="text/css">
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/css/bootstrap.min.css" integrity="sha384-Gn5384xqQ1aoWXA+058RXPxPg6fy4IWvTNh0E263XmFcJlSAwiGgFAW/dAiS6JXm" crossorigin="anonymous">

<script src="https://code.jquery.com/jquery-3.2.1.slim.min.js" integrity="sha384-KJ3o2DKtIkvYIK3UENzmM7KCkRr/rE9/Qpg6aAZGJwFDMVNA/GpGFF93hXpG5KkN" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.12.9/umd/popper.min.js" integrity="sha384-ApNbgh9B+Y1QKtv3Rn7W3mgPxhU9K/ScQsAP7hUibX39j7fakFPskvXusvfa0b4Q" crossorigin="anonymous"></script>

<script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/js/bootstrap.min.js" integrity="sha384-JZR6Spejh4U02d8jOt6vLEHfe/JQGiRRSQQxSfFWpi1MquVdAyjUar5+76PVCmYl" crossorigin="anonymous"></script>

<script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.4.0/MathJax.js?config=TeX-MML-AM_CHTML">
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {inlineMath: [['$','$']]}
  });
  MathJax.Hub.Config({
    TeX: { equationNumbers: { autoNumber: "AMS" } }
  });
</script>

<link rel="stylesheet"
      href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.13.1/styles/default.min.css">
  <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.13.1/highlight.min.js"></script>
  <script>hljs.initHighlightingOnLoad();</script>
</head>

<script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
<script src=https://ccrs.cac.cornell.edu:8443/client.0.2.js></script>
<script id="script">
class Example {
  constructor(buttonID, editorID, outputID, sourceFile, fileName, commandStr) {
    this.buttonID = buttonID;
    this.editorID = editorID;
    this.outputID = outputID;
    this.sourceFile = sourceFile;
    this.fileName = fileName;
    this.commandStr = commandStr;
  }
    
  async display(results, object) {
    if (results.stdout.length > 0)
      document.getElementById(object.outputID).textContent = results.stdout;
    else
      document.getElementById(object.outputID).textContent = results.stderr;
  }

  async initialize() {
    this.editor = await MonacoEditorFileSource.create(this.editorID);
    this.editor.setTextFromFile(this.sourceFile);
    this.job = await Job.create(JobType.MPI);
    this.command = new CommandWithFiles(this.job, this.commandStr);
    this.command.addFileSource(this.editor, this.fileName);
    this.trigger = new ButtonTrigger(this.command, this.display, this.buttonID, this);
    document.getElementById(this.buttonID).disabled = false;
  }
}
</script>
<style></style>

<div class="container">
  <div class="row">
    <div class="col-12">
      <div class="pagehead">
        <h1>MPI topic: Functional parallelism</h1>
        <h5>Experimental html version of downloadable textbook, see http://www.tacc.utexas.edu/~eijkhout/istc/istc.html</h5>
      </div>
    </div>
  </div>
  <div>


\[
\newcommand\inv{^{-1}}\newcommand\invt{^{-t}}
\newcommand\bbP{\mathbb{P}}
\newcommand\bbR{\mathbb{R}}
\newcommand\defined{
  \mathrel{\lower 5pt \hbox{${\equiv\atop\mathrm{\scriptstyle D}}$}}}
\]


2.1 : <a href="mpi-functional.html#TheSPMDmodel">The SPMD model</a><br>
2.2 : <a href="mpi-functional.html#StartingandrunningMPIprocesses">Starting and running MPI processes</a><br>
2.2.1 : <a href="mpi-functional.html#Headers">Headers</a><br>
2.2.2 : <a href="mpi-functional.html#Initializationfinalization">Initialization / finalization</a><br>
2.2.2.1 : <a href="mpi-functional.html#AbortinganMPIrun">Aborting an MPI run</a><br>
2.2.2.2 : <a href="mpi-functional.html#Testingtheinitializedfinalizedstatus">Testing the initialized/finalized status</a><br>
2.2.2.3 : <a href="mpi-functional.html#Informationabouttherun">Information about the run</a><br>
2.2.2.4 : <a href="mpi-functional.html#Commandlinearguments">Commandline arguments</a><br>
2.3 : <a href="mpi-functional.html#Processoridentification">Processor identification</a><br>
2.3.1 : <a href="mpi-functional.html#Processorname">Processor name</a><br>
2.3.2 : <a href="mpi-functional.html#Communicators">Communicators</a><br>
2.3.3 : <a href="mpi-functional.html#Processandcommunicatorproperties:rankandsize">Process and communicator properties: rank and size</a><br>
2.4 : <a href="mpi-functional.html#Functionalparallelism">Functional parallelism</a><br>
2.5 : <a href="mpi-functional.html#Distributedcomputinganddistributeddata">Distributed computing and distributed data</a><br>
2.6 : <a href="mpi-functional.html#Reviewquestions">Review questions</a><br>
<a href="index.html">Back to Table of Contents</a>
<h1>2 MPI topic: Functional parallelism</h1>
<!-- TranslatingLineGenerator file ['file'] -->
<p name="switchToTextMode">

<h2><a id="TheSPMDmodel">2.1</a> The SPMD model</h2>
<p name=crumbs>
crumb trail:  > <a href="mpi-functional.html">mpi-functional</a> > <a href="mpi-functional.html#TheSPMDmodel">The SPMD model</a>
</p>

</p>

<p name="switchToTextMode">
MPI programs conform largely
to the 
<span title="acronym" ><i>SPMD</i></span>
 model, where each processor runs the same executable.
This running executable we call a 
<i>process</i>
.
</p>

<p name="switchToTextMode">
When MPI was first written, 20 years ago, it was clear what a processor
was: it was what was in a computer on someone's desk, or in a rack.
If this computer was part of a networked cluster, you called it a 
<i>node</i>
.
So if you ran an MPI program, each node would have one MPI process;
<!-- environment: figure start embedded generator -->
</p>
<!-- environment block purpose: [[ environment=figure ]] -->
<figure>
<float mode=figure>
<!-- TranslatingLineGenerator figure ['figure'] -->
<img src="graphics/mpi-node1.jpeg" width=800></img>
<p name="caption">
FIGURE 2.1: Cluster structure as of the mid 1990s
</p>

</float>
</figure>
<!-- environment: figure end embedded generator -->
<p name="switchToTextMode">
figure~
2.1
.
You could of course run more than one
process, using the 
<i>time slicing</i>
 of the 
<span title="acronym" ><i>OS</i></span>
, but that
would give you no extra performance.
</p>

<p name="switchToTextMode">
These days the situation is more complicated.
You can still talk about a node in a cluster, but now a node can contain
more than one processor chip (sometimes called a 
<i>socket</i>
),
and each processor chip probably has multiple
<i>cores</i>
<!-- index -->
.
<!-- environment: figure start embedded generator -->
</p>
<!-- environment block purpose: [[ environment=figure ]] -->
<figure>
<float mode=figure>
<!-- TranslatingLineGenerator figure ['figure'] -->
<img src="graphics/mpi-node3.jpeg" width=800></img>
<p name="caption">
FIGURE 2.2: Hybrid cluster structure
</p>

</float>
</figure>
<!-- environment: figure end embedded generator -->
<p name="switchToTextMode">
Figure~
2.2
 shows how you could explore this using a mix
of MPI between the nodes, and a shared memory programming system on the nodes.
</p>

<p name="switchToTextMode">
However, since each core can act like an independent processor,
you can also have multiple MPI processes per node. To MPI, the cores look
like the old completely separate processors. This is the `pure MPI'
model of figure~
2.3
, which we will use in most of this part
of the book. (Hybrid computing will be discussed in chapter~
<a href="http://pages.tacc.utexas.edu/~eijkhout/pcse/html/hybrid.html">Hybrid computing</a>
.)
<!-- environment: figure start embedded generator -->
</p>
<!-- environment block purpose: [[ environment=figure ]] -->
<figure>
<float mode=figure>
<!-- TranslatingLineGenerator figure ['figure'] -->
<img src="graphics/mpi-node2.jpeg" width=800></img>
<p name="caption">
FIGURE 2.3: MPI-only cluster structure
</p>

</float>
</figure>
<!-- environment: figure end embedded generator -->
<p name="switchToTextMode">

This is somewhat confusing: the old processors needed MPI programming, because
they were physically separated. The cores on a modern processor, on the other hand,
share the same memory, and even some caches. In its basic mode MPI
seems to ignore all
of this: each core receives an MPI process and the programmer writes the same send/receive call no matter
where the other process is located. In fact, you can't immediately see
whether two cores are on the same node or different nodes. Of course,
on the implementation level MPI uses a different communication
mechanism depending on whether  cores are on the same socket or on
different nodes, so you don't have to worry about lack of efficiency.
</p>

<!-- environment: remark start embedded generator -->
<!-- environment block purpose: [[ environment=remark ]] -->
<remark>
<b>Remark</b>
<p name="remark">
<!-- TranslatingLineGenerator remark ['remark'] -->
  In some rare cases you may want to run in an 
<i>MPMD</i>
 mode, rather
  than 
<span title="acronym" ><i>SPMD</i></span>
. This can be achieved either on the 
<span title="acronym" ><i>OS</i></span>
 level
  (see section~
<a href="http://pages.tacc.utexas.edu/~eijkhout/pcse/html/mpi.html#Multipleprogramstart">15.9.4</a>
),
  using options of the 
<tt>mpiexec</tt>
 mechanism, or you can use
  MPI's built-in process management; chapter~
<a href="http://pages.tacc.utexas.edu/~eijkhout/pcse/html/mpi-proc.html">MPI topic: Process management</a>
. Like
  I~said, this concerns only rare cases.
</p name="remark">
</remark>
<!-- environment: remark end embedded generator -->
<p name="switchToTextMode">

<!-- TranslatingLineGenerator file ['file'] -->
</p>

<h2><a id="StartingandrunningMPIprocesses">2.2</a> Starting and running MPI processes</h2>
<p name=crumbs>
crumb trail:  > <a href="mpi-functional.html">mpi-functional</a> > <a href="mpi-functional.html#StartingandrunningMPIprocesses">Starting and running MPI processes</a>
</p>

<p name="switchToTextMode">

The 
<span title="acronym" ><i>SPMD</i></span>
 model may be initially confusing. Even though there is
only a single source, compiled into a single executable,
the parallel run comprises a number of independently started MPI
processes (see section~
<a href="http://pages.tacc.utexas.edu/~eijkhout/pcse/html/mpi-started.html#Basicmodel">1.3</a>
 for the mechanism).
</p>

<p name="switchToTextMode">
The following exercises are designed to give you an intuition for this
one-source-many-processes setup. In the first exercise you will see
that the mechanism for starting MPI programs starts up independent
copies. There is nothing in the source that says `and now you become parallel'.
</p>

<!-- environment: figure start embedded generator -->
<!-- environment block purpose: [[ environment=figure ]] -->
<figure>
<float mode=figure>
<!-- TranslatingLineGenerator figure ['figure'] -->
<img src="graphics/hello-parallel.png" width=800></img>
<p name="caption">
FIGURE 2.4: Running a hello world program in parallel
</p>

</float>
</figure>
<!-- environment: figure end embedded generator -->
<p name="switchToTextMode">

The following exercise demonstrates this point.
</p>

<!-- exercise start: ex-hello.txt -->
<script type="text/plain" id="mpiHelloCode">
/****************************************************************
 ****
 **** This program file is part of the book
 **** `Parallel programming with MPI and OpenMP'
 **** by Victor Eijkhout, eijkhout@tacc.utexas.edu
 ****
 **** copyright Victor Eijkhout 2012-9
 ****
 **** MPI Exercise
 ****
 ****************************************************************/

#include <stdlib.h>
#include <stdio.h>
#include <mpi.h>

int main(int argc,char **argv) {

/**** your code here ****/

  return 0;
}
</script>
<br/>

<div id="mpiHelloEdDiv"></div>
<!-- EX-CHANGE: change the id and the contained code to fit the example: -->
<script type="application/javascript">
  // Some settings for the editor; currently width and height
  var edSettings = new CCRS.Ed.Settings(500, 300);

  // Now configure the dynamic parts of the editor logic
  // by creating a list of Actions; these actions add buttons
  // that take input from the editor and store it in a file,
  // as well as a command to run on the host on the configured
  // output file.

  // EX-CHANGE: name of the function should be changed per example
  var mpiHelloEditorActions = function (aceEd, jobId) {
    var makeExecFile = CCRS.functize0(function () {
      // EX-CHANGE: Name the file will be on disk:
      var editFile = "hello.c";
      var fileContents = {};
      fileContents[editFile] = aceEd.getValue();
      // CHANGE: Declare a new Job type (ExecFile):
      //         Most uses for now will be editing files, so keeping
      //         ExecFile here is probably want you want. See the OneShot
      //         example above for a different type of example
      //         (single command, no file). More options to come.
      var ef = new CCRS.ExecFile(
        jobId,
        // EX-CHANGE: command to run for this action
        "mpicc " + editFile + " -o hello && mpirun --oversubscribe -np 8 hello",
        // CHANGE: metadata above, usually don't need to change for
        //         each exercise, but may have a few different
        //         definitions to select from depending on exercise and
        //         container type, etc.
        mpiExampleMeta,
        CCRS.makeFileContents(fileContents)
      );
      return CCRS.listize([ef]);
    });
    // EX-CHANGE: Button text:
    var runButtonTxt = "Compile and run";
    var runAction = CCRS.functize0(function () {
      return CCRS.Ed.Act(
        Tags.b(runButtonTxt),
        runButtonTxt,
        makeExecFile,
        // CHANGE: this must match the type of job
        //         (the variable 'ef' above).
        CCRS.jobExecFile
      );
    });
    return CCRS.listize([runAction]);
  };
  var mpiHelloEd = CCRS.makeEditor(
    // EX-CHANGE - this sould be the function defined above.
    mpiHelloEditorActions,
    CCRS.makeJobId(),
    // EX-CHANGE: a name for the editor used internally by ace editor
    "mpi-hello-ace-example",
    // CHANGE: language type used by the editor. See a listing at:
    //         https://github.com/ajaxorg/ace/tree/master/lib/ace/mode
    "c_cpp",
    edSettings,
    // EX-CHANGE: the script ID containing the example code, defined above
    document.getElementById("mpiHelloCode").innerText,
    // EX-CHANGE: the div ID where the example will be rendered,
    //            defined in this page
    document.getElementById("mpiHelloEdDiv")
  );
</script>

<!-- exercise end ex-hello.txt -->
<p name="switchToTextMode">

<!-- environment: exercise start embedded generator -->
</p>
<!-- environment block purpose: [[ environment=exercise ]] -->
<exercise>
<b>Exercise</b>
<p name="exercise">
<!-- TranslatingLineGenerator exercise ['exercise'] -->

  Write a `hello world' program, without any MPI in it,
  and run it in parallel with 
<tt>mpiexec</tt>
 or your local equivalent.
  Explain the output.
</p>

<!-- environment: tacc start embedded generator -->
<!-- environment block purpose: [[ environment=tacc ]] -->
<tacc>

<p name="tacc">
<!-- TranslatingLineGenerator tacc ['tacc'] -->
    (On TACC machines such as stampede, use 
<tt>ibrun</tt>
, no
    processor count.)
</p name="tacc">

</tacc>
<!-- environment: tacc end embedded generator -->
<p name="switchToTextMode">

<!-- skeleton start: hello -->
<button id="runBtnhello">Compile and run hello</button>
<div id="editorDivhello" 
     style="height:125px;border:1px solid black; 
     resize:vertical; overflow: hidden;"></div>
<pre id="outputPrehello"></pre>
<script name="defSkeletonhello">
let examplehello = new Example(
    "runBtnhello", "editorDivhello", "outputPrehello", 
    "skeletons/hello.c", "hello.c",
    "mpicc hello.c && mpiexec -n 4 ./a.out" );
examplehello.initialize();
</script>
<!-- skeleton end: hello -->
</p name="exercise">
</exercise>
<!-- environment: exercise end embedded generator -->
<!-- environment: answer start embedded generator -->
<!-- environment block purpose: [[ environment=answer ]] -->
<answer>


</answer>
<!-- environment: answer end embedded generator -->
<p name="switchToTextMode">

This exercise is illustrated in figure&nbsp;
2.4
.
</p>

<h3><a id="Headers">2.2.1</a> Headers</h3>
<p name=crumbs>
crumb trail:  > <a href="mpi-functional.html">mpi-functional</a> > <a href="mpi-functional.html#StartingandrunningMPIprocesses">Starting and running MPI processes</a> > <a href="mpi-functional.html#Headers">Headers</a>
</p>
<p name="switchToTextMode">

If you use MPI commands in a program file, be sure to include
the proper header file, 
<tt>mpi.h</tt>
 or 
<tt>mpif.h</tt>
.
<!-- environment: verbatim start embedded generator -->
</p>
<!-- environment block purpose: [[ environment=verbatim ]] -->
<verbatim>
<pre>
#include "mpi.h" // for C
#include "mpif.h" ! for Fortran
</pre>
</verbatim>
<!-- environment: verbatim end embedded generator -->
<p name="switchToTextMode">
For \fstandard{90}, many MPI installations
also have an MPI module, so you can write
<!-- environment: verbatim start embedded generator -->
</p>
<!-- environment block purpose: [[ environment=verbatim ]] -->
<verbatim>
<pre>
use mpi     ! pre 3.0
use mpi_f08 ! 3.0 standard
</pre>
</verbatim>
<!-- environment: verbatim end embedded generator -->
<p name="switchToTextMode">
The internals of these files can be different between MPI
installations, so you can not compile one file against one 
<tt>mpi.h</tt>

file and another file, even with the same compiler on the same machine,
against a different MPI.
</p>

<!-- environment: pythonnote start embedded generator -->
<!-- environment block purpose: [[ environment=pythonnote ]] -->
<remark>
<b>Python note</b>
<!-- TranslatingLineGenerator pythonnote ['pythonnote'] -->
<p name="switchToTextMode">
  It's easiest to
<!-- environment: lstlisting start embedded generator -->
</p>
<!-- environment block purpose: [[ environment=lstlisting ]] -->
<lstlisting>
<pre>
from mpi4py import MPI
</pre>
</lstlisting>
<!-- environment: lstlisting end embedded generator -->
</remark>
<!-- environment: pythonnote end embedded generator -->
<p name="switchToTextMode">

<!-- environment: mplnote start embedded generator -->
</p>
<!-- environment block purpose: [[ environment=mplnote ]] -->
<remark>
<b>MPL note</b>
<!-- TranslatingLineGenerator mplnote ['mplnote'] -->
<p name="switchToTextMode">
  To compile MPL programs, add a line
<!-- environment: lstlisting start embedded generator -->
</p>
<!-- environment block purpose: [[ environment=lstlisting ]] -->
<lstlisting>
<pre>
#include &lt;mpl/mpl.hpp&gt;
</pre>
</lstlisting>
<!-- environment: lstlisting end embedded generator -->
<p name="switchToTextMode">
  to your file.
<i>End of MPL note</i>
</remark>
<!-- environment: mplnote end embedded generator -->
<p name="switchToTextMode">

<h3><a id="Initializationfinalization">2.2.2</a> Initialization / finalization</h3>
<p name=crumbs>
crumb trail:  > <a href="mpi-functional.html">mpi-functional</a> > <a href="mpi-functional.html#StartingandrunningMPIprocesses">Starting and running MPI processes</a> > <a href="mpi-functional.html#Initializationfinalization">Initialization / finalization</a>
</p>

</p>

<p name="switchToTextMode">
Every (useful) MPI program has to start with 
<i>MPI initialization</i>
through a call to
<div class="card">
  <div class="card-header" id="headingOne">
    <h5 class="mb-0">
      <button class="btn btn-link" data-toggle="collapse" data-target="#MPI_Init" aria-expanded="false" aria-controls="MPI_Init">
        Routine reference: MPI_Init
      </button>
    </h5>
  </div>
  <div id="MPI_Init" class="collapse">
  <pre>
C:
int MPI_Init(int *argc, char ***argv)

Fortran:
MPI_Init(ierror)
INTEGER, OPTIONAL, INTENT(OUT) :: ierror
</pre>
</div>
</div>
<i>MPI_Init</i>
, and have
<div class="card">
  <div class="card-header" id="headingOne">
    <h5 class="mb-0">
      <button class="btn btn-link" data-toggle="collapse" data-target="#MPI_Finalize" aria-expanded="false" aria-controls="MPI_Finalize">
        Routine reference: MPI_Finalize
      </button>
    </h5>
  </div>
  <div id="MPI_Finalize" class="collapse">
  <pre>
C:
int MPI_Finalize(void)

Fortran:
MPI_Finalize(ierror)
INTEGER, OPTIONAL, INTENT(OUT) :: ierror
</pre>
</div>
</div>
<i>MPI_Finalize</i>
 to finish the use of MPI in your program.
The init call is different between the various languages.
</p>

<p name="switchToTextMode">
In&nbsp;C, you can pass 
<tt>argc</tt>
 and 
<tt>argv</tt>
, the arguments
of a C language main program:
<!-- environment: lstlisting start embedded generator -->
</p>
<!-- environment block purpose: [[ environment=lstlisting ]] -->
<lstlisting>
<pre>
int main(int argc,char **argv) {
    ....
    return 0;
}
</pre>
</lstlisting>
<!-- environment: lstlisting end embedded generator -->
<p name="switchToTextMode">
(It is allowed to pass 
<tt>NULL</tt>
 for these arguments.)
</p>

<p name="switchToTextMode">
Fortran (before 2008) lacks this commandline argument handling,
so 
<tt>MPI_Init</tt>
 lacks those arguments.
</p>

<!-- environment: pythonnote start embedded generator -->
<!-- environment block purpose: [[ environment=pythonnote ]] -->
<remark>
<b>Python note</b>
<!-- TranslatingLineGenerator pythonnote ['pythonnote'] -->
<p name="switchToTextMode">
  In many cases,  no initialize and finalize calls are needed:
  the statement
<div class="card">
  <div class="card-header" id="headingOne">
    <h5 class="mb-0">
      <button class="btn btn-link" data-toggle="collapse" data-target="#pympiimport" aria-expanded="false" aria-controls="pympiimport">
        Text: pympiimport
      </button>
    </h5>
  </div>
  <div id="pympiimport" class="collapse">
  <pre>
## mpi.py
from mpi4py import MPI
</pre>
</div>
</div>
  performs the initialization.
  Likewise, the finalize happens at the end of the program.
</p>

<p name="switchToTextMode">
  However, for special cases, there is an 
<tt>mpi4py.rc</tt>
 object
  that can be set in between importing 
<tt>mpi4py</tt>
 and
  importing 
<tt>mpi4py.MPI</tt>
:
<!-- environment: lstlisting start embedded generator -->
</p>
<!-- environment block purpose: [[ environment=lstlisting ]] -->
<lstlisting>
<pre>
import mpi4py
mpi4py.rc.initialize = False
mpi4py.rc.finalize = False
from mpi4py import MPI
MPI.Init()
# stuff
MPI.Finalize()
</pre>
</lstlisting>
<!-- environment: lstlisting end embedded generator -->
</remark>
<!-- environment: pythonnote end embedded generator -->
<p name="switchToTextMode">

<!-- environment: mplnote start embedded generator -->
</p>
<!-- environment block purpose: [[ environment=mplnote ]] -->
<remark>
<b>MPL note</b>
<!-- TranslatingLineGenerator mplnote ['mplnote'] -->
<p name="switchToTextMode">
  There is no initialization or finalize call.
<!-- environment: mplimpl start embedded generator -->
</p>
<!-- environment block purpose: [[ environment=mplimpl ]] -->
<remark>

<!-- TranslatingLineGenerator mplimpl ['mplimpl'] -->
    Initialization is done at the first  <tt>mpl::environment</tt>  method call,
    such as  <tt>comm_world</tt> .
</remark>
<!-- environment: mplimpl end embedded generator -->
<p name="switchToTextMode">

<i>End of MPL note</i>
</remark>
<!-- environment: mplnote end embedded generator -->
<p name="switchToTextMode">

This may look a bit like declaring `this is the parallel part of a
program', but that's not true: again, the whole code is executed
multiple times in parallel.
</p>

<!-- environment: exercise start embedded generator -->
<!-- environment block purpose: [[ environment=exercise ]] -->
<exercise>
<b>Exercise</b>
<p name="exercise">
<!-- TranslatingLineGenerator exercise ['exercise'] -->

  Add the commands 
<tt>MPI_Init</tt>
 and 
<tt>MPI_Finalize</tt>
  to your code. Put three different print statements in your code: one before the init,
  one between init and finalize, and one after the finalize. Again explain the output.
</p>

<p name="switchToTextMode">
  Run your program on a large scale, using a batch job.
  Where does the output go?
  Experiment with
<!-- environment: verbatim start embedded generator -->
</p>
<!-- environment block purpose: [[ environment=verbatim ]] -->
<verbatim>
<pre>
MY_MPIRUN_OPTIONS="-prepend-rank" ibrun yourprogram
</pre>
</verbatim>
<!-- environment: verbatim end embedded generator -->
</exercise>
<!-- environment: exercise end embedded generator -->
<!-- environment: answer start embedded generator -->
<!-- environment block purpose: [[ environment=answer ]] -->
<answer>


</answer>
<!-- environment: answer end embedded generator -->
<p name="switchToTextMode">

<!-- environment: remark start embedded generator -->
</p>
<!-- environment block purpose: [[ environment=remark ]] -->
<remark>
<b>Remark</b>
<p name="remark">
<!-- TranslatingLineGenerator remark ['remark'] -->
  For hybrid MPI-plus-threads programming there is also a call
<tt>MPI_Init_thread</tt>
. For that, see
  section&nbsp;
<a href="http://pages.tacc.utexas.edu/~eijkhout/pcse/html/mpi-hybrid.html#MPIsupportforthreading">13.1</a>
.
</p name="remark">
</remark>
<!-- environment: remark end embedded generator -->
<p name="switchToTextMode">

<h4><a id="AbortinganMPIrun">2.2.2.1</a> Aborting an MPI run</h4>
<p name=crumbs>
crumb trail:  > <a href="mpi-functional.html">mpi-functional</a> > <a href="mpi-functional.html#StartingandrunningMPIprocesses">Starting and running MPI processes</a> > <a href="mpi-functional.html#Initializationfinalization">Initialization / finalization</a> > <a href="mpi-functional.html#AbortinganMPIrun">Aborting an MPI run</a>
</p>
</p>

<p name="switchToTextMode">
Apart from 
<tt>MPI_Finalize</tt>
, which signals a successful
conclusion of the MPI run, an abnormal end to a run can be forced by
<div class="card">
  <div class="card-header" id="headingOne">
    <h5 class="mb-0">
      <button class="btn btn-link" data-toggle="collapse" data-target="#MPI_Abort" aria-expanded="false" aria-controls="MPI_Abort">
        Routine reference: MPI_Abort
      </button>
    </h5>
  </div>
  <div id="MPI_Abort" class="collapse">
  <pre>
Synopsis:
int MPI_Abort(MPI_Comm comm, int errorcode)

Input Parameters
comm : communicator of tasks to abort
errorcode : error code to return to invoking environment

Python:
MPI.Comm.Abort(self, int errorcode=0)

MPL:
void mpl::communicator::abort ( int ) const
</pre>
</div>
</div>
<i>MPI_Abort</i>
.
This stop execution on all processes associated with the communicator,
but many implementations will terminate all processes. The 
<tt>value</tt>
 parameter
is returned to the environment.
</p>

<p name="switchToTextMode">
\csnippetwithoutput{abortcode}{code/mpi/c}{return}
</p>

<h4><a id="Testingtheinitializedfinalizedstatus">2.2.2.2</a> Testing the initialized/finalized status</h4>
<p name=crumbs>
crumb trail:  > <a href="mpi-functional.html">mpi-functional</a> > <a href="mpi-functional.html#StartingandrunningMPIprocesses">Starting and running MPI processes</a> > <a href="mpi-functional.html#Initializationfinalization">Initialization / finalization</a> > <a href="mpi-functional.html#Testingtheinitializedfinalizedstatus">Testing the initialized/finalized status</a>
</p>
<p name="switchToTextMode">

The commandline arguments 
<tt>argc</tt>
 and 
<tt>argv</tt>
 are only guaranteed to
be passed to process zero, so the best way to pass commandline information
is by a broadcast (section&nbsp;
<a href="http://pages.tacc.utexas.edu/~eijkhout/pcse/html/mpi-collective.html#Broadcast">3.3.3</a>
).
</p>

<p name="switchToTextMode">
There are a few commands, such as
<tt>MPI_Get_processor_name</tt>
, that are allowed before
<tt>MPI_Init</tt>
.
</p>

<p name="switchToTextMode">
If MPI is used in a library, MPI can have already been initialized in a main program.
For this reason, one can test where 
<tt>MPI_Init</tt>
 has been called with
<div class="card">
  <div class="card-header" id="headingOne">
    <h5 class="mb-0">
      <button class="btn btn-link" data-toggle="collapse" data-target="#MPI_Initialized" aria-expanded="false" aria-controls="MPI_Initialized">
        Routine reference: MPI_Initialized
      </button>
    </h5>
  </div>
  <div id="MPI_Initialized" class="collapse">
  <pre>
C:
int MPI_Initialized(int *flag)

Fortran:
MPI_Initialized(flag, ierror)
LOGICAL, INTENT(OUT) :: flag
INTEGER, OPTIONAL, INTENT(OUT) :: ierror
</pre>
</div>
</div>
<i>MPI_Initialized</i>
.
</p>

<p name="switchToTextMode">
You can test whether 
<tt>MPI_Finalize</tt>
 has been called with
<div class="card">
  <div class="card-header" id="headingOne">
    <h5 class="mb-0">
      <button class="btn btn-link" data-toggle="collapse" data-target="#MPI_Finalized" aria-expanded="false" aria-controls="MPI_Finalized">
        Routine reference: MPI_Finalized
      </button>
    </h5>
  </div>
  <div id="MPI_Finalized" class="collapse">
  <pre>
C:
int MPI_Finalized( int *flag )

Fortran:
MPI_Finalized(flag, ierror)
LOGICAL, INTENT(OUT) :: flag
INTEGER, OPTIONAL, INTENT(OUT) :: ierror
</pre>
</div>
</div>
<i>MPI_Finalized</i>
.
</p>

<h4><a id="Informationabouttherun">2.2.2.3</a> Information about the run</h4>
<p name=crumbs>
crumb trail:  > <a href="mpi-functional.html">mpi-functional</a> > <a href="mpi-functional.html#StartingandrunningMPIprocesses">Starting and running MPI processes</a> > <a href="mpi-functional.html#Initializationfinalization">Initialization / finalization</a> > <a href="mpi-functional.html#Informationabouttherun">Information about the run</a>
</p>
<p name="switchToTextMode">

Once MPI has been initialized, the 
<tt>MPI_INFO_ENV</tt>
 object
contains a number of key/value pairs describing run-specific
information; see section&nbsp;
<a href="http://pages.tacc.utexas.edu/~eijkhout/pcse/html/mpi.html#Environmentinformation">15.1.1.1</a>
.
</p>

<h4><a id="Commandlinearguments">2.2.2.4</a> Commandline arguments</h4>
<p name=crumbs>
crumb trail:  > <a href="mpi-functional.html">mpi-functional</a> > <a href="mpi-functional.html#StartingandrunningMPIprocesses">Starting and running MPI processes</a> > <a href="mpi-functional.html#Initializationfinalization">Initialization / finalization</a> > <a href="mpi-functional.html#Commandlinearguments">Commandline arguments</a>
</p>
<p name="switchToTextMode">

The 
<tt>MPI_Init</tt>
 routines takes a reference to 
<tt>argc</tt>
and 
<tt>argv</tt>
 for the following reason: the 
<tt>MPI_Init</tt>
 calls
filters out the arguments to 
<i>mpirun</i>
 or 
<tt>mpiexec</tt>
,
thereby lowering the value of 
<tt>argc</tt>
 and elimitating some of the 
<tt>argv</tt>

arguments.
</p>

<p name="switchToTextMode">
On the other hand, the commandline arguments that are meant for 
<tt>mpiexec</tt>
wind up in the 
<tt>MPI_INFO_ENV</tt>
 object as a set of
key/value pairs; see section&nbsp;
<a href="http://pages.tacc.utexas.edu/~eijkhout/pcse/html/mpi.html#Infoobjects">15.1.1</a>
.
</p>

<p name="switchToTextMode">

<!-- TranslatingLineGenerator file ['file'] -->
</p>

<h2><a id="Processoridentification">2.3</a> Processor identification</h2>
<p name=crumbs>
crumb trail:  > <a href="mpi-functional.html">mpi-functional</a> > <a href="mpi-functional.html#Processoridentification">Processor identification</a>
</p>

<p name="switchToTextMode">

Since all processes in an MPI job are instantiations of the same executable,
you'd think that they all execute the exact same instructions,
which would not be terribly useful.
You will now learn how to distinguish
processes from each other, so that together they can start doing
useful work.
</p>

<h3><a id="Processorname">2.3.1</a> Processor name</h3>
<p name=crumbs>
crumb trail:  > <a href="mpi-functional.html">mpi-functional</a> > <a href="mpi-functional.html#Processoridentification">Processor identification</a> > <a href="mpi-functional.html#Processorname">Processor name</a>
</p>
<p name="switchToTextMode">

In the following exercise you will print out the hostname
of each MPI process
with
<div class="card">
  <div class="card-header" id="headingOne">
    <h5 class="mb-0">
      <button class="btn btn-link" data-toggle="collapse" data-target="#MPI_Get_processor_name" aria-expanded="false" aria-controls="MPI_Get_processor_name">
        Routine reference: MPI_Get_processor_name
      </button>
    </h5>
  </div>
  <div id="MPI_Get_processor_name" class="collapse">
  <pre>
C:
int MPI_Get_processor_name(char *name, int *resultlen)
name : buffer char[MPI_MAX_PROCESSOR_NAME]

Fortran:
MPI_Get_processor_name(name, resultlen, ierror)
CHARACTER(LEN=MPI_MAX_PROCESSOR_NAME), INTENT(OUT) :: name
INTEGER, INTENT(OUT) :: resultlen
INTEGER, OPTIONAL, INTENT(OUT) :: ierror

Python:
MPI.Get_processor_name()
</pre>
</div>
</div>
<i>MPI_Get_processor_name</i>
as a first way of distinguishing between processes.
This routine has a character buffer argument, which
needs to be allocated by you.
The length of the buffer is also passed,
and on return that parameter has the actually used length.
The maximum needed length is 
<tt>MPI_MAX_PROCESSOR_NAME</tt>
.
\csnippetwithoutput{procname}{examples/mpi/c}{procname}
(Underallocating the buffer will not lead to a runtime error.)
</p>

<!-- environment: exercise start embedded generator -->
<!-- environment block purpose: [[ environment=exercise ]] -->
<exercise>
<b>Exercise</b>
<p name="exercise">
<!-- TranslatingLineGenerator exercise ['exercise'] -->

  Use the command 
<tt>MPI_Get_processor_name</tt>
.
  Confirm that you are able to run a program that uses two different nodes.
</p>

<!-- environment: tacc start embedded generator -->
<!-- environment block purpose: [[ environment=tacc ]] -->
<tacc>

<p name="tacc">
<!-- TranslatingLineGenerator tacc ['tacc'] -->
    TACC nodes have a hostname 
<tt>cRRR-CNN</tt>
, where RRR is the rack number, C is the chassis
    number in the rack, and NN is the node number within the chassis. Communication
    is faster inside a rack than between racks!
</p name="tacc">

</tacc>
<!-- environment: tacc end embedded generator -->
</exercise>
<!-- environment: exercise end embedded generator -->
<p name="switchToTextMode">

<!-- environment: mplnote start embedded generator -->
</p>
<!-- environment block purpose: [[ environment=mplnote ]] -->
<remark>
<b>MPL note</b>
<!-- TranslatingLineGenerator mplnote ['mplnote'] -->
<p name="switchToTextMode">
  The 
<tt>processor_name</tt>
  returning a 
<tt>std::string</tt>
:
<!-- environment: lstlisting start embedded generator -->
</p>
<!-- environment block purpose: [[ environment=lstlisting ]] -->
<lstlisting>
<pre>
std::string mpl::environment::processor_name ();
</pre>
</lstlisting>
<!-- environment: lstlisting end embedded generator -->
<i>End of MPL note</i>
</remark>
<!-- environment: mplnote end embedded generator -->
<p name="switchToTextMode">

<h3><a id="Communicators">2.3.2</a> Communicators</h3>
<p name=crumbs>
crumb trail:  > <a href="mpi-functional.html">mpi-functional</a> > <a href="mpi-functional.html#Processoridentification">Processor identification</a> > <a href="mpi-functional.html#Communicators">Communicators</a>
</p>
</p>

<p name="switchToTextMode">
First we need to introduce the concept of
<i>communicator</i>
, which is an abstract description of a
group of processes. For now you only need to know about the existence
of the 
<tt>MPI_Comm</tt>
 data type, and that there is a
pre-defined communicator 
<tt>MPI_COMM_WORLD</tt>
 which
describes all the processes involved in your parallel run.
</p>

<p name="switchToTextMode">

In the procedural languages&nbsp;C,
a 
<i>communicator</i>

<!-- index -->
 is a 
<i>variable</i>

that is passed to most routines:
<!-- environment: lstlisting start embedded generator -->
</p>
<!-- environment block purpose: [[ environment=lstlisting ]] -->
<lstlisting>
<pre>
#include &lt;mpi.h&gt;
MPI_Comm comm = MPI_COMM_WORLD;
MPI_Send( /* stuff */ comm );
</pre>
</lstlisting>
<!-- environment: lstlisting end embedded generator -->
<p name="switchToTextMode">

<!-- environment: fortrannote start embedded generator -->
</p>
<!-- environment block purpose: [[ environment=fortrannote ]] -->
<remark>
<b>Fortran note</b>
<p name="remark">
<!-- TranslatingLineGenerator fortrannote ['fortrannote'] -->
  In Fortran, pre-2008 a communicator was an 
<i>opaque handle</i>
,
  stored in an 
<tt>Integer</tt>
. With 
<i>Fortran 2008</i>
,
  communicators are derived types:
<!-- environment: lstlisting start embedded generator -->
</p>
<!-- environment block purpose: [[ environment=lstlisting ]] -->
<lstlisting>
<pre>
use mpi_f098
Type(MPI_Comm} :: comm = MPI_COMM_WORLD
call MPI_Send( ... comm )
</pre>
</lstlisting>
<!-- environment: lstlisting end embedded generator -->
</remark>
<!-- environment: fortrannote end embedded generator -->
<p name="switchToTextMode">
{Communicator type}
</p>

<!-- environment: pythonnote start embedded generator -->
<!-- environment block purpose: [[ environment=pythonnote ]] -->
<remark>
<b>Python note</b>
<!-- TranslatingLineGenerator pythonnote ['pythonnote'] -->
<p name="switchToTextMode">
In object-oriented languages, a communicator is an
<i>object</i>
<!-- index -->
,
and rather than passing it to routines,
the routines are often methods of the communicator object:
<!-- environment: lstlisting start embedded generator -->
</p>
<!-- environment block purpose: [[ environment=lstlisting ]] -->
<lstlisting>
<pre>
from mpi4py import MPI
comm = MPI.COMM_WORLD
comm.Send( buffer, target )
</pre>
</lstlisting>
<!-- environment: lstlisting end embedded generator -->
</remark>
<!-- environment: pythonnote end embedded generator -->
<p name="switchToTextMode">

<!-- environment: mplnote start embedded generator -->
</p>
<!-- environment block purpose: [[ environment=mplnote ]] -->
<remark>
<b>MPL note</b>
<!-- TranslatingLineGenerator mplnote ['mplnote'] -->
<p name="switchToTextMode">
  The naive way of declaring a communicator would be:
<div class="card">
  <div class="card-header" id="headingOne">
    <h5 class="mb-0">
      <button class="btn btn-link" data-toggle="collapse" data-target="#mplcommcopy" aria-expanded="false" aria-controls="mplcommcopy">
        C++ Code: mplcommcopy
      </button>
    </h5>
  </div>
  <div id="mplcommcopy" class="collapse">
  <pre>
// commrank.cxx
mpl::communicator comm_world =
  mpl::environment::comm_world();
</pre>
</div>
</div>
  calling the predefined environment method 
<tt>comm_world</tt>
</p>

<p name="switchToTextMode">
  However, if the variable will always correspond to the world communicator,
  it is better to make it 
<tt>const</tt>
 and declare it to be a reference:
<div class="card">
  <div class="card-header" id="headingOne">
    <h5 class="mb-0">
      <button class="btn btn-link" data-toggle="collapse" data-target="#mplcommref" aria-expanded="false" aria-controls="mplcommref">
        C++ Code: mplcommref
      </button>
    </h5>
  </div>
  <div id="mplcommref" class="collapse">
  <pre>
const mpl::communicator &comm_world =
  mpl::environment::comm_world();
</pre>
</div>
</div>
<i>End of MPL note</i>
</remark>
<!-- environment: mplnote end embedded generator -->
<p name="switchToTextMode">

<!-- environment: mplnote start embedded generator -->
</p>
<!-- environment block purpose: [[ environment=mplnote ]] -->
<remark>
<b>MPL note</b>
<!-- TranslatingLineGenerator mplnote ['mplnote'] -->
<p name="switchToTextMode">
  The communicator class has its copy operator deleted;
  however, copy initialization exists:
<div class="card">
  <div class="card-header" id="headingOne">
    <h5 class="mb-0">
      <button class="btn btn-link" data-toggle="collapse" data-target="#mplcompare" aria-expanded="false" aria-controls="mplcompare">
        C++ Code: mplcompare
      </button>
    </h5>
  </div>
  <div id="mplcompare" class="collapse">
  <pre>
// commcompare.cxx
const mpl::communicator &comm =
  mpl::environment::comm_world();
cout &lt;&lt; "same: " &lt;&lt; boolalpha &lt;&lt; (comm==comm) &lt;&lt; endl;

mpl::communicator copy =
  mpl::environment::comm_world();
cout &lt;&lt; "copy: " &lt;&lt; boolalpha &lt;&lt; (comm==copy) &lt;&lt; endl;

mpl::communicator init = comm;
cout &lt;&lt; "init: " &lt;&lt; boolalpha &lt;&lt; (init==comm) &lt;&lt; endl;
</pre>
</div>
</div>
  (This outputs true/false/false respectively.)
</p>

<!-- environment: mplimpl start embedded generator -->
<!-- environment block purpose: [[ environment=mplimpl ]] -->
<remark>

<!-- TranslatingLineGenerator mplimpl ['mplimpl'] -->
<p name="switchToTextMode">
    The copy initializer performs an 
<tt>MPI_Comm_dup</tt>
.
</remark>
<!-- environment: mplimpl end embedded generator -->
<i>End of MPL note</i>
</remark>
<!-- environment: mplnote end embedded generator -->
<p name="switchToTextMode">

<!-- environment: mplnote start embedded generator -->
</p>
<!-- environment block purpose: [[ environment=mplnote ]] -->
<remark>
<b>MPL note</b>
<!-- TranslatingLineGenerator mplnote ['mplnote'] -->
<p name="switchToTextMode">
  Pass communicators by reference to avoid communicator duplication:
<div class="card">
  <div class="card-header" id="headingOne">
    <h5 class="mb-0">
      <button class="btn btn-link" data-toggle="collapse" data-target="#mplcommpass" aria-expanded="false" aria-controls="mplcommpass">
        C++ Code: mplcommpass
      </button>
    </h5>
  </div>
  <div id="mplcommpass" class="collapse">
  <pre>
// commpass.cxx
// BAD! this does a MPI_Comm_dup.
void comm_val( const mpl::communicator comm );

// correct!
void comm_ref( const mpl::communicator &comm );
</pre>
</div>
</div>
<i>End of MPL note</i>
</remark>
<!-- environment: mplnote end embedded generator -->
<p name="switchToTextMode">

You will
learn much more about communicators in chapter&nbsp;
<a href="http://pages.tacc.utexas.edu/~eijkhout/pcse/html/mpi-comm.html">MPI topic: Communicators</a>
.
</p>

<h3><a id="Processandcommunicatorproperties:rankandsize">2.3.3</a> Process and communicator properties: rank and size</h3>
<p name=crumbs>
crumb trail:  > <a href="mpi-functional.html">mpi-functional</a> > <a href="mpi-functional.html#Processoridentification">Processor identification</a> > <a href="mpi-functional.html#Processandcommunicatorproperties:rankandsize">Process and communicator properties: rank and size</a>
</p>
<p name="switchToTextMode">

To distinguish between processes in a communicator, MPI provides two calls
<!-- environment: enumerate start embedded generator -->
</p>
<!-- environment block purpose: [[ environment=enumerate ]] -->
<enumerate>
<ol>
<!-- TranslatingLineGenerator enumerate ['enumerate'] -->
<li>
<div class="card">
  <div class="card-header" id="headingOne">
    <h5 class="mb-0">
      <button class="btn btn-link" data-toggle="collapse" data-target="#MPI_Comm_size" aria-expanded="false" aria-controls="MPI_Comm_size">
        Routine reference: MPI_Comm_size
      </button>
    </h5>
  </div>
  <div id="MPI_Comm_size" class="collapse">
  <pre>
Semantics:
MPI_COMM_SIZE(comm, size)
IN comm: communicator (handle)
OUT size: number of processes in the group of comm (integer)

C:
int MPI_Comm_size(MPI_Comm comm, int *size)

Fortran:
MPI_Comm_size(comm, size, ierror)
TYPE(MPI_Comm), INTENT(IN) :: comm
INTEGER, INTENT(OUT) :: size
INTEGER, OPTIONAL, INTENT(OUT) :: ierror

Python:
MPI.Comm.Get_size(self)

MPL:
int mpl::communicator::size ( ) const
</pre>
</div>
</div>
<i>MPI_Comm_size</i>
 reports how many processes there are in all; and
<li>
<div class="card">
  <div class="card-header" id="headingOne">
    <h5 class="mb-0">
      <button class="btn btn-link" data-toggle="collapse" data-target="#MPI_Comm_rank" aria-expanded="false" aria-controls="MPI_Comm_rank">
        Routine reference: MPI_Comm_rank
      </button>
    </h5>
  </div>
  <div id="MPI_Comm_rank" class="collapse">
  <pre>
Semantics:
MPI_COMM_RANK(comm, rank)
IN comm: communicator (handle)
OUT rank: rank of the calling process in group of comm (integer)

C:
int MPI_Comm_rank(MPI_Comm comm, int *rank)

Fortran:
MPI_Comm_rank(comm, rank, ierror)
TYPE(MPI_Comm), INTENT(IN) :: comm
INTEGER, INTENT(OUT) :: rank
INTEGER, OPTIONAL, INTENT(OUT) :: ierror

Python:
MPI.Comm.Get_rank(self)

MPL:
int mpl::communicator::rank ( ) const
</pre>
</div>
</div>
<i>MPI_Comm_rank</i>
 states what the number of the
  process is that calls this routine.
</ol>
</enumerate>
<!-- environment: enumerate end embedded generator -->
<p name="switchToTextMode">

If every process executes the 
<tt>MPI_Comm_size</tt>
 call, they all get the
same result, namely the total number of processes in your run.
On the
other hand, if every process executes 
<tt>MPI_Comm_rank</tt>
, they all get
a different result, namely their own unique number, an integer in the
range from zero to the number of processes minus&nbsp;1.
See figure&nbsp;
2.5
.
<!-- environment: figure start embedded generator -->
</p>
<!-- environment block purpose: [[ environment=figure ]] -->
<figure>
<float mode=figure>
<!-- TranslatingLineGenerator figure ['figure'] -->
<img src="graphics/rank-parallel.png" width=800></img>
<p name="caption">
FIGURE 2.5: Parallel program that prints process rank
</p>

</float>
</figure>
<!-- environment: figure end embedded generator -->
<p name="switchToTextMode">
In other words, each process can find out `I&nbsp;am process&nbsp;5
out of a total of&nbsp;20'.
</p>

<!-- exercise start: ex-rank.txt -->
<script type="text/plain" id="mpiRankCode">
/****************************************************************
 ****
 **** This program file is part of the book
 **** `Parallel programming with MPI and OpenMP'
 **** by Victor Eijkhout, eijkhout@tacc.utexas.edu
 ****
 **** copyright Victor Eijkhout 2012-8
 ****
 **** MPI Exercise for the use of Comm_rank/size
 ****
 ****************************************************************/

#include <stdlib.h>
#include <stdio.h>
#include <mpi.h>

int main(int argc,char **argv) {

  MPI_Comm comm = MPI_COMM_WORLD;
  int nprocs, procno;

  MPI_Init(&argc,&argv);

  // Exercise part 1:
  // -- Use the routine
  //    MPI_Comm_size and MPI_Comm_rank
  // -- Let each processor print out a message like
  //    "Hello from processor 7 out of 12"
  //    reporting its number and the total number.
/**** your code here ****/

  // Exercise part 2:
  // -- let only processs zero print out
  //    "There are 16 processes"
  //    reporting only the total number
/**** your code here ****/

  MPI_Finalize();
  return 0;
}
</script>
<br/>

<div id="mpiRankEdDiv"></div>
<!-- EX-CHANGE: change the id and the contained code to fit the example: -->
<script type="application/javascript">
  // Some settings for the editor; currently width and height
  var edSettings = new CCRS.Ed.Settings(500, 300);

  // Now configure the dynamic parts of the editor logic
  // by creating a list of Actions; these actions add buttons
  // that take input from the editor and store it in a file,
  // as well as a command to run on the host on the configured
  // output file.

  // EX-CHANGE: name of the function should be changed per example
  var mpiRankEditorActions = function (aceEd, jobId) {
    var makeExecFile = CCRS.functize0(function () {
      // EX-CHANGE: Name the file will be on disk:
      var editFile = "rank.c";
      var fileContents = {};
      fileContents[editFile] = aceEd.getValue();
      // CHANGE: Declare a new Job type (ExecFile):
      //         Most uses for now will be editing files, so keeping
      //         ExecFile here is probably want you want. See the OneShot
      //         example above for a different type of example
      //         (single command, no file). More options to come.
      var ef = new CCRS.ExecFile(
        jobId,
        // EX-CHANGE: command to run for this action
        "mpicc " + editFile + " -o rank && mpirun --oversubscribe -np 8 rank",
        // CHANGE: metadata above, usually don't need to change for
        //         each exercise, but may have a few different
        //         definitions to select from depending on exercise and
        //         container type, etc.
        mpiExampleMeta,
        CCRS.makeFileContents(fileContents)
      );
      return CCRS.listize([ef]);
    });
    // EX-CHANGE: Button text:
    var runButtonTxt = "Compile and run";
    var runAction = CCRS.functize0(function () {
      return CCRS.Ed.Act(
        Tags.b(runButtonTxt),
        runButtonTxt,
        makeExecFile,
        // CHANGE: this must match the type of job
        //         (the variable 'ef' above).
        CCRS.jobExecFile
      );
    });
    return CCRS.listize([runAction]);
  };
  var mpiRankEd = CCRS.makeEditor(
    // EX-CHANGE - this sould be the function defined above.
    mpiRankEditorActions,
    CCRS.makeJobId(),
    // EX-CHANGE: a name for the editor used internally by ace editor
    "mpi-rank-ace-example",
    // CHANGE: language type used by the editor. See a listing at:
    //         https://github.com/ajaxorg/ace/tree/master/lib/ace/mode
    "c_cpp",
    edSettings,
    // EX-CHANGE: the script ID containing the example code, defined above
    document.getElementById("mpiRankCode").innerText,
    // EX-CHANGE: the div ID where the example will be rendered,
    //            defined in this page
    document.getElementById("mpiRankEdDiv")
  );
</script>

<!-- exercise end ex-rank.txt -->
<p name="switchToTextMode">

<!-- environment: exercise start embedded generator -->
</p>
<!-- environment block purpose: [[ environment=exercise ]] -->
<exercise>
<b>Exercise</b>
<p name="exercise">
<!-- TranslatingLineGenerator exercise ['exercise'] -->

  Write a program where each process prints out a message
  reporting its number, and how many processes there are:
<!-- environment: verbatim start embedded generator -->
</p>
<!-- environment block purpose: [[ environment=verbatim ]] -->
<verbatim>
<pre>
Hello from process 2 out of 5!
</pre>
</verbatim>
<!-- environment: verbatim end embedded generator -->
<p name="switchToTextMode">

  Write a second version of this program, where each process opens a
  unique file and writes to it. 
<i>On some clusters this may not be     advisable if you have large numbers of processors, since it can     overload the file system.</i>

<!-- skeleton start: commrank -->
<button id="runBtncommrank">Compile and run commrank</button>
<div id="editorDivcommrank" 
     style="height:125px;border:1px solid black; 
     resize:vertical; overflow: hidden;"></div>
<pre id="outputPrecommrank"></pre>
<script name="defSkeletoncommrank">
let examplecommrank = new Example(
    "runBtncommrank", "editorDivcommrank", "outputPrecommrank", 
    "skeletons/commrank.c", "commrank.c",
    "mpicc commrank.c && mpiexec -n 4 ./a.out" );
examplecommrank.initialize();
</script>
<!-- skeleton end: commrank -->
</p name="exercise">
</exercise>
<!-- environment: exercise end embedded generator -->
<!-- environment: answer start embedded generator -->
<!-- environment block purpose: [[ environment=answer ]] -->
<answer>


</answer>
<!-- environment: answer end embedded generator -->
<!-- environment: exercise start embedded generator -->
<!-- environment block purpose: [[ environment=exercise ]] -->
<exercise>
<b>Exercise</b>
<p name="exercise">
<!-- TranslatingLineGenerator exercise ['exercise'] -->

  Write a program where only the process with number zero
  reports on how many processes there are in total.
</p name="exercise">
</exercise>
<!-- environment: exercise end embedded generator -->
<p name="switchToTextMode">

In object-oriented approaches to MPI,
that is, 
<tt>mpi4py</tt>
 and 
<i>MPL</i>
,
the 
<tt>MPI_Comm_rank</tt>
 and 
<tt>MPI_Comm_size</tt>
routines are methods of the communicator class:
</p>

<!-- environment: pythonnote start embedded generator -->
<!-- environment block purpose: [[ environment=pythonnote ]] -->
<remark>
<b>Python note</b>
<!-- TranslatingLineGenerator pythonnote ['pythonnote'] -->
<p name="switchToTextMode">
  Rank and size are methods of the communicator object.
  Note that their names are slightly different from the MPI standard names.
<!-- environment: lstlisting start embedded generator -->
</p>
<!-- environment block purpose: [[ environment=lstlisting ]] -->
<lstlisting>
<pre>
comm = MPI.COMM_WORLD
procid = comm.Get_rank()
nprocs = comm.Get_size()
</pre>
</lstlisting>
<!-- environment: lstlisting end embedded generator -->
</remark>
<!-- environment: pythonnote end embedded generator -->
<p name="switchToTextMode">

<!-- environment: mplnote start embedded generator -->
</p>
<!-- environment block purpose: [[ environment=mplnote ]] -->
<remark>
<b>MPL note</b>
<!-- TranslatingLineGenerator mplnote ['mplnote'] -->
  The rank of a process (by  <tt>mpl::communicator::</tt> 
<tt>rank</tt>
  the size of a communicator (by  <tt>mpl::communicator::</tt> 
<tt>size</tt>
<p name="switchToTextMode">
  are both methods of the 
<tt>communicator</tt>
<!-- environment: lstlisting start embedded generator -->
</p>
<!-- environment block purpose: [[ environment=lstlisting ]] -->
<lstlisting>
<pre>
const mpl::communicator &comm_world =
    mpl::environment::comm_world();
int procid = comm_world.rank();
int nprocs = comm_world.size();
</pre>
</lstlisting>
<!-- environment: lstlisting end embedded generator -->
<i>End of MPL note</i>
</remark>
<!-- environment: mplnote end embedded generator -->
<p name="switchToTextMode">

<h2><a id="Functionalparallelism">2.4</a> Functional parallelism</h2>
<p name=crumbs>
crumb trail:  > <a href="mpi-functional.html">mpi-functional</a> > <a href="mpi-functional.html#Functionalparallelism">Functional parallelism</a>
</p>
</p>

<p name="switchToTextMode">
Now that processes can distinguish themselves from each other,
they can decide to engage in different activities.
In an extreme case you could have a code that looks like
<!-- environment: lstlisting start embedded generator -->
</p>
<!-- environment block purpose: [[ environment=lstlisting ]] -->
<lstlisting>
<pre>
// climate simulation:
if (procid==0)
  earth_model();
else if (procid=1)
  sea_model();
else
  air_model();
</pre>
</lstlisting>
<!-- environment: lstlisting end embedded generator -->
<p name="switchToTextMode">
Practice is a little more complicated than this. But we will start
exploring this notion of processes deciding on their activity
based on their process number.
</p>

<p name="switchToTextMode">
Being able to tell processes apart is already enough to write some
applications, without knowing any other MPI.
We will look at a simple parallel search algorithm:
based on its rank, a processor can find its section of
a search space.  For instance, in 
<i>Monte Carlo codes</i>
 a
large number of random samples is generated and some computation
performed on each. (This particular example requires each MPI process
to run an independent random number generator, which is not entirely
trivial.)
</p>

<!-- environment: exercise start embedded generator -->
<!-- environment block purpose: [[ environment=exercise ]] -->
<exercise>
<b>Exercise</b>
<p name="exercise">
<!-- TranslatingLineGenerator exercise ['exercise'] -->

  Is the number $N=2,000,000,111$ prime?  Let each process test a
  disjoint set of integers, and print out any factor they find.  You don't
  have to test all integers&nbsp;$&lt;N$: any factor is at
  most&nbsp;$\sqrt N\approx 45,200$.
</p>

<p name="switchToTextMode">
  (Hint: 
 <tt>i%0</tt>  probably gives a runtime error.)
</p>

<p name="switchToTextMode">
  Can you find more than one solution?
<!-- skeleton start: prime -->
<button id="runBtnprime">Compile and run prime</button>
<div id="editorDivprime" 
     style="height:125px;border:1px solid black; 
     resize:vertical; overflow: hidden;"></div>
<pre id="outputPreprime"></pre>
<script name="defSkeletonprime">
let exampleprime = new Example(
    "runBtnprime", "editorDivprime", "outputPreprime", 
    "skeletons/prime.c", "prime.c",
    "mpicc prime.c && mpiexec -n 4 ./a.out" );
exampleprime.initialize();
</script>
<!-- skeleton end: prime -->
</p name="exercise">
</exercise>
<!-- environment: exercise end embedded generator -->
<!-- environment: answer start embedded generator -->
<!-- environment block purpose: [[ environment=answer ]] -->
<answer>


</answer>
<!-- environment: answer end embedded generator -->
<p name="switchToTextMode">

<!-- environment: remark start embedded generator -->
</p>
<!-- environment block purpose: [[ environment=remark ]] -->
<remark>
<b>Remark</b>
<p name="remark">
<!-- TranslatingLineGenerator remark ['remark'] -->
  Normally, we expect parallel algorithms to be faster than sequential.
  Now consider the above exercise. Suppose the number we are testing
  is divisible by some small prime number, but every process has a
  large block of numbers to test. In that case the sequential algorithm would
  have been faster than the parallel one. Food for thought.
</p name="remark">
</remark>
<!-- environment: remark end embedded generator -->
<p name="switchToTextMode">

As another example, in 
<i>Boolean satisfiability</i>
 problems
a number of points in a search space needs to be evaluated. Knowing
a process's rank is enough to let it generate its own portion of the
search space. The computation of the 
<i>Mandelbrot set</i>
 can
also be considered as a case of functional parallelism. However, the
image that is constructed is data that needs to be kept on one
processor, which breaks the symmetry of the parallel run.
</p>

<p name="switchToTextMode">
Of course, at the end of a functionally parallel run you need to
summarize the results, for instance printing out some total.
The mechanisms for that you will learn next.
</p>

<h2><a id="Distributedcomputinganddistributeddata">2.5</a> Distributed computing and distributed data</h2>
<p name=crumbs>
crumb trail:  > <a href="mpi-functional.html">mpi-functional</a> > <a href="mpi-functional.html#Distributedcomputinganddistributeddata">Distributed computing and distributed data</a>
</p>

<p name="switchToTextMode">

One reason for using MPI is that sometimes you need to work on
a single object,
say a vector or a matrix,
with a  data size larger than can fit in the memory of a single processor.
With distributed memory, each processor then gets a part
of the whole data structure and only works on that.
</p>

<p name="switchToTextMode">
So let's say we have a large array, and we want to
distribute the data over the processors.
That means that, with 
<tt>p</tt>
 processes and 
<tt>n</tt>
&nbsp;elements
per processor, we have a total of $\mathtt{n}\cdot\mathtt{p}$
elements.
</p>

<!-- environment: figure start embedded generator -->
<!-- environment block purpose: [[ environment=figure ]] -->
<figure>
<float mode=figure>
<!-- TranslatingLineGenerator figure ['figure'] -->
<img src="graphics/mpi-array.jpeg" width=800></img>
<p name="caption">
FIGURE 2.6: Local parts of a distributed array
</p>

</float>
</figure>
<!-- environment: figure end embedded generator -->
<p name="switchToTextMode">

We sometimes say that 
<tt>data</tt>
 is the local part
of a 
<i>distributed array</i>
 with a total size of
$\mathtt{n}\cdot\mathtt{p}$
elements.
However, this array only exists
conceptually: each processor has an array with lowest index zero,
and you have to translate that yourself to an index in the global
array.
In other words, you have to write your code in such a way that
it acts like you're working with a large array that is distributed
over the processors, while
actually manipulating only the local arrays on the processors.
</p>

<p name="switchToTextMode">
Your typical code then looks like
</p>

<!-- environment: lstlisting start embedded generator -->
<!-- environment block purpose: [[ environment=lstlisting ]] -->
<lstlisting>
<pre>
int myfirst = .....;
for (int ilocal=0; ilocal&lt;nlocal; ilocal++) {
   int iglobal = myfirst+ilocal;
   array[ilocal] = f(iglobal);
}
</pre>
</lstlisting>
<!-- environment: lstlisting end embedded generator -->
<p name="switchToTextMode">

<!-- environment: exercise start embedded generator -->
</p>
<!-- environment block purpose: [[ environment=exercise ]] -->
<exercise>
<b>Exercise</b>
<p name="exercise">
<!-- TranslatingLineGenerator exercise ['exercise'] -->

  Allocate on each process an array:
<!-- environment: lstlisting start embedded generator -->
</p>
<!-- environment block purpose: [[ environment=lstlisting ]] -->
<lstlisting>
<pre>
int my_ints[10];
</pre>
</lstlisting>
<!-- environment: lstlisting end embedded generator -->
<p name="switchToTextMode">
and fill it so that process&nbsp;0 has the integers $0\cdots 9$, process&nbsp;1 has $10\cdots 19$,
et cetera.
</p>

<p name="switchToTextMode">
It may be hard to print the output in a non-messy way.
</p name="exercise">
</exercise>
<!-- environment: exercise end embedded generator -->
<p name="switchToTextMode">

If the array size is not perfectly divisible by the number of processors,
we have to come up with a division that is uneven, but not too much.
You could for instance, write
</p>

<!-- environment: lstlisting start embedded generator -->
<!-- environment block purpose: [[ environment=lstlisting ]] -->
<lstlisting>
<pre>
int Nglobal, // is something large
    Nlocal = Nglobal/ntids,
    excess = Nglobal%ntids;
if (mytid==ntids-1)
  Nlocal += excess;
</pre>
</lstlisting>
<!-- environment: lstlisting end embedded generator -->
<p name="switchToTextMode">

<!-- environment: exercise start embedded generator -->
</p>
<!-- environment block purpose: [[ environment=exercise ]] -->
<exercise>
<b>Exercise</b>
<p name="exercise">
<!-- TranslatingLineGenerator exercise ['exercise'] -->
  Argue that this strategy is not optimal. Can you come up with a
  better distribution?
  Load balancing is further discussed in&nbsp;
<i>Eijkhout:IntroHPC</i>
.
</p name="exercise">
</exercise>
<!-- environment: exercise end embedded generator -->
<p name="switchToTextMode">

<!-- environment: comment start embedded generator -->
</p>
<!-- environment block purpose: [[ environment=comment ]] -->
<comment>


</comment>
<!-- environment: comment end embedded generator -->
<p name="switchToTextMode">

<h2><a id="Reviewquestions">2.6</a> Review questions</h2>
<p name=crumbs>
crumb trail:  > <a href="mpi-functional.html">mpi-functional</a> > <a href="mpi-functional.html#Reviewquestions">Review questions</a>
</p>
</p>

<p name="switchToTextMode">
For all true/false questions, if you answer that a statement is false,
give a one-line explanation.
</p>

<!-- environment: exercise start embedded generator -->
<!-- environment block purpose: [[ environment=exercise ]] -->
<exercise>
<b>Exercise</b>
<p name="exercise">
<!-- TranslatingLineGenerator exercise ['exercise'] -->

  True or false: 
<tt>mpicc</tt>
 is a compiler.
</p name="exercise">
</exercise>
<!-- environment: exercise end embedded generator -->
<!-- environment: answer start embedded generator -->
<!-- environment block purpose: [[ environment=answer ]] -->
<answer>


</answer>
<!-- environment: answer end embedded generator -->
<p name="switchToTextMode">

<!-- environment: exercise start embedded generator -->
</p>
<!-- environment block purpose: [[ environment=exercise ]] -->
<exercise>
<b>Exercise</b>
<p name="exercise">
<!-- TranslatingLineGenerator exercise ['exercise'] -->

  T/F?
<!-- environment: enumerate start embedded generator -->
</p>
<!-- environment block purpose: [[ environment=enumerate ]] -->
<enumerate>
<ol>
<!-- TranslatingLineGenerator enumerate ['enumerate'] -->
<li>
In C, the result of 
<tt>MPI_Comm_rank</tt>
 is a number
    from zero to number-of-processes-minus-one, inclusive.
<li>
In Fortran, the result of 
<tt>MPI_Comm_rank</tt>
 is a number
    from one to number-of-processes, inclusive.
</ol>
</enumerate>
<!-- environment: enumerate end embedded generator -->
</exercise>
<!-- environment: exercise end embedded generator -->
<p name="switchToTextMode">

<!-- environment: exercise start embedded generator -->
</p>
<!-- environment block purpose: [[ environment=exercise ]] -->
<exercise>
<b>Exercise</b>
<p name="exercise">
<!-- TranslatingLineGenerator exercise ['exercise'] -->
  What is the function of a hostfile?
</p name="exercise">
</exercise>
<!-- environment: exercise end embedded generator -->
<!-- environment: answer start embedded generator -->
<!-- environment block purpose: [[ environment=answer ]] -->
<answer>


</answer>
<!-- environment: answer end embedded generator -->
<p name="switchToTextMode">

\begin{pcse}
<!-- environment: exercise start embedded generator -->
</p>
<!-- environment block purpose: [[ environment=exercise ]] -->
<exercise>
<b>Exercise</b>
<p name="exercise">
<!-- TranslatingLineGenerator exercise ['exercise'] -->
    An architecture is called `symmetric' or `uniform' if the
    relation between any pair of processes is essentially the same.
    In what way are MPI processes run on stampede symmetric; in what way
    not?
</p name="exercise">
</exercise>
<!-- environment: exercise end embedded generator -->
<!-- environment: answer start embedded generator -->
<!-- environment block purpose: [[ environment=answer ]] -->
<answer>


</answer>
<!-- environment: answer end embedded generator -->
<p name="switchToTextMode">
\end{pcse}
</p>

</div>
<a href="index.html">Back to Table of Contents</a>
