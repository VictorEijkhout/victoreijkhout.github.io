<html>
<head>
<link href="ihpsc.css" rel="stylesheet" type="text/css">
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/css/bootstrap.min.css" integrity="sha384-Gn5384xqQ1aoWXA+058RXPxPg6fy4IWvTNh0E263XmFcJlSAwiGgFAW/dAiS6JXm" crossorigin="anonymous">

<script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js">
    </script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.12.9/umd/popper.min.js" integrity="sha384-ApNbgh9B+Y1QKtv3Rn7W3mgPxhU9K/ScQsAP7hUibX39j7fakFPskvXusvfa0b4Q" crossorigin="anonymous">
    </script>

<script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/js/bootstrap.min.js" integrity="sha384-JZR6Spejh4U02d8jOt6vLEHfe/JQGiRRSQQxSfFWpi1MquVdAyjUar5+76PVCmYl" crossorigin="anonymous"></script>

<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {inlineMath: [['$','$']]}
  });
  MathJax.Hub.Config({
    TeX: { equationNumbers: { autoNumber: "AMS" } }
  });
</script>

<link rel="stylesheet"
      href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.13.1/styles/default.min.css">
  <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.13.1/highlight.min.js"></script>
  <script>hljs.initHighlightingOnLoad();</script>
</head>

<script src=https://ccrs.cac.cornell.edu:8443/client.0.2.js></script>
<script id="script">
class Example {
  constructor(buttonID, editorID, outputID, sourceFile, fileName, commandStr) {
    this.buttonID = buttonID;
    this.editorID = editorID;
    this.outputID = outputID;
    this.sourceFile = sourceFile;
    this.fileName = fileName;
    this.commandStr = commandStr;
  }
    
  async display(results, object) {
    if (results.stdout.length > 0)
      document.getElementById(object.outputID).textContent = results.stdout;
    else
      document.getElementById(object.outputID).textContent = results.stderr;
  }

  async initialize() {
    this.editor = await MonacoEditorFileSource.create(this.editorID);
    this.editor.setTextFromFile(this.sourceFile);
    this.job = await Job.create(JobType.MPI);
    this.command = new CommandWithFiles(this.job, this.commandStr);
    this.command.addFileSource(this.editor, this.fileName);
    this.trigger = new ButtonTrigger(this.command, this.display, this.buttonID, this);
    document.getElementById(this.buttonID).disabled = false;
  }
}
</script>
<style></style>

<div class="container">
  <div class="row">
    <div class="col-12">
      <div class="pagehead">
        <h1>Sycl, OneAPI, DPC++</h1>
        <h5>Experimental html version of downloadable textbook, see http://www.tacc.utexas.edu/~eijkhout/istc/istc.html</h5>
      </div>
    </div>
  </div>
  <div>


\[
\newcommand\inv{^{-1}}\newcommand\invt{^{-t}}
\newcommand\bbP{\mathbb{P}}
\newcommand\bbR{\mathbb{R}}
\newcommand\defined{
  \mathrel{\lower 5pt \hbox{${\equiv\atop\mathrm{\scriptstyle D}}$}}}
\]


42.1 : <a href="dpcpp.html#Logistics">Logistics</a><br>
42.2 : <a href="dpcpp.html#Platformsanddevices">Platforms and devices</a><br>
42.3 : <a href="dpcpp.html#Queues">Queues</a><br>
42.3.1 : <a href="dpcpp.html#Deviceselectors">Device selectors</a><br>
42.3.2 : <a href="dpcpp.html#Queueexecution">Queue execution</a><br>
42.3.3 : <a href="dpcpp.html#Kernelordering">Kernel ordering</a><br>
42.4 : <a href="dpcpp.html#Kernels">Kernels</a><br>
42.5 : <a href="dpcpp.html#Paralleloperations">Parallel operations</a><br>
42.5.1 : <a href="dpcpp.html#Loops">Loops</a><br>
42.5.1.1 : <a href="dpcpp.html#Loopbounds:ranges">Loop bounds: ranges</a><br>
42.5.1.2 : <a href="dpcpp.html#Loopindices">Loop indices</a><br>
42.5.1.3 : <a href="dpcpp.html#Multi-dimensionalindexing">Multi-dimensional indexing</a><br>
42.5.2 : <a href="dpcpp.html#Taskdependencies">Task dependencies</a><br>
42.5.3 : <a href="dpcpp.html#Raceconditions">Race conditions</a><br>
42.5.4 : <a href="dpcpp.html#Reductions">Reductions</a><br>
42.6 : <a href="dpcpp.html#Memoryaccess">Memory access</a><br>
42.6.1 : <a href="dpcpp.html#Unifiedsharedmemory">Unified shared memory</a><br>
42.6.2 : <a href="dpcpp.html#Buffersandaccessors">Buffers and accessors</a><br>
42.6.3 : <a href="dpcpp.html#Querying">Querying</a><br>
42.7 : <a href="dpcpp.html#Paralleloutput">Parallel output</a><br>
42.8 : <a href="dpcpp.html#DPCPPextensions">DPCPP extensions</a><br>
42.9 : <a href="dpcpp.html#Inteldevcloudnotes">Intel devcloud notes</a><br>
42.10 : <a href="dpcpp.html#Examples">Examples</a><br>
42.10.1 : <a href="dpcpp.html#Kernelsinaloop">Kernels in a loop</a><br>
42.10.2 : <a href="dpcpp.html#Stencilcomputations">Stencil computations</a><br>
<a href="index.html">Back to Table of Contents</a>
<h1>42 Sycl, OneAPI, DPC++</h1>
<!-- TranslatingLineGenerator file ['file'] -->
</p>

<p name="switchToTextMode">
This chapter explains the basic concepts of Sycl/Dpc++,
and helps you get
started on running your first program.
</p>

<!-- environment: itemize start embedded generator -->
<!-- environment block purpose: [[ environment=itemize ]] -->
<itemize>
<ul>
<!-- TranslatingLineGenerator itemize ['itemize'] -->
<li>
<i>SYCL</i>
 is a C++-based language for portable parallel programming.
<li>
<i>DPCPP</i>
 is Intel's extension of Sycl.
<li>
<i>OneAPI</i>
 is Intel's compiler suite,
  which contains the 
<span title="acronym" ><i>DPCPP</i></span>
 compiler.
</ul>
</itemize>
<!-- environment: itemize end embedded generator -->
<p name="switchToTextMode">

\begin{dpcppnote}
  The various Intel extensions are listed here:
  
<a href=https://spec.oneapi.com/versions/latest/elements/dpcpp/source/index.html#extensions-table>https://spec.oneapi.com/versions/latest/elements/dpcpp/source/index.html#extensions-table</a>

\end{dpcppnote}
</p>

<h2><a id="Logistics">42.1</a> Logistics</h2>
<p name=crumbs>
crumb trail:  > <a href="dpcpp.html">dpcpp</a> > <a href="dpcpp.html#Logistics">Logistics</a>
</p>
<p name="switchToTextMode">

Headers:
<!-- environment: lstlisting start embedded generator -->
</p>
<!-- environment block purpose: [[ environment=lstlisting ]] -->
<lstlisting>
<pre>
#include &lt;CL/sycl.hpp&gt;
</pre>
</lstlisting>
<!-- environment: lstlisting end embedded generator -->
<p name="switchToTextMode">

You can now include namespace, but with care!
If you use
<!-- environment: lstlisting start embedded generator -->
</p>
<!-- environment block purpose: [[ environment=lstlisting ]] -->
<lstlisting>
<pre>
using namespace cl;
</pre>
</lstlisting>
<!-- environment: lstlisting end embedded generator -->
you have to prefix all SYCL class with  <tt>sycl::</tt> ,
<p name="switchToTextMode">
which is a bit of a bother.
However, if you use
<!-- environment: lstlisting start embedded generator -->
</p>
<!-- environment block purpose: [[ environment=lstlisting ]] -->
<lstlisting>
<pre>
using namespace cl::sycl;
</pre>
</lstlisting>
<!-- environment: lstlisting end embedded generator -->
<p name="switchToTextMode">
you run into the fact that SYCL has its own versions of many 
<span title="acronym" ><i>STL</i></span>
commands, and so you will get name collisions.
The most obvious example is that
the  <tt>cl::sycl</tt>  name space has its own versions of \n{cout} and \n{endl}.
Therefore you have to use explicitly \lstinline+std::cout+ and  <tt>std::end</tt> .
Using the wrong I/O will cause tons of inscrutable error messages.
Additionally, SYCL has its own version of 
<tt>free</tt>
,
and of several math routines.
</p>

<p name="switchToTextMode">
\begin{dpcppnote}
<!-- environment: lstlisting start embedded generator -->
</p>
<!-- environment block purpose: [[ environment=lstlisting ]] -->
<lstlisting>
<pre>
    using namespace sycl;
</pre>
</lstlisting>
<!-- environment: lstlisting end embedded generator -->
<p name="switchToTextMode">
\end{dpcppnote}
</p>

<h2><a id="Platformsanddevices">42.2</a> Platforms and devices</h2>
<p name=crumbs>
crumb trail:  > <a href="dpcpp.html">dpcpp</a> > <a href="dpcpp.html#Platformsanddevices">Platforms and devices</a>
</p>
<p name="switchToTextMode">

Since 
<span title="acronym" ><i>DPCPP</i></span>
 is cross-platform, we first need to discovers
the devices.
</p>

<p name="switchToTextMode">
First we list the platforms:
<div class="card">
  <div class="card-header" id="headingOne">
    <h5 class="mb-0">
      <button class="btn btn-link" data-toggle="collapse" data-target="#dpcppplatforms" aria-expanded="false" aria-controls="dpcppplatforms">
        C++ Code: dpcppplatforms
      </button>
    </h5>
  </div>
  <div id="dpcppplatforms" class="collapse">
  <pre>
// devices.cxx
std::vector&lt;sycl::platform&gt; platforms = sycl::platform::get_platforms();
for (const auto &plat : platforms) {
// get_info is a template. So we pass the type as an `arguments`.
  std::cout &lt;&lt; "Platform: "
            &lt;&lt; plat.get_info&lt;sycl::info::platform::name&gt;() &lt;&lt; " "
            &lt;&lt; plat.get_info&lt;sycl::info::platform::vendor&gt;() &lt;&lt; " "
            &lt;&lt; plat.get_info&lt;sycl::info::platform::version&gt;() &lt;&lt; std::endl;
</pre>
</div>
</div>
</p>

<p name="switchToTextMode">
Then for each platform we list the devices:
<div class="card">
  <div class="card-header" id="headingOne">
    <h5 class="mb-0">
      <button class="btn btn-link" data-toggle="collapse" data-target="#dpcppdevices" aria-expanded="false" aria-controls="dpcppdevices">
        C++ Code: dpcppdevices
      </button>
    </h5>
  </div>
  <div id="dpcppdevices" class="collapse">
  <pre>
std::vector&lt;sycl::device&gt; devices = plat.get_devices();
for (const auto &dev : devices) {
  std::cout &lt;&lt; "-- Device: "
            &lt;&lt; dev.get_info&lt;sycl::info::device::name&gt;()
            &lt;&lt; (dev.is_host() ? ": is the host" : "")
            &lt;&lt; (dev.is_cpu() ? ": is a cpu" : "")
            &lt;&lt; (dev.is_gpu() ? ": is a gpu" : "")
            &lt;&lt; std::endl;
</pre>
</div>
</div>
</p>

<p name="switchToTextMode">
You can query what type of device you are dealing with by
</p>

<h2><a id="Queues">42.3</a> Queues</h2>
<p name=crumbs>
crumb trail:  > <a href="dpcpp.html">dpcpp</a> > <a href="dpcpp.html#Queues">Queues</a>
</p>
<p name="switchToTextMode">

The execution mechanism of SYCL is the
<i>queue</i>
<!-- index -->
:
a sequence of actions that will be executed on a selected device.
The only user action is submitting actions to a queue;
the queue is executed at the end of the scope where it is declared.
</p>

<p name="switchToTextMode">
Queue execution is asynchronous with host code.
</p>

<h3><a id="Deviceselectors">42.3.1</a> Device selectors</h3>
<p name=crumbs>
crumb trail:  > <a href="dpcpp.html">dpcpp</a> > <a href="dpcpp.html#Queues">Queues</a> > <a href="dpcpp.html#Deviceselectors">Device selectors</a>
</p>
<p name="switchToTextMode">

You need to select a device on which to execute the queue.
A&nbsp;single queue can only dispatch to a single device.
</p>

<p name="switchToTextMode">
A queue is coupled to one specific device,
so it can not spread work over multiple devices.
You can find a default device for the queue with
<!-- environment: lstlisting start embedded generator -->
</p>
<!-- environment block purpose: [[ environment=lstlisting ]] -->
<lstlisting>
<pre>
  sycl::queue myqueue;
</pre>
</lstlisting>
<!-- environment: lstlisting end embedded generator -->
<p name="switchToTextMode">

The following example explicitly assigns the queue to the CPU device
using the  <tt>sycl::</tt> 
<div class="card">
  <div class="card-header" id="headingOne">
    <h5 class="mb-0">
      <button class="btn btn-link" data-toggle="collapse" data-target="#cpuclass" aria-expanded="false" aria-controls="cpuclass">
        C++ Code: cpuclass
      </button>
    </h5>
  </div>
  <div id="cpuclass" class="collapse">
  <pre>
// cpuname.cxx
sycl::queue myqueue( sycl::cpu_selector{} );
</pre>
</div>
</div>
</p>

The  <tt>sycl::</tt> 
<p name="switchToTextMode">
make the code run on the host.
</p>

<p name="switchToTextMode">
It is good for your sanity to print the name of the device
you are running on:
<div class="card">
  <div class="card-header" id="headingOne">
    <h5 class="mb-0">
      <button class="btn btn-link" data-toggle="collapse" data-target="#devname" aria-expanded="false" aria-controls="devname">
        C++ Code: devname
      </button>
    </h5>
  </div>
  <div id="devname" class="collapse">
  <pre>
// devname.cxx
std::cout &lt;&lt; myqueue.get_device().get_info&lt;sycl::info::device::name&gt;()
          &lt;&lt; std::endl;
</pre>
</div>
</div>
</p>

<p name="switchToTextMode">
If you try to select a device that is not available,
a  <tt>sycl::</tt> 
</p>

<p name="switchToTextMode">
\begin{dpcppnote}
<!-- environment: lstlisting start embedded generator -->
</p>
<!-- environment block purpose: [[ environment=lstlisting ]] -->
<lstlisting>
<pre>
    #include "CL/sycl/intel/fpga_extensions.hpp"
    fpga_selector
</pre>
</lstlisting>
<!-- environment: lstlisting end embedded generator -->
<p name="switchToTextMode">
\end{dpcppnote}
</p>

<h3><a id="Queueexecution">42.3.2</a> Queue execution</h3>
<p name=crumbs>
crumb trail:  > <a href="dpcpp.html">dpcpp</a> > <a href="dpcpp.html#Queues">Queues</a> > <a href="dpcpp.html#Queueexecution">Queue execution</a>
</p>
<p name="switchToTextMode">

It seems that queue kernels will also be executed when only they
go out of scope, but not the queue:
<!-- environment: lstlisting start embedded generator -->
</p>
<!-- environment block purpose: [[ environment=lstlisting ]] -->
<lstlisting>
<pre>
cpu_selector selector;
queue q(selector);
{
  q.submit( /* some kernel */ );
} // here the kernel executes
</pre>
</lstlisting>
<!-- environment: lstlisting end embedded generator -->
<p name="switchToTextMode">

<h3><a id="Kernelordering">42.3.3</a> Kernel ordering</h3>
<p name=crumbs>
crumb trail:  > <a href="dpcpp.html">dpcpp</a> > <a href="dpcpp.html#Queues">Queues</a> > <a href="dpcpp.html#Kernelordering">Kernel ordering</a>
</p>
</p>

<p name="switchToTextMode">
Kernels are not necessarily executed in the order in which they are submitted.
You can enforce this by specifying an 
<i>in-order queue</i>
:
<!-- environment: lstlisting start embedded generator -->
</p>
<!-- environment block purpose: [[ environment=lstlisting ]] -->
<lstlisting>
<pre>
sycl::queue myqueue{property::queue::inorder()};
</pre>
</lstlisting>
<!-- environment: lstlisting end embedded generator -->
<p name="switchToTextMode">

<h2><a id="Kernels">42.4</a> Kernels</h2>
<p name=crumbs>
crumb trail:  > <a href="dpcpp.html">dpcpp</a> > <a href="dpcpp.html#Kernels">Kernels</a>
</p>
</p>

<p name="switchToTextMode">
One kernel per submit.
</p>

<!-- environment: lstlisting start embedded generator -->
<!-- environment block purpose: [[ environment=lstlisting ]] -->
<lstlisting>
<pre>
myqueue.submit( [&] ( handler &commandgroup ) {
    commandgroup.parallel_for&lt;uniquename&gt;
      ( range&lt;1&gt;{N},
        [=] ( id&lt;1&gt; idx ) { ... idx }
      )
    } );
</pre>
</lstlisting>
<!-- environment: lstlisting end embedded generator -->
<p name="switchToTextMode">

Note that the lambda in the kernel captures by value.
Capturing by reference makes no sense,
since the kernel is executed on a device.
</p>

<!-- environment: lstlisting start embedded generator -->
<!-- environment block purpose: [[ environment=lstlisting ]] -->
<lstlisting>
<pre>
cgh.single_task(
  [=]() {
    // kernel function is executed EXACTLY once on a SINGLE work-item
});
</pre>
</lstlisting>
<!-- environment: lstlisting end embedded generator -->
<p name="switchToTextMode">

The 
<!-- environment: lstlisting start embedded generator -->
</p>
<!-- environment block purpose: [[ environment=lstlisting ]] -->
<lstlisting>
<pre>
auto myevent = myqueue.submit( /* stuff */ );
</pre>
</lstlisting>
<!-- environment: lstlisting end embedded generator -->
<p name="switchToTextMode">
This can be used for two purposes:
<!-- environment: enumerate start embedded generator -->
</p>
<!-- environment block purpose: [[ environment=enumerate ]] -->
<enumerate>
<ol>
<!-- TranslatingLineGenerator enumerate ['enumerate'] -->
<li>
It becomes possible to wait for this specific event:
<!-- environment: lstlisting start embedded generator -->
</p>
<!-- environment block purpose: [[ environment=lstlisting ]] -->
<lstlisting>
<pre>
myevent.wait();
</pre>
</lstlisting>
<!-- environment: lstlisting end embedded generator -->
<li>
It can be used to indicate kernel dependencies:
<!-- environment: lstlisting start embedded generator -->
</p>
<!-- environment block purpose: [[ environment=lstlisting ]] -->
<lstlisting>
<pre>
myqueue.submit( [=] (handler &h) {
    h.depends_on(myevent);
    /* stuff */
    } );
</pre>
</lstlisting>
<!-- environment: lstlisting end embedded generator -->
</ol>
</enumerate>
<!-- environment: enumerate end embedded generator -->
<p name="switchToTextMode">

<h2><a id="Paralleloperations">42.5</a> Parallel operations</h2>
<p name=crumbs>
crumb trail:  > <a href="dpcpp.html">dpcpp</a> > <a href="dpcpp.html#Paralleloperations">Parallel operations</a>
</p>
</p>

<h3><a id="Loops">42.5.1</a> Loops</h3>
<p name=crumbs>
crumb trail:  > <a href="dpcpp.html">dpcpp</a> > <a href="dpcpp.html#Paralleloperations">Parallel operations</a> > <a href="dpcpp.html#Loops">Loops</a>
</p>
<p name="switchToTextMode">

<!-- environment: lstlisting start embedded generator -->
</p>
<!-- environment block purpose: [[ environment=lstlisting ]] -->
<lstlisting>
<pre>
cgh.parallel_for(
  range&lt;3&gt;(1024,1024,1024),
  // using 3D in this example
  [=](id&lt;3&gt; myID) {
    // kernel function is executed on an n-dimensional range (NDrange)
});


cgh.parallel_for(
  nd_range&lt;3&gt;( {1024,1024,1024},{16,16,16} ),
  // using 3D in this example
  [=](nd_item&lt;3&gt; myID) {
    // kernel function is executed on an n-dimensional range (NDrange)
});


cgh.parallel_for_work_group(
  range&lt;2&gt;(1024,1024),
  // using 2D in this example
  [=](group&lt;2&gt; myGroup) {
    // kernel function is executed once per work-group
});


grp.parallel_for_work_item(
  range&lt;1&gt;(1024),
  // using 1D in this example
  [=](h_item&lt;1&gt; myItem) {
    // kernel function is executed once per work-item
});
</pre>
</lstlisting>
<!-- environment: lstlisting end embedded generator -->
<p name="switchToTextMode">

<h4><a id="Loopbounds:ranges">42.5.1.1</a> Loop bounds: ranges</h4>
<p name=crumbs>
crumb trail:  > <a href="dpcpp.html">dpcpp</a> > <a href="dpcpp.html#Paralleloperations">Parallel operations</a> > <a href="dpcpp.html#Loops">Loops</a> > <a href="dpcpp.html#Loopbounds:ranges">Loop bounds: ranges</a>
</p>
</p>

<p name="switchToTextMode">
SYCL adopts the modern C++ philosophy that one does not iterate
over by explicitly enumerating indices, but by indicating their range.
This is realized by the 
which is templated over the number of space dimensions.
</p>

<!-- environment: lstlisting start embedded generator -->
<!-- environment block purpose: [[ environment=lstlisting ]] -->
<lstlisting>
<pre>
sycl::range&lt;2&gt; matrix{10,10};
</pre>
</lstlisting>
<!-- environment: lstlisting end embedded generator -->
<p name="switchToTextMode">

Some compilers are sensitive to the type of the integer arguments:
<!-- environment: lstlisting start embedded generator -->
</p>
<!-- environment block purpose: [[ environment=lstlisting ]] -->
<lstlisting>
<pre>
sycl::range&lt;1&gt; array{ static_cast&lt;size_t&gt;(size)} ;
</pre>
</lstlisting>
<!-- environment: lstlisting end embedded generator -->
<p name="switchToTextMode">

<h4><a id="Loopindices">42.5.1.2</a> Loop indices</h4>
<p name=crumbs>
crumb trail:  > <a href="dpcpp.html">dpcpp</a> > <a href="dpcpp.html#Paralleloperations">Parallel operations</a> > <a href="dpcpp.html#Loops">Loops</a> > <a href="dpcpp.html#Loopindices">Loop indices</a>
</p>
</p>

<p name="switchToTextMode">
Kernels such as 
expects two arguments:
<!-- environment: itemize start embedded generator -->
</p>
<!-- environment block purpose: [[ environment=itemize ]] -->
<itemize>
<ul>
<!-- TranslatingLineGenerator itemize ['itemize'] -->
<li>
a 
<li>
a lambda of one argument: an index.
</ul>
</itemize>
<!-- environment: itemize end embedded generator -->
<p name="switchToTextMode">

There are several ways of indexing.
The 
<!-- environment: lstlisting start embedded generator -->
</p>
<!-- environment block purpose: [[ environment=lstlisting ]] -->
<lstlisting>
<pre>
myHandle.parallel_for&lt;class uniqueID&gt;
   ( mySize,
     [=]( id&lt;1&gt; index ) {
       float x = index.get(0) * h;
       deviceAccessorA[index] *= 2.;
     }
   )
</pre>
</lstlisting>
<!-- environment: lstlisting end embedded generator -->
<p name="switchToTextMode">

<!-- environment: lstlisting start embedded generator -->
</p>
<!-- environment block purpose: [[ environment=lstlisting ]] -->
<lstlisting>
<pre>
cgh.parallel_for&lt;class foo&gt;(
    range&lt;1&gt;{D*D*D},
    [=](id&lt;1&gt; item) {
        xx[ item[0] ] = 2 * item[0] + 1;
    }
)
</pre>
</lstlisting>
<!-- environment: lstlisting end embedded generator -->
<p name="switchToTextMode">

While the C++ vectors remain one-dimensional,
<span title="acronym" ><i>DPCPP</i></span>
 allows you to make multi-dimensional buffers:
<!-- environment: lstlisting start embedded generator -->
</p>
<!-- environment block purpose: [[ environment=lstlisting ]] -->
<lstlisting>
<pre>
std::vector&lt;int&gt; y(D*D*D);
buffer&lt;int,1&gt; y_buf(y.data(), range&lt;1&gt;(D*D*D));
cgh.parallel_for&lt;class foo2D&gt;
   (range&lt;2&gt;{D,D*D},
    [=](id&lt;2&gt; item) {
        yy[ item[0] + D*item[1] ] = 2;
    }
   );
</pre>
</lstlisting>
<!-- environment: lstlisting end embedded generator -->
<p name="switchToTextMode">

\begin{dpcppnote}
  There is an implicit conversion from the one-dimensional
   <tt>sycl::</tt> 
  to  <tt>size_t</tt> , so
<!-- environment: lstlisting start embedded generator -->
</p>
<!-- environment block purpose: [[ environment=lstlisting ]] -->
<lstlisting>
<pre>
[=](sycl::id&lt;1&gt; i) {
   data[i] = i;
}
</pre>
</lstlisting>
<!-- environment: lstlisting end embedded generator -->
<p name="switchToTextMode">
is legal, which in SYCL requires
<!-- environment: lstlisting start embedded generator -->
</p>
<!-- environment block purpose: [[ environment=lstlisting ]] -->
<lstlisting>
<pre>
data[i[0]] = i[0];
</pre>
</lstlisting>
<!-- environment: lstlisting end embedded generator -->
<p name="switchToTextMode">
\end{dpcppnote}
</p>

<h4><a id="Multi-dimensionalindexing">42.5.1.3</a> Multi-dimensional indexing</h4>
<p name=crumbs>
crumb trail:  > <a href="dpcpp.html">dpcpp</a> > <a href="dpcpp.html#Paralleloperations">Parallel operations</a> > <a href="dpcpp.html#Loops">Loops</a> > <a href="dpcpp.html#Multi-dimensionalindexing">Multi-dimensional indexing</a>
</p>
<p name="switchToTextMode">

<div class="card">
  <div class="card-header" id="headingOne">
    <h5 class="mb-0">
      <button class="btn btn-link" data-toggle="collapse" data-target="#syclrange2" aria-expanded="false" aria-controls="syclrange2">
        C++ Code: syclrange2
      </button>
    </h5>
  </div>
  <div id="syclrange2" class="collapse">
  <pre>
// stencil2d.cxx
sycl::range&lt;2&gt; stencil_range(N, M);
sycl::range&lt;2&gt; alloc_range(N + 2, M + 2);
std::vector&lt;float&gt;
  input(alloc_range.size()),
  output(alloc_range.size());
  sycl::buffer&lt;float, 2&gt; input_buf(input.data(), alloc_range);
  sycl::buffer&lt;float, 2&gt; output_buf(output.data(), alloc_range);
</pre>
</div>
</div>
</p>

<div class="card">
  <div class="card-header" id="headingOne">
    <h5 class="mb-0">
      <button class="btn btn-link" data-toggle="collapse" data-target="#syclrange2nd" aria-expanded="false" aria-controls="syclrange2nd">
        C++ Code: syclrange2nd
      </button>
    </h5>
  </div>
  <div id="syclrange2nd" class="collapse">
  <pre>
constexpr size_t B = 4;
sycl::range&lt;2&gt; local_range(B, B);
sycl::range&lt;2&gt; tile_range = local_range + sycl::range&lt;2&gt;(2, 2); // Includes boundary cells
auto tile = local_accessor&lt;float, 2&gt;(tile_range, h); // see templated def'n above
</pre>
</div>
</div>
<p name="switchToTextMode">

We first copy global data into an array local to the work group:
<div class="card">
  <div class="card-header" id="headingOne">
    <h5 class="mb-0">
      <button class="btn btn-link" data-toggle="collapse" data-target="#syclnduse" aria-expanded="false" aria-controls="syclnduse">
        C++ Code: syclnduse
      </button>
    </h5>
  </div>
  <div id="syclnduse" class="collapse">
  <pre>
sycl::id&lt;2&gt; offset(1, 1);
h.parallel_for
  ( sycl::nd_range&lt;2&gt;(stencil_range, local_range, offset),
    [=] ( sycl::nd_item&lt;2&gt; it ) {
// Load this tile into work-group local memory
    sycl::id&lt;2&gt;    lid    = it.get_local_id();
    sycl::range&lt;2&gt; lrange = it.get_local_range();
    for   (int ti = lid[0]; ti &lt; B + 2; ti += lrange[0]) {
      for (int tj = lid[1]; tj &lt; B + 2; tj += lrange[1]) {
        int gi = ti + B * it.get_group(0);
        int gj = tj + B * it.get_group(1);
        tile[ti][tj] = input[gi][gj];
      }
    }
</pre>
</div>
</div>
</p>

<p name="switchToTextMode">
Global coordinates in the input are computed from the
<!-- environment: lstlisting start embedded generator -->
</p>
<!-- environment block purpose: [[ environment=lstlisting ]] -->
<lstlisting>
<pre>
[=] ( sycl::nd_item&lt;2&gt; it ) {
for   (int ti ... ) {
  for (int tj ... ) {
    int gi = ti + B * it.get_group(0);
    int gj = tj + B * it.get_group(1);
    ... = input[gi][gj];
</pre>
</lstlisting>
<!-- environment: lstlisting end embedded generator -->
<p name="switchToTextMode">

Local coordinates in the tile, including boundary,
I DON'T QUITE GET THIS YET.
<!-- environment: lstlisting start embedded generator -->
</p>
<!-- environment block purpose: [[ environment=lstlisting ]] -->
<lstlisting>
<pre>
[=] ( sycl::nd_item&lt;2&gt; it ) {
sycl::id&lt;2&gt;    lid    = it.get_local_id();
sycl::range&lt;2&gt; lrange = it.get_local_range();
for   (int ti = lid[0]; ti &lt; B + 2; ti += lrange[0]) {
  for (int tj = lid[1]; tj &lt; B + 2; tj += lrange[1]) {
    tile[ti][tj] = ..
</pre>
</lstlisting>
<!-- environment: lstlisting end embedded generator -->
<p name="switchToTextMode">

<h3><a id="Taskdependencies">42.5.2</a> Task dependencies</h3>
<p name=crumbs>
crumb trail:  > <a href="dpcpp.html">dpcpp</a> > <a href="dpcpp.html#Paralleloperations">Parallel operations</a> > <a href="dpcpp.html#Taskdependencies">Task dependencies</a>
</p>
</p>

<p name="switchToTextMode">
Each 
<tt>submit</tt>
Since it returns a token, it becomes possible to specify
task dependencies by refering to a token as a dependency
in a later specified task.
<!-- environment: lstlisting start embedded generator -->
</p>
<!-- environment block purpose: [[ environment=lstlisting ]] -->
<lstlisting>
<pre>
queue myQueue;
auto myTokA = myQueue.submit
   ( [&](handler& h) {
       h.parallel_for&lt;class taskA&gt;(...);
     }
   );
auto myTokB = myQueue.submit
   ( [&](handler& h) {
       h.depends_on(myTokA);
       h.parallel_for&lt;class taskB&gt;(...);
     }
   );
</pre>
</lstlisting>
<!-- environment: lstlisting end embedded generator -->
<p name="switchToTextMode">

<h3><a id="Raceconditions">42.5.3</a> Race conditions</h3>
<p name=crumbs>
crumb trail:  > <a href="dpcpp.html">dpcpp</a> > <a href="dpcpp.html#Paralleloperations">Parallel operations</a> > <a href="dpcpp.html#Raceconditions">Race conditions</a>
</p>
</p>

<p name="switchToTextMode">
Sycl has the same problems with
<i>race conditions</i>
<!-- index -->
that other shared memory system have:
</p>

<div class="card">
  <div class="card-header" id="headingOne">
    <h5 class="mb-0">
      <button class="btn btn-link" data-toggle="collapse" data-target="#dpcppsumreduct" aria-expanded="false" aria-controls="dpcppsumreduct">
        C++ Code: dpcppsumreduct
      </button>
    </h5>
  </div>
  <div id="dpcppsumreduct" class="collapse">
  <pre>
// sum1d.cxx
auto array_accessor =
  array_buffer.get_access&lt;sycl::access::mode::read&gt;(h);
auto scalar_accessor =
  scalar_buffer.get_access&lt;sycl::access::mode::read_write&gt;(h);
h.parallel_for&lt;class uniqueID&gt;
  ( array_range,
    [=](sycl::id&lt;1&gt; index)
    {
      scalar_accessor[0] += array_accessor[index];
    }
    ); // end of parallel for
</pre>
</div>
</div>
<p name="switchToTextMode">

To get this working correctly would need either
a reduction primitive or atomics on the accumulator.
The 2020 proposed standard has improved atomics.
</p>

<div class="card">
  <div class="card-header" id="headingOne">
    <h5 class="mb-0">
      <button class="btn btn-link" data-toggle="collapse" data-target="#dpcppsumreduction" aria-expanded="false" aria-controls="dpcppsumreduction">
        C++ Code: dpcppsumreduction
      </button>
    </h5>
  </div>
  <div id="dpcppsumreduction" class="collapse">
  <pre>
// reduct1d.cxx
	auto input_values = array_buffer.get_access&lt;sycl::access::mode::read&gt;(h);
	auto sum_reduction = sycl::reduction( scalar_buffer,h,std::plus&lt;&gt;() );
        h.parallel_for
          ( array_range,sum_reduction,
            [=]( sycl::id&lt;1&gt; index,auto& sum )
            {
	      sum += input_values[index];
            }
            ); // end of parallel for
</pre>
</div>
</div>
<p name="switchToTextMode">

<h3><a id="Reductions">42.5.4</a> Reductions</h3>
<p name=crumbs>
crumb trail:  > <a href="dpcpp.html">dpcpp</a> > <a href="dpcpp.html#Paralleloperations">Parallel operations</a> > <a href="dpcpp.html#Reductions">Reductions</a>
</p>
</p>

<p name="switchToTextMode">
Reduction operations were added in the the SYCL 2020 Provisional Standard,
meaning that they are not yet finalized.
</p>

<p name="switchToTextMode">
Here is one approach, which works in 
<i>hipsycl</i>
:
<div class="card">
  <div class="card-header" id="headingOne">
    <h5 class="mb-0">
      <button class="btn btn-link" data-toggle="collapse" data-target="#syclsumreduct" aria-expanded="false" aria-controls="syclsumreduct">
        C++ Code: syclsumreduct
      </button>
    </h5>
  </div>
  <div id="syclsumreduct" class="collapse">
  <pre>
// reductscalar.cxx
auto reduce_to_sum =
  sycl::reduction( sum_array, static_cast&lt;float&gt;(0.), std::plus&lt;float&gt;() );
myqueue.parallel_for// parallel_for&lt;reduction_kernel&lt;T,BinaryOp,__LINE__&gt;&gt;
  ( array_range,    // sycl::range&lt;1&gt;(input_size),
    reduce_to_sum,  // sycl::reduction(output, identity, op),
    [=] (sycl::id&lt;1&gt; idx, auto& reducer) { // type of reducer is impl-dependent, so use auto
    reducer.combine(shared_array[idx[0]]); //(input[idx[0]]);
//reducer += shared_array[idx[0]]; // see line 216: add_reducer += input0[idx[0]];
  } ).wait();
</pre>
</div>
</div>
Here a  <tt>sycl::</tt> 
from the target data and the reduction operator.
This is then passed to the 
and its 
</p>

<h2><a id="Memoryaccess">42.6</a> Memory access</h2>
<p name=crumbs>
crumb trail:  > <a href="dpcpp.html">dpcpp</a> > <a href="dpcpp.html#Memoryaccess">Memory access</a>
</p>
<p name="switchToTextMode">

Memory treatment in SYCL is a little complicated, because is (at the very least)
host memory and device memory, which are not necessarily coherent.
</p>

<p name="switchToTextMode">
There are also three mechanisms:
<!-- environment: itemize start embedded generator -->
</p>
<!-- environment block purpose: [[ environment=itemize ]] -->
<itemize>
<ul>
<!-- TranslatingLineGenerator itemize ['itemize'] -->
<li>
Unified Shared Memory, based on ordinary C/C++ `star'-pointers.
<li>
Buffers, using the 
  this needs the 
<li>
Images.
</ul>
</itemize>
<!-- environment: itemize end embedded generator -->
<p name="switchToTextMode">

<!-- environment: table start embedded generator -->
</p>
<!-- environment block purpose: [[ environment=table ]] -->
<table>
<table><tbody>
<!-- TranslatingLineGenerator table ['table'] -->
<p name="caption">
TABLE: Memory types and treatments
</p>

<!-- environment: tabular start embedded generator -->
<table>
<tr>
<td>
<!-- TranslatingLineGenerator tabular ['tabular'] -->
    \toprule
    Location</td><td>allocation</td><td>coherence</td><td>copy to/from device </td></tr>
<tr><td>
    \midrule
    Host  </td><td>
<tt>malloc</tt>
                   </td><td>explicit transfer   </td><td>
          </td><td>
    Device</td><td>
    Shared</td><td>
    \bottomrule
</td>
</tr>
</table>
<!-- environment: tabular end embedded generator -->
</tbody></table>
</table>
<!-- environment: table end embedded generator -->
<p name="switchToTextMode">

<h3><a id="Unifiedsharedmemory">42.6.1</a> Unified shared memory</h3>
<p name=crumbs>
crumb trail:  > <a href="dpcpp.html">dpcpp</a> > <a href="dpcpp.html#Memoryaccess">Memory access</a> > <a href="dpcpp.html#Unifiedsharedmemory">Unified shared memory</a>
</p>
</p>

<p name="switchToTextMode">
Memory allocated with 
is visible on the host:
<div class="card">
  <div class="card-header" id="headingOne">
    <h5 class="mb-0">
      <button class="btn btn-link" data-toggle="collapse" data-target="#syclsharealloc" aria-expanded="false" aria-controls="syclsharealloc">
        C++ Code: syclsharealloc
      </button>
    </h5>
  </div>
  <div id="syclsharealloc" class="collapse">
  <pre>
// outshared.cxx
floattype
  *host_float = (floattype*)malloc_host( sizeof(floattype),ctx ),
  *shar_float = (floattype*)malloc_shared( sizeof(floattype),dev,ctx );
    cgh.single_task
	( [=] () {
	  shar_float[0] = 2 * host_float[0];
	  sout &lt;&lt; "Device sets " &lt;&lt; shar_float[0] &lt;&lt; sycl::endl;
	} );
</pre>
</div>
</div>
</p>

<p name="switchToTextMode">
Device memory is allocated with 
passing the queue as parameter:
<div class="card">
  <div class="card-header" id="headingOne">
    <h5 class="mb-0">
      <button class="btn btn-link" data-toggle="collapse" data-target="#sycldevcalloc" aria-expanded="false" aria-controls="sycldevcalloc">
        C++ Code: sycldevcalloc
      </button>
    </h5>
  </div>
  <div id="sycldevcalloc" class="collapse">
  <pre>
// reductimpl.cxx
floattype
  *host_float = (floattype*)malloc( sizeof(floattype) ),
  *devc_float = (floattype*)malloc_device( sizeof(floattype),dev,ctx );
   [&](sycl::handler &cgh) {
     cgh.memcpy(devc_float,host_float,sizeof(floattype));
   }
</pre>
</div>
</div>
Note the corresponding 
that also has the queue as parameter.
</p>

<p name="switchToTextMode">
Note that you need to be in a parallel task.
The following gives a segmentation error:
<!-- environment: lstlisting start embedded generator -->
</p>
<!-- environment block purpose: [[ environment=lstlisting ]] -->
<lstlisting>
<pre>
  [&](sycl::handler &cgh) {
    shar_float[0] = host_float[0];
  }
</pre>
</lstlisting>
<!-- environment: lstlisting end embedded generator -->
<p name="switchToTextMode">

Ordinary memory, for instance from 
has to be copied in a kernel:
<div class="card">
  <div class="card-header" id="headingOne">
    <h5 class="mb-0">
      <button class="btn btn-link" data-toggle="collapse" data-target="#sycldevcmemcpy" aria-expanded="false" aria-controls="sycldevcmemcpy">
        C++ Code: sycldevcmemcpy
      </button>
    </h5>
  </div>
  <div id="sycldevcmemcpy" class="collapse">
  <pre>
   [&](sycl::handler &cgh) {
     cgh.memcpy(devc_float,host_float,sizeof(floattype));
   }
   [&](sycl::handler &cgh) {
     sycl::stream sout(1024, 256, cgh);
     cgh.single_task
	 (
	  [=] () {
	    sout &lt;&lt; "Number " &lt;&lt; devc_float[0] &lt;&lt; sycl::endl;
	  }
	  );
   } // end of submitted lambda
free(host_float);
sycl::free(devc_float,myqueue);
</pre>
</div>
</div>
</p>

<h3><a id="Buffersandaccessors">42.6.2</a> Buffers and accessors</h3>
<p name=crumbs>
crumb trail:  > <a href="dpcpp.html">dpcpp</a> > <a href="dpcpp.html#Memoryaccess">Memory access</a> > <a href="dpcpp.html#Buffersandaccessors">Buffers and accessors</a>
</p>
<p name="switchToTextMode">

Arrays need to be declared in a way such that they can be
access from any device.
</p>

<div class="card">
  <div class="card-header" id="headingOne">
    <h5 class="mb-0">
      <button class="btn btn-link" data-toggle="collapse" data-target="#syclbufdef" aria-expanded="false" aria-controls="syclbufdef">
        C++ Code: syclbufdef
      </button>
    </h5>
  </div>
  <div id="syclbufdef" class="collapse">
  <pre>
// forloop.cxx
std::vector&lt;int&gt; myArray(SIZE);
  range&lt;1&gt; mySize{myArray.size()};
  buffer&lt;int, 1&gt; bufferA(myArray.data(), myArray.size());
</pre>
</div>
</div>
<p name="switchToTextMode">

Inside the kernel, the array is then unpacked from the buffer:
</p>

<div class="card">
  <div class="card-header" id="headingOne">
    <h5 class="mb-0">
      <button class="btn btn-link" data-toggle="collapse" data-target="#syclbufuse" aria-expanded="false" aria-controls="syclbufuse">
        C++ Code: syclbufuse
      </button>
    </h5>
  </div>
  <div id="syclbufuse" class="collapse">
  <pre>
myqueue.submit( [&] (handler &h) {
	auto deviceAccessorA =
	  bufferA.get_access&lt;access::mode::read_write&gt;(h);
</pre>
</div>
</div>
<p name="switchToTextMode">

However, the 
in a  <tt>sycl::</tt> 
The precise type is templated and complicated, so this
is a good place to use  <tt>auto</tt> .
</p>

<p name="switchToTextMode">
Accessors can have a mode associated:
 <tt>sycl::access::mode::</tt> 
 <tt>sycl::access::mode::</tt> 
</p>

<p name="switchToTextMode">
\begin{dpcppnote}
<!-- environment: lstlisting start embedded generator -->
</p>
<!-- environment block purpose: [[ environment=lstlisting ]] -->
<lstlisting>
<pre>
    array&lt;floattype,1&gt; leftsum{0.};
#ifdef __INTEL_CLANG_COMPILER
    sycl::buffer leftbuf(leftsum);
#else
    sycl::range&lt;1&gt; scalar{1};
    sycl::buffer&lt;floattype,1&gt; leftbuf(leftsum.data(),scalar);
</pre>
</lstlisting>
<!-- environment: lstlisting end embedded generator -->
<p name="switchToTextMode">
\end{dpcppnote}
</p>

<p name="switchToTextMode">
\begin{dpcppnote}
there are modes
<!-- environment: lstlisting start embedded generator -->
</p>
<!-- environment block purpose: [[ environment=lstlisting ]] -->
<lstlisting>
<pre>
// standard
sycl::accessor acc = buffer.get_access&lt;sycl::access::mode:write&gt;(h);
// dpcpp extension
sycl::accessor acc( buffer,h,sycl::read_only );
sycl::accessor acc( buffer,h,sycl::write_only );
</pre>
</lstlisting>
<!-- environment: lstlisting end embedded generator -->
<p name="switchToTextMode">
\end{dpcppnote}
</p>

<h3><a id="Querying">42.6.3</a> Querying</h3>
<p name=crumbs>
crumb trail:  > <a href="dpcpp.html">dpcpp</a> > <a href="dpcpp.html#Memoryaccess">Memory access</a> > <a href="dpcpp.html#Querying">Querying</a>
</p>
<p name="switchToTextMode">

The function 
or an accessor:
\cxxverbatimsnippet[code/dpcpp/cxx/range2.cxx]{syclbufrange}
\cxxverbatimsnippet[code/dpcpp/cxx/range2.cxx]{syclaccrange}
</p>

<h2><a id="Paralleloutput">42.7</a> Parallel output</h2>
<p name=crumbs>
crumb trail:  > <a href="dpcpp.html">dpcpp</a> > <a href="dpcpp.html#Paralleloutput">Parallel output</a>
</p>
<p name="switchToTextMode">

There is a  <tt>sycl::</tt> 
</p>

<div class="card">
  <div class="card-header" id="headingOne">
    <h5 class="mb-0">
      <button class="btn btn-link" data-toggle="collapse" data-target="#syclcout" aria-expanded="false" aria-controls="syclcout">
        C++ Code: syclcout
      </button>
    </h5>
  </div>
  <div id="syclcout" class="collapse">
  <pre>
// hello.cxx
[&](sycl::handler &cgh) {
  sycl::stream sout(1024, 256, cgh);
  cgh.parallel_for&lt;class hello_world&gt;
	 (
	  sycl::range&lt;1&gt;(global_range), [=](sycl::id&lt;1&gt; idx) {
	    sout &lt;&lt; "Hello, World: World rank " &lt;&lt; idx &lt;&lt; sycl::endl;
	  }); // End of the kernel function
}
</pre>
</div>
</div>
<p name="switchToTextMode">

Since the end of a queue does not flush stdout,
it may be necessary to call
 <tt>sycl::queue::</tt> 
<!-- environment: lstlisting start embedded generator -->
</p>
<!-- environment block purpose: [[ environment=lstlisting ]] -->
<lstlisting>
<pre>
myQueue.wait();
</pre>
</lstlisting>
<!-- environment: lstlisting end embedded generator -->
<p name="switchToTextMode">

<h2><a id="DPCPPextensions">42.8</a> DPCPP extensions</h2>
<p name=crumbs>
crumb trail:  > <a href="dpcpp.html">dpcpp</a> > <a href="dpcpp.html#DPCPPextensions">DPCPP extensions</a>
</p>
</p>

<p name="switchToTextMode">
Intel has made some extensions to SYCL:
<!-- environment: itemize start embedded generator -->
</p>
<!-- environment block purpose: [[ environment=itemize ]] -->
<itemize>
<ul>
<!-- TranslatingLineGenerator itemize ['itemize'] -->
<li>
Unified Shared Memory,
<li>
Ordered queues.
</ul>
</itemize>
<!-- environment: itemize end embedded generator -->
<p name="switchToTextMode">

<h2><a id="Inteldevcloudnotes">42.9</a> Intel devcloud notes</h2>
<p name=crumbs>
crumb trail:  > <a href="dpcpp.html">dpcpp</a> > <a href="dpcpp.html#Inteldevcloudnotes">Intel devcloud notes</a>
</p>
</p>

<p name="switchToTextMode">

<tt>qsub -I</tt>
 for interactive session.
</p>

<p name="switchToTextMode">

<tt>gdb-oneapi</tt>
 for debugging.
</p>

<p name="switchToTextMode">

<a href=https://community.intel.com/t5/Intel-oneAPI-Toolkits/ct-p/oneapi>https://community.intel.com/t5/Intel-oneAPI-Toolkits/ct-p/oneapi</a>

for support.
</p>

<h2><a id="Examples">42.10</a> Examples</h2>
<p name=crumbs>
crumb trail:  > <a href="dpcpp.html">dpcpp</a> > <a href="dpcpp.html#Examples">Examples</a>
</p>
<p name="switchToTextMode">

<h3><a id="Kernelsinaloop">42.10.1</a> Kernels in a loop</h3>
<p name=crumbs>
crumb trail:  > <a href="dpcpp.html">dpcpp</a> > <a href="dpcpp.html#Examples">Examples</a> > <a href="dpcpp.html#Kernelsinaloop">Kernels in a loop</a>
</p>
</p>

<p name="switchToTextMode">
The following idiom works:
\cxxverbatimsnippet[code/dpcpp/cxx/jacobi1d.cxx]{syclkernelloop}
</p>

<h3><a id="Stencilcomputations">42.10.2</a> Stencil computations</h3>
<p name=crumbs>
crumb trail:  > <a href="dpcpp.html">dpcpp</a> > <a href="dpcpp.html#Examples">Examples</a> > <a href="dpcpp.html#Stencilcomputations">Stencil computations</a>
</p>
<p name="switchToTextMode">

The problem with stencil computations is that only interior points are updated.
Translated to SYCL: we need to iterate over a subrange of the range over which
the buffer is defined. First let us define these ranges:
\cxxverbatimsnippet[code/dpcpp/cxx/jacobi1d.cxx]{syclrangebc}
Note the boundary value&nbsp;$1.$ on the right boundary.
</p>

<p name="switchToTextMode">
Restricting the iteration to the interior points is done through
the 
\cxxverbatimsnippet[code/dpcpp/cxx/jacobi1d.cxx]{sycliteratebc}
</div>
<a href="index.html">Back to Table of Contents</a>
