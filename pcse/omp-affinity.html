<html>
<head>
<link href="ihpsc.css" rel="stylesheet" type="text/css">
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/css/bootstrap.min.css" integrity="sha384-Gn5384xqQ1aoWXA+058RXPxPg6fy4IWvTNh0E263XmFcJlSAwiGgFAW/dAiS6JXm" crossorigin="anonymous">

  <script src="https://code.jquery.com/jquery-3.2.1.slim.min.js" integrity="sha384-KJ3o2DKtIkvYIK3UENzmM7KCkRr/rE9/Qpg6aAZGJwFDMVNA/GpGFF93hXpG5KkN" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.12.9/umd/popper.min.js" integrity="sha384-ApNbgh9B+Y1QKtv3Rn7W3mgPxhU9K/ScQsAP7hUibX39j7fakFPskvXusvfa0b4Q" crossorigin="anonymous"></script>
  <script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/js/bootstrap.min.js" integrity="sha384-JZR6Spejh4U02d8jOt6vLEHfe/JQGiRRSQQxSfFWpi1MquVdAyjUar5+76PVCmYl" crossorigin="anonymous"></script>

  <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

  <script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {inlineMath: [['$','$']]}
  });
  MathJax.Hub.Config({
    TeX: { equationNumbers: { autoNumber: "AMS" } }
  });
  </script>

  <link rel="stylesheet"
      href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.13.1/styles/default.min.css">
  <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.13.1/highlight.min.js"></script>
  <script>hljs.initHighlightingOnLoad();</script>
</head>

<script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
<script src="http://ccrs.cac.cornell.edu:8080/client.0.1.js"></script>
<style>
</style>

<script type="application/javascript">
  // First we declare some metadata, primarily to describe
  // the container environment.
  var ccrsApiNamespace = "org.xsede.jobrunner.model.ModelApi";
  var mpiExampleMetaJson = {
    // CHANGE: for now, leave the appended string as .SysJobMetaData;
    //         other options will be supported in the future
    "$type": ccrsApiNamespace + ".SysJobMetaData",
    // CHANGE: shell to use implicitly when running commands in the container
    "shell": ["bash"],
    // CHANGE: should currently be one of: .NixOS, .Singularity
    "containerType": {
      "$type":  ccrsApiNamespace + ".NixOS"
    },
    // CHANGE: Specify for NixOS for all jobs, or for Singularity when resuming existing jobs
    "containerId": ["vicOpenMPI"],
    // CHANGE: Specify the singularity image name
    "image": [],
    // Directories on the host to mount in the container, if any:
    "binds": [],
    // Only for singularity:
    "overlay": [],
    // CHANGE: should be filled in dynamically to contain the (student) user,
    //         but this is a demo, so we use a static user name:
    "user": "test0",
    "address": [],
    "hostname": [],
    "url": window.location.href
  };
  var mpiExampleMeta = CCRS.sysJobMetaData(mpiExampleMetaJson);
</script>

<div class="container">
  <div class="row">
    <div class="col-12">
      <div class="pagehead">
        <h1>OpenMP topic: Affinity</h1>
        <h5>Experimental html version of downloadable textbook, see http://www.tacc.utexas.edu/~eijkhout/istc/istc.html</h5>
      </div>
    </div>
  </div>
  <div>


\[
\newcommand\inv{^{-1}}\newcommand\invt{^{-t}}
\newcommand\bbP{\mathbb{P}}
\newcommand\bbR{\mathbb{R}}
\newcommand\defined{
  \mathrel{\lower 5pt \hbox{${\equiv\atop\mathrm{\scriptstyle D}}$}}}
\]


25.1 : <a href="omp-affinity.html#OpenMPthreadaffinitycontrol">OpenMP thread affinity control</a><br>
25.1.1 : <a href="omp-affinity.html#Threadbinding">Thread binding</a><br>
25.1.2 : <a href="omp-affinity.html#Effectsofthreadbinding">Effects of thread binding</a><br>
25.1.3 : <a href="omp-affinity.html#Placedefinition">Place definition</a><br>
25.1.4 : <a href="omp-affinity.html#Bindingpossibilities">Binding possibilities</a><br>
25.2 : <a href="omp-affinity.html#First-touch">First-touch</a><br>
25.2.1 : <a href="omp-affinity.html#C++">C++</a><br>
25.2.2 : <a href="omp-affinity.html#Remarks">Remarks</a><br>
25.3 : <a href="omp-affinity.html#AffinitycontroloutsideOpenMP">Affinity control outside OpenMP</a><br>
<a href="index.html">Back to Table of Contents</a>
<h1>25 OpenMP topic: Affinity</h1>
<!-- TranslatingLineGenerator file ['file'] -->
</p>

<!-- index -->
<p name="switchToTextMode">

<h2><a id="OpenMPthreadaffinitycontrol">25.1</a> OpenMP thread affinity control</h2>
<p name=crumbs>
crumb trail:  > <a href="omp-affinity.html">omp-affinity</a> > <a href="omp-affinity.html#OpenMPthreadaffinitycontrol">OpenMP thread affinity control</a>
</p>

</p>

<p name="switchToTextMode">

<!-- index -->
;
see the example in section~
<a href="http://pages.tacc.utexas.edu/~eijkhout/pcse/html/omp-affinity.html#First-touch">25.2</a>
.
</p>

<p name="switchToTextMode">
Thread placement can be controlled with two environment variables:
<!-- environment: itemize start embedded generator -->
</p>
<!-- environment block purpose: [[ environment=itemize ]] -->
<itemize>
<ul>
<!-- TranslatingLineGenerator itemize ['itemize'] -->
<li>
the environment variable 
<tt>OMP_PROC_BIND</tt>
  describes how threads are bound to 
<i>OpenMP places</i>
; while
<li>
the variable 
<tt>OMP_PLACES</tt>
 describes these places
  in terms of the available hardware.
<li>
When you're experimenting with these variables it is a good idea
  to set 
<tt>OMP_DISPLAY_ENV</tt>
 to true, so that OpenMP will
  print out at runtime how it has interpreted your specification.
  The examples in the following sections will display this output.
</ul>
</itemize>
<!-- environment: itemize end embedded generator -->
<p name="switchToTextMode">

<h3><a id="Threadbinding">25.1.1</a> Thread binding</h3>
<p name=crumbs>
crumb trail:  > <a href="omp-affinity.html">omp-affinity</a> > <a href="omp-affinity.html#OpenMPthreadaffinitycontrol">OpenMP thread affinity control</a> > <a href="omp-affinity.html#Threadbinding">Thread binding</a>
</p>

</p>

<p name="switchToTextMode">
The variable 
<tt>OMP_PLACES</tt>
 defines a series of places to
which the threads are assigned.
</p>

<p name="switchToTextMode">
Example: if you have two sockets and you define
<!-- environment: verbatim start embedded generator -->
</p>
<!-- environment block purpose: [[ environment=verbatim ]] -->
<verbatim>
<pre>
OMP_PLACES=sockets
</pre>
</verbatim>
<!-- environment: verbatim end embedded generator -->
<p name="switchToTextMode">
then
<!-- environment: itemize start embedded generator -->
</p>
<!-- environment block purpose: [[ environment=itemize ]] -->
<itemize>
<ul>
<!-- TranslatingLineGenerator itemize ['itemize'] -->
<li>
thread 0 goes to socket 0,
<li>
thread 1 goes to socket 1,
<li>
thread 2 goes to socket 0 again,
<li>
and so on.
</ul>
</itemize>
<!-- environment: itemize end embedded generator -->
<p name="switchToTextMode">
On the other hand, if the two sockets have a total of sixteen cores
and you define
<!-- environment: verbatim start embedded generator -->
</p>
<!-- environment block purpose: [[ environment=verbatim ]] -->
<verbatim>
<pre>
OMP_PLACES=cores
OMP_PROC_BIND=close
</pre>
</verbatim>
<!-- environment: verbatim end embedded generator -->
<p name="switchToTextMode">
then
<!-- environment: itemize start embedded generator -->
</p>
<!-- environment block purpose: [[ environment=itemize ]] -->
<itemize>
<ul>
<!-- TranslatingLineGenerator itemize ['itemize'] -->
<li>
thread 0 goes to core 0, which is on socket&nbsp;0,
<li>
thread 1 goes to core 1, which is on socket&nbsp;0,
<li>
thread 2 goes to core 2, which is on socket&nbsp;0,
<li>
and so on, until thread 7 goes to core 7 on socket&nbsp;0, and
<li>
thread 8 goes to core 8, which is on socket&nbsp;1,
<li>
et cetera.
</ul>
</itemize>
<!-- environment: itemize end embedded generator -->
<p name="switchToTextMode">
The value 
<tt>OMP_PROC_BIND=close</tt>
 means that the assignment goes
successively through the available places.
The variable 
<tt>OMP_PROC_BIND</tt>
 can also be set to 
<tt>spread</tt>
, which
spreads the threads over the places.
With
<!-- environment: verbatim start embedded generator -->
</p>
<!-- environment block purpose: [[ environment=verbatim ]] -->
<verbatim>
<pre>
OMP_PLACES=cores
OMP_PROC_BIND=spread
</pre>
</verbatim>
<!-- environment: verbatim end embedded generator -->
<p name="switchToTextMode">
you find that
<!-- environment: itemize start embedded generator -->
</p>
<!-- environment block purpose: [[ environment=itemize ]] -->
<itemize>
<ul>
<!-- TranslatingLineGenerator itemize ['itemize'] -->
<li>
thread 0 goes to core 0, which is on socket&nbsp;0,
<li>
thread 1 goes to core 8, which is on socket&nbsp;1,
<li>
thread 2 goes to core 1, which is on socket&nbsp;0,
<li>
thread 3 goes to core 9, which is on socket&nbsp;1,
<li>
and so on, until thread 14 goes to core 7 on socket&nbsp;0, and
<li>
thread 15 goes to core 15, which is on socket&nbsp;1.
</ul>
</itemize>
<!-- environment: itemize end embedded generator -->
<p name="switchToTextMode">

So you see that 
<tt>OMP_PLACES=cores</tt>
 and 
<tt>OMP_PROC_BIND=spread</tt>
 very
similar to 
<tt>OMP_PLACES=sockets</tt>
. The difference is that the latter
choice does not bind a thread to a specific core, so the operating
system can move threads about, and it can put more than one thread on
the same core, even if there is another core still unused.
</p>

<p name="switchToTextMode">
The value 
<tt>OMP_PROC_BIND=master</tt>
 puts the threads in the same place
as the master of the team. This is convenient if you create teams
recursively. In that case you would use the 
clause rather than the environment variable, set to 
<tt>spread</tt>
 for the
initial team, and to 
<tt>master</tt>
 for the recursively created team.
</p>

<h3><a id="Effectsofthreadbinding">25.1.2</a> Effects of thread binding</h3>
<p name=crumbs>
crumb trail:  > <a href="omp-affinity.html">omp-affinity</a> > <a href="omp-affinity.html#OpenMPthreadaffinitycontrol">OpenMP thread affinity control</a> > <a href="omp-affinity.html#Effectsofthreadbinding">Effects of thread binding</a>
</p>

<p name="switchToTextMode">

Let's consider two example program. First we consider the program for
computing&nbsp;$\pi$, which is purely compute-bound.
</p>

<!-- environment: tabular start embedded generator -->
<table>
<tr>
<td>
<!-- TranslatingLineGenerator tabular ['tabular'] -->
  </td></tr>
<tr><td>
  \#threads</td><td>
<tt>close/cores</tt>
</td><td>
<tt>spread/sockets</tt>
</td><td>
<tt>spread/cores</tt>
</td></tr>
<tr><td>
  </td></tr>
<tr><td>
   1</td><td> 0.359</td><td> 0.354</td><td> 0.353</td></tr>
<tr><td>
   2</td><td> 0.177</td><td> 0.177</td><td> 0.177</td></tr>
<tr><td>
   4</td><td> 0.088</td><td> 0.088</td><td> 0.088</td></tr>
<tr><td>
   6</td><td> 0.059</td><td> 0.059</td><td> 0.059</td></tr>
<tr><td>
   8</td><td> 0.044</td><td> 0.044</td><td> 0.044</td></tr>
<tr><td>
  12</td><td> 0.029</td><td> 0.045</td><td> 0.029</td></tr>
<tr><td>
  16</td><td> 0.022</td><td> 0.050</td><td> 0.022</td></tr>
<tr><td>
  </td></tr>
<tr><td>
</td>
</tr>
</table>
<!-- environment: tabular end embedded generator -->
<p name="switchToTextMode">

We see pretty much perfect speedup for the 
<tt>OMP_PLACES=cores</tt>

strategy; with 
<tt>OMP_PLACES=sockets</tt>
 we probably get occasional
collisions where two threads wind up on the same core.
</p>

<p name="switchToTextMode">
Next we take a program for computing the time evolution of the
<i>heat equation</i>
:
\[
 t=0,1,2,&hellip;\colon \forall_i\colon
x^{(t+1)}_i = 2x^{(t)}_i-x^{(t)}_{i-1}-x^{(t)}_{i+1}
\]
This is a bandwidth-bound operation because the amount of computation
per data item is low.
</p>

<!-- environment: tabular start embedded generator -->
<table>
<tr>
<td>
<!-- TranslatingLineGenerator tabular ['tabular'] -->
  </td></tr>
<tr><td>
  \#threads</td><td>
<tt>close/cores</tt>
</td><td>
<tt>spread/sockets</tt>
</td><td>
<tt>spread/cores</tt>
</td></tr>
<tr><td>
  </td></tr>
<tr><td>
   1</td><td> 2.88</td><td> 2.89</td><td> 2.88</td></tr>
<tr><td>
   2</td><td> 1.71</td><td> 1.41</td><td> 1.42</td></tr>
<tr><td>
   4</td><td> 1.11</td><td> 0.74</td><td> 0.74</td></tr>
<tr><td>
   6</td><td> 1.09</td><td> 0.57</td><td> 0.57</td></tr>
<tr><td>
   8</td><td> 1.12</td><td> 0.57</td><td> 0.53</td></tr>
<tr><td>
  12</td><td> 0.72</td><td> 0.53</td><td> 0.52</td></tr>
<tr><td>
  16</td><td> 0.52</td><td> 0.61</td><td> 0.53</td></tr>
<tr><td>
  </td></tr>
<tr><td>
</td>
</tr>
</table>
<!-- environment: tabular end embedded generator -->
<p name="switchToTextMode">

Again we see that 
<tt>OMP_PLACES=sockets</tt>
 gives worse performance for
high core counts,
probably because of threads winding up on the same core.
The thing to observe in this example is that with 6&nbsp;or&nbsp;8 cores the

<tt>OMP_PROC_BIND=spread</tt>
 strategy gives twice the performance of

<tt>OMP_PROC_BIND=close</tt>
.
</p>

<p name="switchToTextMode">
The reason for this is that a single socket
does not have enough bandwidth for all eight cores on the
socket. Therefore, dividing the eight threads over two sockets gives
each thread a higher available bandwidth than putting all threads on
one socket.
</p>

<h3><a id="Placedefinition">25.1.3</a> Place definition</h3>
<p name=crumbs>
crumb trail:  > <a href="omp-affinity.html">omp-affinity</a> > <a href="omp-affinity.html#OpenMPthreadaffinitycontrol">OpenMP thread affinity control</a> > <a href="omp-affinity.html#Placedefinition">Place definition</a>
</p>
<p name="switchToTextMode">

There are three predefined values for the 
<tt>OMP_PLACES</tt>
variable: 
<tt>sockets, cores, threads</tt>
. You have already seen the first
two; the 
<tt>threads</tt>
 value becomes relevant on processors that have
hardware threads. In that case, 
<tt>OMP_PLACES=cores</tt>
 does not tie a
thread to a specific hardware thread, leading again to possible
collisions as in the above example. Setting 
<tt>OMP_PLACES=threads</tt>

ties each OpenMP thread to a specific hardware thread.
</p>

<p name="switchToTextMode">
There is also a very general syntax for defining places that uses a
<!-- environment: verbatim start embedded generator -->
</p>
<!-- environment block purpose: [[ environment=verbatim ]] -->
<verbatim>
<pre>
  location:number:stride
</pre>
</verbatim>
<!-- environment: verbatim end embedded generator -->
<p name="switchToTextMode">
syntax. Examples:
<!-- environment: itemize start embedded generator -->
</p>
<!-- environment block purpose: [[ environment=itemize ]] -->
<itemize>
<ul>
<!-- TranslatingLineGenerator itemize ['itemize'] -->
<li>
<!-- environment: verbatim start embedded generator -->
</p>
<!-- environment block purpose: [[ environment=verbatim ]] -->
<verbatim>
<pre>
OMP_PLACES="{0:8:1},{8:8:1}"
</pre>
</verbatim>
<!-- environment: verbatim end embedded generator -->
<p name="switchToTextMode">
  is equivalent to
  
<tt>sockets</tt>
 on a two-socket design with eight cores per socket: it
  defines two places, each having eight consecutive cores. The threads
  are then places alternating between the two places, but not further
  specified inside the place.
<li>
The setting 
<tt>cores</tt>
 is equivalent to
<!-- environment: verbatim start embedded generator -->
</p>
<!-- environment block purpose: [[ environment=verbatim ]] -->
<verbatim>
<pre>
OMP_PLACES="{0},{1},{2},...,{15}"
</pre>
</verbatim>
<!-- environment: verbatim end embedded generator -->
<li>
On a four-socket design, the specification
<!-- environment: verbatim start embedded generator -->
</p>
<!-- environment block purpose: [[ environment=verbatim ]] -->
<verbatim>
<pre>
OMP_PLACES="{0:4:8}:4:1"
</pre>
</verbatim>
<!-- environment: verbatim end embedded generator -->
<p name="switchToTextMode">
  states that the place 
<tt>0,8,16,24</tt>
 needs to be repeated four times,
  with a stride of one. In other words,  thread&nbsp;0 winds up on
  core&nbsp;0 of some socket, the thread&nbsp;1 winds up on core&nbsp;1 of some
  socket, et cetera.
</ul>
</itemize>
<!-- environment: itemize end embedded generator -->
<p name="switchToTextMode">

<h3><a id="Bindingpossibilities">25.1.4</a> Binding possibilities</h3>
<p name=crumbs>
crumb trail:  > <a href="omp-affinity.html">omp-affinity</a> > <a href="omp-affinity.html#OpenMPthreadaffinitycontrol">OpenMP thread affinity control</a> > <a href="omp-affinity.html#Bindingpossibilities">Binding possibilities</a>
</p>
</p>

<p name="switchToTextMode">
Values for 
<tt>OMP_PROC_BIND</tt>
 are: 
<tt>false, true, master, close, spread</tt>
.
<!-- environment: itemize start embedded generator -->
</p>
<!-- environment block purpose: [[ environment=itemize ]] -->
<itemize>
<ul>
<!-- TranslatingLineGenerator itemize ['itemize'] -->
<li>
false: set no binding 
<li>
true: lock threads to a core 
<li>
  master: collocate threads with the master thread 
<li>
close: place
  threads close to the master in the places list 
<li>
spread: spread
  out threads as much as possible
</ul>
</itemize>
<!-- environment: itemize end embedded generator -->
<p name="switchToTextMode">

This effect can be made local by
giving the 
<tt>parallel</tt>
 directive.
</p>

<p name="switchToTextMode">
A safe default setting is
<!-- environment: verbatim start embedded generator -->
</p>
<!-- environment block purpose: [[ environment=verbatim ]] -->
<verbatim>
<pre>
export OMP_PROC_BIND=true
</pre>
</verbatim>
<!-- environment: verbatim end embedded generator -->
<p name="switchToTextMode">
which prevents the operating system from
<i>migrating a thread</i>
. This prevents many scaling problems.
</p>

<p name="switchToTextMode">
Good examples of 
<i>thread placement</i>
 on the
<i>Intel Knight's Landing</i>
<!-- index -->
:

<a href=https://software.intel.com/en-us/articles/process-and-thread-affinity-for-intel-xeon-phi-processors-x200>https://software.intel.com/en-us/articles/process-and-thread-affinity-for-intel-xeon-phi-processors-x200</a>

</p>

<p name="switchToTextMode">
As an example, consider a code where two threads write to a shared
location.
<div class="card">
  <div class="card-header" id="headingOne">
    <h5 class="mb-0">
      <button class="btn btn-link" data-toggle="collapse" data-target="#shareboth" aria-expanded="false" aria-controls="shareboth">
        C Code: shareboth
      </button>
    </h5>
  </div>
  <div id="shareboth" class="collapse">
  <pre>
// sharing.c
#pragma omp parallel
  { // not a parallel for: just a bunch of reps
    for (int j = 0; j &lt; reps; j++) {
#pragma omp for schedule(static,1)
      for (int i = 0; i &lt; N; i++){
#pragma omp atomic
	a++;
      }

    }
  }
</pre>
</div>
</div>
There is now a big difference in runtime depending on how close the
threads are. We test this on a processor with both cores and
hyperthreads. First we bind the OpenMP threads to the cores:
<!-- environment: verbatim start embedded generator -->
</p>
<!-- environment block purpose: [[ environment=verbatim ]] -->
<verbatim>
<pre>
OMP_NUM_THREADS=2 OMP_PLACES=cores OMP_PROC_BIND=close ./sharing
run time = 4752.231836usec
sum = 80000000.0
</pre>
</verbatim>
<!-- environment: verbatim end embedded generator -->
<p name="switchToTextMode">
Next we force the OpenMP threads to bind to hyperthreads inside one core:
<!-- environment: verbatim start embedded generator -->
</p>
<!-- environment block purpose: [[ environment=verbatim ]] -->
<verbatim>
<pre>
OMP_PLACES=threads OMP_PROC_BIND=close ./sharing
run time = 941.970110usec
sum = 80000000.0
</pre>
</verbatim>
<!-- environment: verbatim end embedded generator -->
<p name="switchToTextMode">
Of course in this example the inner loop is pretty much meaningless
and parallelism does not speed up anything:
<!-- environment: verbatim start embedded generator -->
</p>
<!-- environment block purpose: [[ environment=verbatim ]] -->
<verbatim>
<pre>
OMP_NUM_THREADS=1 OMP_PLACES=cores OMP_PROC_BIND=close ./sharing
run time = 806.669950usec
sum = 80000000.0
</pre>
</verbatim>
<!-- environment: verbatim end embedded generator -->
<p name="switchToTextMode">
However, we see that the two-thread result is almost as fast, meaning
that there is very little parallelization overhead.
</p>

<!-- index -->
<p name="switchToTextMode">

<h2><a id="First-touch">25.2</a> First-touch</h2>
<p name=crumbs>
crumb trail:  > <a href="omp-affinity.html">omp-affinity</a> > <a href="omp-affinity.html#First-touch">First-touch</a>
</p>

</p>

<p name="switchToTextMode">
The affinity issue shows up in the 
<i>first-touch</i>
phenomemon.
</p>

<p name="switchToTextMode">
A little background knowledge. Memory is organized in
<i>memory page</i>
s
<!-- index -->
,
and what we think of as `addresses' really
<i>virtual address</i>
es,
mapped to 
<i>physical address</i>
es,
through a 
<i>page table</i>
.
</p>

<p name="switchToTextMode">
This means that data in your program can be anywhere in physical memory.
In particular, on a 
<i>dual socket</i>
 node,
the memory can be mapped to either of the sockets.
</p>

<p name="switchToTextMode">
The next thing to know is that
memory allocated with 
<tt>malloc</tt>
 and like
routines is not immediately mapped; that only happens when data is
written to it. In light of this, consider the following OpenMP code:
<!-- environment: lstlisting start embedded generator -->
</p>
<!-- environment block purpose: [[ environment=lstlisting ]] -->
<lstlisting>
<pre>
double *x = (double*) malloc(N*sizeof(double));


for (i=0; i&lt;N; i++)
  x[i] = 0;


#pragma omp parallel for
for (i=0; i&lt;N; i++)
  .... something with x[i] ...
</pre>
</lstlisting>
<!-- environment: lstlisting end embedded generator -->
<p name="switchToTextMode">
Since the initialization loop is not parallel it is executed by the
master thread, making all the memory associated with the socket of
that thread. Subsequent access by the other socket will then access
data from memory not attached to that socket.
</p>

<p name="switchToTextMode">
Let's consider an example. We make the initialization
parallel subject to an option:
<div class="card">
  <div class="card-header" id="headingOne">
    <h5 class="mb-0">
      <button class="btn btn-link" data-toggle="collapse" data-target="#heatinitfirst" aria-expanded="false" aria-controls="heatinitfirst">
        C Code: heatinitfirst
      </button>
    </h5>
  </div>
  <div id="heatinitfirst" class="collapse">
  <pre>
// heat.cxx
#pragma omp parallel if (init&gt;0)
  {
#pragma omp for
    for (int i=0; i&lt;N; i++)
      y[i] = x[i] = 0.;
    x[0] = 0; x[N-1] = 1.;
  }
</pre>
</div>
</div>
</p>

<p name="switchToTextMode">
If the initialization is not parallel, the array will be mapped
to the socket of the master thread; if it is parallel,
it may be mapped to different sockets, depending on where the threads run.
</p>

<p name="switchToTextMode">
As a simple application
we run a heat equation, which is parallel,
though not embarassingly so:
<div class="card">
  <div class="card-header" id="headingOne">
    <h5 class="mb-0">
      <button class="btn btn-link" data-toggle="collapse" data-target="#heatmethodrun" aria-expanded="false" aria-controls="heatmethodrun">
        C Code: heatmethodrun
      </button>
    </h5>
  </div>
  <div id="heatmethodrun" class="collapse">
  <pre>
for (int it=0; it&lt;1000; it++) {
#pragma omp parallel for
  for (int i=1; i&lt;N-1; i++)
    y[i] = ( x[i-1]+x[i]+x[i+1] )/3.;
#pragma omp parallel for
  for (int i=1; i&lt;N-1; i++)
    x[i] = y[i];
}
</pre>
</div>
</div>
</p>

<p name="switchToTextMode">
On the 
<i>TACC Frontera</i>
 machine, with dual 28-core
<i>Intel Cascade Lake</i>
 processors,
we use the following settings:
</p>

<!-- environment: verbatim start embedded generator -->
<!-- environment block purpose: [[ environment=verbatim ]] -->
<verbatim>
<pre>
export OMP_PLACES=cores
export OMP_PROC_BIND=close
# no parallel initialization
make heat && OMP_NUM_THREADS=56 ./heat
# yes parallel initialization
make heat && OMP_NUM_THREADS=56 ./heat 1
</pre>
</verbatim>
<!-- environment: verbatim end embedded generator -->
<p name="switchToTextMode">

This gives us a remarkable difference in runtime:
<!-- environment: itemize start embedded generator -->
</p>
<!-- environment block purpose: [[ environment=itemize ]] -->
<itemize>
<ul>
<!-- TranslatingLineGenerator itemize ['itemize'] -->
<li>
  Sequential init: avg=2.089, stddev=0.1083
<li>
  Parallel init: avg=1.006, stddev=0.0216
</ul>
</itemize>
<!-- environment: itemize end embedded generator -->
<p name="switchToTextMode">
This large difference will be mitigated
for algorithms with higher arithmetic intensity.
</p>

<!-- environment: exercise start embedded generator -->
<!-- environment block purpose: [[ environment=exercise ]] -->
<exercise>
<b>Exercise</b>
<p name="exercise">
<!-- TranslatingLineGenerator exercise ['exercise'] -->
  How do the OpenMP dynamic schedules relate to this issue?
</p name="exercise">
</exercise>
<!-- environment: exercise end embedded generator -->
<p name="switchToTextMode">

<h3><a id="C++">25.2.1</a> C++</h3>
<p name=crumbs>
crumb trail:  > <a href="omp-affinity.html">omp-affinity</a> > <a href="omp-affinity.html#First-touch">First-touch</a> > <a href="omp-affinity.html#C++">C++</a>
</p>
</p>

<p name="switchToTextMode">

The problem with realizing first-touch in 
<i>C++</i>
%
<!-- index -->
<!-- index -->
is that  <tt>std::vector</tt>  fills its allocation with default values.
This makes
<!-- environment: lstlisting start embedded generator -->
</p>
<!-- environment block purpose: [[ environment=lstlisting ]] -->
<lstlisting>
<pre>
vector&lt;double&gt; x(N);
</pre>
</lstlisting>
<!-- environment: lstlisting end embedded generator -->
<p name="switchToTextMode">
equivalent to the non-parallel allocation and initialization above.
</p>

<p name="switchToTextMode">
Here is a solution.
We make a template for uninitialized types:
<div class="card">
  <div class="card-header" id="headingOne">
    <h5 class="mb-0">
      <button class="btn btn-link" data-toggle="collapse" data-target="#cppuninitial" aria-expanded="false" aria-controls="cppuninitial">
        C++ Code: cppuninitial
      </button>
    </h5>
  </div>
  <div id="cppuninitial" class="collapse">
  <pre>
// heatalloc.cxx
template&lt;typename T&gt;
struct uninitialized {
  uninitialized() {};
  T val;
  constexpr operator T() const {return val;};
  double operator=( const T&& v ) { val = v; return val; };
};
</pre>
</div>
</div>
</p>

<p name="switchToTextMode">
so that we can create vectors that behave normally:
<div class="card">
  <div class="card-header" id="headingOne">
    <h5 class="mb-0">
      <button class="btn btn-link" data-toggle="collapse" data-target="#cppuninitialvec" aria-expanded="false" aria-controls="cppuninitialvec">
        C++ Code: cppuninitialvec
      </button>
    </h5>
  </div>
  <div id="cppuninitialvec" class="collapse">
  <pre>
vector&lt;uninitialized&lt;double&gt;&gt; x(N),y(N);

#pragma omp parallel for
for (int i=0; i&lt;N; i++)
  y[i] = x[i] = 0.;
x[0] = 0; x[N-1] = 1.;
</pre>
</div>
</div>
</p>

<p name="switchToTextMode">
Running the code with the regular definition of a vector,
and the above modification,
reproduces the runtimes of the C&nbsp;variant above.
</p>

<p name="switchToTextMode">
Another option is to wrap memory allocated with 
<tt>new</tt>

in a  <tt>unique_ptr</tt> :
<div class="card">
  <div class="card-header" id="headingOne">
    <h5 class="mb-0">
      <button class="btn btn-link" data-toggle="collapse" data-target="#newuninitial" aria-expanded="false" aria-controls="newuninitial">
        C++ Code: newuninitial
      </button>
    </h5>
  </div>
  <div id="newuninitial" class="collapse">
  <pre>
// heatptr.cxx
unique_ptr&lt;double[]&gt; x( new double[N] );
unique_ptr&lt;double[]&gt; y( new double[N] );

#pragma omp parallel for
for (int i=0; i&lt;N; i++) {
  y[i] = x[i] = 0.;
}
x[0] = 0; x[N-1] = 1.;
</pre>
</div>
</div>
</p>

<p name="switchToTextMode">
Note that this gives fairly elegant code,
since square bracket indexing is overloaded for  <tt>unique_ptr</tt> .
The only disadvantage is that we can not query the 
<tt>size</tt>

of these arrays. Or do bound checking with 
<tt>at</tt>
,
but in high performance contexts that is usually not appropriate anyway.
</p>

<p name="switchToTextMode">

<!-- environment: comment start embedded generator -->
</p>
<!-- environment block purpose: [[ environment=comment ]] -->
<comment>


</comment>
<!-- environment: comment end embedded generator -->
<p name="switchToTextMode">

<h3><a id="Remarks">25.2.2</a> Remarks</h3>
<p name=crumbs>
crumb trail:  > <a href="omp-affinity.html">omp-affinity</a> > <a href="omp-affinity.html#First-touch">First-touch</a> > <a href="omp-affinity.html#Remarks">Remarks</a>
</p>
</p>

<p name="switchToTextMode">
You could move pages with 
<tt>move_pages</tt>
.
</p>

<p name="switchToTextMode">
By regarding affinity,
in effect you are adopting an 
<span title="acronym" ><i>SPMD</i></span>
 style of programming.
You could make this explicit by having each thread allocate its part
of the arrays separately, and storing a private pointer as
<tt>threadprivate</tt>
&nbsp;
<a href="http://pages.tacc.utexas.edu/~eijkhout/pcse/html/bibliography.html#Liu:2003:OMP-SPMD">[Liu:2003:OMP-SPMD]</a>
. However, this
makes it impossible for threads to access each other's parts of the
distributed array, so this is only suitable for
total 
<i>data parallel</i>
 or
<i>embarrassingly parallel</i>
 applications.
</p>

<!-- environment: comment start embedded generator -->
<!-- environment block purpose: [[ environment=comment ]] -->
<comment>


</comment>
<!-- environment: comment end embedded generator -->
<p name="switchToTextMode">

<h2><a id="AffinitycontroloutsideOpenMP">25.3</a> Affinity control outside OpenMP</h2>
<p name=crumbs>
crumb trail:  > <a href="omp-affinity.html">omp-affinity</a> > <a href="omp-affinity.html#AffinitycontroloutsideOpenMP">Affinity control outside OpenMP</a>
</p>
</p>

<p name="switchToTextMode">
There are various utilities to control process and thread placement.
</p>

<p name="switchToTextMode">
Process placement can be controlled on the Operating system level by
<!-- environment: tacc start embedded generator -->
</p>
<!-- environment block purpose: [[ environment=tacc ]] -->
<tacc>

<p name="tacc">
<!-- TranslatingLineGenerator tacc ['tacc'] -->
(the TACC utility 
 is a wrapper around this)
</p name="tacc">

</tacc>
<!-- environment: tacc end embedded generator -->
<p name="switchToTextMode">
on Linux (also 
<tt>taskset</tt>
); Windows
<tt>start/affinity</tt>
.
</p>

<p name="switchToTextMode">
Corresponding system calls: 
<tt>pbing</tt>
 on Solaris,
<tt>sched_setaffinity</tt>
 on Linux,
<tt>SetThreadAffinityMask</tt>
 on Windows.
</p>

<p name="switchToTextMode">
Corresponding environment variables: 
<tt>SUNW_MP_PROCBIND</tt>
 on
Solaris, 
<tt>KMP_AFFINITY</tt>
 on Intel.
</p>

<p name="switchToTextMode">
The 
<i>Intel compiler</i>

<!-- index -->
 has an
environment variable for affinity control:
<!-- environment: verbatim start embedded generator -->
</p>
<!-- environment block purpose: [[ environment=verbatim ]] -->
<verbatim>
<pre>
export KMP_AFFINITY=verbose,scatter
</pre>
</verbatim>
<!-- environment: verbatim end embedded generator -->
<p name="switchToTextMode">
values: 
<tt>none,scatter,compact</tt>

</p>

<p name="switchToTextMode">
For 
<i>gcc</i>

<!-- index -->
:
<!-- environment: verbatim start embedded generator -->
</p>
<!-- environment block purpose: [[ environment=verbatim ]] -->
<verbatim>
<pre>
export GOMP_CPU_AFFINITY=0,8,1,9
</pre>
</verbatim>
<!-- environment: verbatim end embedded generator -->
<p name="switchToTextMode">

For the 
<i>Sun compiler</i>
:
<!-- environment: verbatim start embedded generator -->
</p>
<!-- environment block purpose: [[ environment=verbatim ]] -->
<verbatim>
<pre>
SUNW_MP_PROCBIND
</pre>
</verbatim>
<!-- environment: verbatim end embedded generator -->
<p name="switchToTextMode">

</div>
<a href="index.html">Back to Table of Contents</a>
