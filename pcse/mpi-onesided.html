<html>
<head>
<link href="ihpsc.css" rel="stylesheet" type="text/css">
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/css/bootstrap.min.css" integrity="sha384-Gn5384xqQ1aoWXA+058RXPxPg6fy4IWvTNh0E263XmFcJlSAwiGgFAW/dAiS6JXm" crossorigin="anonymous">

  <script src="https://code.jquery.com/jquery-3.2.1.slim.min.js" integrity="sha384-KJ3o2DKtIkvYIK3UENzmM7KCkRr/rE9/Qpg6aAZGJwFDMVNA/GpGFF93hXpG5KkN" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.12.9/umd/popper.min.js" integrity="sha384-ApNbgh9B+Y1QKtv3Rn7W3mgPxhU9K/ScQsAP7hUibX39j7fakFPskvXusvfa0b4Q" crossorigin="anonymous"></script>
  <script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/js/bootstrap.min.js" integrity="sha384-JZR6Spejh4U02d8jOt6vLEHfe/JQGiRRSQQxSfFWpi1MquVdAyjUar5+76PVCmYl" crossorigin="anonymous"></script>

  <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

  <script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {inlineMath: [['$','$']]}
  });
  MathJax.Hub.Config({
    TeX: { equationNumbers: { autoNumber: "AMS" } }
  });
  </script>

  <link rel="stylesheet"
      href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.13.1/styles/default.min.css">
  <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.13.1/highlight.min.js"></script>
  <script>hljs.initHighlightingOnLoad();</script>
</head>

<script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
<script src=https://ccrs.cac.cornell.edu:8443/client.0.2.js></script>
<script id="script">
class Example {
  constructor(buttonID, editorID, outputID, sourceFile, fileName, commandStr) {
    this.buttonID = buttonID;
    this.editorID = editorID;
    this.outputID = outputID;
    this.sourceFile = sourceFile;
    this.fileName = fileName;
    this.commandStr = commandStr;
  }
    
  async display(results, object) {
    if (results.stdout.length > 0)
      document.getElementById(object.outputID).textContent = results.stdout;
    else
      document.getElementById(object.outputID).textContent = results.stderr;
  }

  async initialize() {
    this.editor = await MonacoEditorFileSource.create(this.editorID);
    this.editor.setTextFromFile(this.sourceFile);
    this.job = await Job.create(JobType.MPI);
    this.command = new CommandWithFiles(this.job, this.commandStr);
    this.command.addFileSource(this.editor, this.fileName);
    this.trigger = new ButtonTrigger(this.command, this.display, this.buttonID, this);
    document.getElementById(this.buttonID).disabled = false;
  }
}
</script>
<style></style>

<div class="container">
  <div class="row">
    <div class="col-12">
      <div class="pagehead">
        <h1>MPI topic: One-sided communication</h1>
        <h5>Experimental html version of downloadable textbook, see http://www.tacc.utexas.edu/~eijkhout/istc/istc.html</h5>
      </div>
    </div>
  </div>
  <div>


\[
\newcommand\inv{^{-1}}\newcommand\invt{^{-t}}
\newcommand\bbP{\mathbb{P}}
\newcommand\bbR{\mathbb{R}}
\newcommand\defined{
  \mathrel{\lower 5pt \hbox{${\equiv\atop\mathrm{\scriptstyle D}}$}}}
\]


9.1 : <a href="mpi-onesided.html#Windows">Windows</a><br>
9.1.1 : <a href="mpi-onesided.html#Windowcreationandallocation">Window creation and allocation</a><br>
9.1.2 : <a href="mpi-onesided.html#Addressarithmetic">Address arithmetic</a><br>
9.2 : <a href="mpi-onesided.html#Activetargetsynchronization:epochs">Active target synchronization: epochs</a><br>
9.2.1 : <a href="mpi-onesided.html#Fenceassertions">Fence assertions</a><br>
9.2.2 : <a href="mpi-onesided.html#Non-globaltargetsynchronization">Non-global target synchronization</a><br>
9.3 : <a href="mpi-onesided.html#Put,get,accumulate">Put, get, accumulate</a><br>
9.3.1 : <a href="mpi-onesided.html#Put">Put</a><br>
9.3.2 : <a href="mpi-onesided.html#Get">Get</a><br>
9.3.3 : <a href="mpi-onesided.html#Putandgetexample:haloupdate">Put and get example: halo update</a><br>
9.3.4 : <a href="mpi-onesided.html#Accumulate">Accumulate</a><br>
9.3.5 : <a href="mpi-onesided.html#OrderingandcoherenceofRMAoperations">Ordering and coherence of RMA operations</a><br>
9.3.6 : <a href="mpi-onesided.html#Request-basedoperations">Request-based operations</a><br>
9.3.7 : <a href="mpi-onesided.html#Atomicoperations">Atomic operations</a><br>
9.3.7.1 : <a href="mpi-onesided.html#Acasestudyinatomicoperations">A case study in atomic operations</a><br>
9.4 : <a href="mpi-onesided.html#Passivetargetsynchronization">Passive target synchronization</a><br>
9.4.1 : <a href="mpi-onesided.html#Locktypes">Lock types</a><br>
9.4.2 : <a href="mpi-onesided.html#Lockall">Lock all</a><br>
9.4.3 : <a href="mpi-onesided.html#Completionandconsistencyinpassivetargetsynchronization">Completion and consistency in passive target synchronization</a><br>
9.4.3.1 : <a href="mpi-onesided.html#Localcompletion">Local completion</a><br>
9.4.3.2 : <a href="mpi-onesided.html#Remotecompletion">Remote completion</a><br>
9.4.3.3 : <a href="mpi-onesided.html#Windowsynchronization">Window synchronization</a><br>
9.5 : <a href="mpi-onesided.html#Moreaboutwindowmemory">More about window memory</a><br>
9.5.1 : <a href="mpi-onesided.html#Memorymodels">Memory models</a><br>
9.5.2 : <a href="mpi-onesided.html#Dynamicallyattachedmemory">Dynamically attached memory</a><br>
9.5.3 : <a href="mpi-onesided.html#Windowusagehints">Window usage hints</a><br>
9.5.4 : <a href="mpi-onesided.html#Windowinformation">Window information</a><br>
9.6 : <a href="mpi-onesided.html#Assertions">Assertions</a><br>
9.7 : <a href="mpi-onesided.html#Implementation">Implementation</a><br>
9.8 : <a href="mpi-onesided.html#Reviewquestions">Review questions</a><br>
<a href="index.html">Back to Table of Contents</a>
<h1>9 MPI topic: One-sided communication</h1>
<!-- TranslatingLineGenerator file ['file'] -->
</p>

<!-- index -->
<!-- index -->
<!-- index -->
<p name="switchToTextMode">

Above, you saw  point-to-point operations of the two-sided type:
they require the co-operation of a sender and
receiver. This co-operation could be loose: you can post a receive
with 
<tt>MPI_ANY_SOURCE</tt>
 as sender, but there had to be both a send and
receive call. This two-sidedness can be limiting. Consider code where the receiving
process is a dynamic function of the data:
<!-- environment: lstlisting start embedded generator -->
</p>
<!-- environment block purpose: [[ environment=lstlisting ]] -->
<lstlisting>
<pre>
x = f();
p = hash(x);
MPI_Send( x, /* to: */ p );
</pre>
</lstlisting>
<!-- environment: lstlisting end embedded generator -->
<p name="switchToTextMode">
The problem is now: how does 
<tt>p</tt>
 know to post a receive,
and how does everyone else know not to?
</p>

<p name="switchToTextMode">
In this section, you will see one-sided communication
routines where a process
can do a `put' or `get' operation, writing data to or reading it from
another processor, without that other processor's involvement.
</p>

<p name="switchToTextMode">
In one-sided MPI operations,
known as 
<span title="acronym" ><i>RMA</i></span>
 operations in the standard,
or as 
<span title="acronym" ><i>RDMA</i></span>
 in other literature,
there
are still two processes involved: the 
<i>origin</i>
, which is the
process that originates the transfer, whether this is a `put' or a `get',
and the 
<i>target</i>
 whose
memory is being accessed. Unlike with two-sided operations, the target
does not perform an action that is the counterpart of the action on the origin.
</p>

<p name="switchToTextMode">
That does not mean that the origin can access arbitrary data on the target
at arbitrary times. First of all, one-sided communication in MPI
is limited to accessing only a specifically declared memory area on the target:
the target declares an area of
user-space memory that is accessible to other processes. This is known
as a 
<i>window</i>
. Windows limit how origin processes can access
the target's memory: you can only `get' data from a window or `put' it
into a window; all the other memory is not reachable from other processes.
On the origin there is no such limitation;
any data can function as the source of a `put'
or the recipient of a `get operation.
</p>

<p name="switchToTextMode">
The alternative to having windows is to use 
<i>distributed shared memory</i>
or 
<i>virtual shared memory</i>
: memory is distributed but acts as if
it shared. The so-called 
<span title="acronym" ><i>PGAS</i></span>
 languages such as 
<span title="acronym" ><i>UPC</i></span>
 use this model.
The MPI 
<span title="acronym" ><i>RMA</i></span>
 model makes it possible to
lock a window which makes programming slightly more cumbersome, but the
implementation more efficient.
</p>

<p name="switchToTextMode">
Within one-sided communication, MPI has two modes: active RMA and
passive RMA. In 
<i>active RMA</i>
, or 
<i>active target synchronization</i>
,
the target sets boundaries on the time period (the `epoch')
during which its window can be accessed.
The main advantage
of this mode is that the origin program can perform many small transfers, which are
aggregated behind the scenes. Active RMA acts much like asynchronous transfer with a
concluding 
<tt>MPI_Waitall</tt>
.
</p>

<p name="switchToTextMode">
In 
<i>passive RMA</i>
, or 
<i>passive target synchronization</i>
,
the target process puts no limitation on when its window can be accessed.
(
<span title="acronym" ><i>PGAS</i></span>
 languages such as 
<span title="acronym" ><i>UPC</i></span>
 are based on this model: data is
simply read or written at will.)
While
intuitively it is attractive to be able to write to and read from a target at
arbitrary time,
there are problems. For instance, it requires a remote agent on the target,
which may interfere with execution of the main thread, or conversely it may not be
activated at the optimal time. Passive RMA is also very hard to debug and can lead
to strange deadlocks.
</p>

<p name="switchToTextMode">

<h2><a id="Windows">9.1</a> Windows</h2>
<p name=crumbs>
crumb trail:  > <a href="mpi-onesided.html">mpi-onesided</a> > <a href="mpi-onesided.html#Windows">Windows</a>
</p>

<!-- index -->
</p>

<!-- environment: figure start embedded generator -->
<!-- environment block purpose: [[ environment=figure ]] -->
<figure>
<float mode=figure>
<!-- TranslatingLineGenerator figure ['figure'] -->
<img src="graphics/one-sided-window.jpeg" width=800></img>
<p name="caption">
FIGURE 9.1: Collective definition of a window for one-sided data access
</p>

</float>
</figure>
<!-- environment: figure end embedded generator -->
<p name="switchToTextMode">

In one-sided communication, each processor can make an area of memory,
called a 
<i>window</i>
, available to one-sided transfers.
This is stored in a variable of type 
<tt>MPI_Win</tt>
.
A&nbsp;process can put an arbitrary item from its own memory
(not limited to any window) to the window of another process,
or get something from the other process'
window in its own memory.
</p>

<p name="switchToTextMode">
A window can be characteristized as follows:
<!-- environment: itemize start embedded generator -->
</p>
<!-- environment block purpose: [[ environment=itemize ]] -->
<itemize>
<ul>
<!-- TranslatingLineGenerator itemize ['itemize'] -->
<li>
The window is defined on a communicator, so the create call
  is collective; see figure&nbsp;
9.1
.
<li>
The window size can be set individually on each process.
  A&nbsp;zero size is allowed, but since window creation is collective,
  it is not possible to skip the create call.
<li>
You can set a `displacement unit' for the window: this is a number of
  bytes that will be used as the indexing unit. For example if you use
  
<tt>sizeof(double)</tt>
 as the displacement unit,
  an&nbsp;
<tt>MPI_Put</tt>
 to location&nbsp;8 will go to the 8th double.
  That's easier than having to specify the 64th byte.
<li>
The window is the target of data in a put operation, or the
  source of data in a get operation; see figure&nbsp;
9.2
.
<li>
There can be memory associated with a window, so it needs to be
  freed explicitly with 
<tt>MPI_Win_free</tt>
.
</ul>
</itemize>
<!-- environment: itemize end embedded generator -->
<p name="switchToTextMode">

The typical calls involved are:
<!-- environment: lstlisting start embedded generator -->
</p>
<!-- environment block purpose: [[ environment=lstlisting ]] -->
<lstlisting>
<pre>
MPI_Info info;
MPI_Win window;
MPI_Win_allocate( /* size info */, info, comm, &memory, &window );
// do put and get calls
MPI_Win_free( &window );
</pre>
</lstlisting>
<!-- environment: lstlisting end embedded generator -->
<p name="switchToTextMode">

<!-- environment: figure start embedded generator -->
</p>
<!-- environment block purpose: [[ environment=figure ]] -->
<figure>
<float mode=figure>
<!-- TranslatingLineGenerator figure ['figure'] -->
<img src="graphics/one-sided-getput.jpeg" width=800></img>
<p name="caption">
FIGURE 9.2: Put and get between process memory and windows
</p>

</float>
</figure>
<!-- environment: figure end embedded generator -->
<p name="switchToTextMode">

<h3><a id="Windowcreationandallocation">9.1.1</a> Window creation and allocation</h3>
<p name=crumbs>
crumb trail:  > <a href="mpi-onesided.html">mpi-onesided</a> > <a href="mpi-onesided.html#Windows">Windows</a> > <a href="mpi-onesided.html#Windowcreationandallocation">Window creation and allocation</a>
</p>

<!-- index -->
</p>

<p name="switchToTextMode">
The memory for a window is at first sight ordinary data in user space. There are multiple
ways you can associate data with a window:
<!-- environment: enumerate start embedded generator -->
</p>
<!-- environment block purpose: [[ environment=enumerate ]] -->
<enumerate>
<ol>
<!-- TranslatingLineGenerator enumerate ['enumerate'] -->
<li>
You can pass a user buffer to
<div class="card">
  <div class="card-header" id="headingOne">
    <h5 class="mb-0">
      <button class="btn btn-link" data-toggle="collapse" data-target="#MPI_Win_create" aria-expanded="false" aria-controls="MPI_Win_create">
        Routine reference: MPI_Win_create
      </button>
    </h5>
  </div>
  <div id="MPI_Win_create" class="collapse">
  <pre>
C:
int MPI_Win_create
   (void *base, MPI_Aint size, int disp_unit,
    MPI_Info info, MPI_Comm comm, MPI_Win *win)

Fortran:
MPI_Win_create(base, size, disp_unit, info, comm, win, ierror)
TYPE(*), DIMENSION(..), ASYNCHRONOUS :: base
INTEGER(KIND=MPI_ADDRESS_KIND), INTENT(IN) :: size
INTEGER, INTENT(IN) :: disp_unit
TYPE(MPI_Info), INTENT(IN) :: info
TYPE(MPI_Comm), INTENT(IN) :: comm
TYPE(MPI_Win), INTENT(OUT) :: win
INTEGER, OPTIONAL, INTENT(OUT) :: ierror

Python:
MPI.Win.Create
   (memory, int disp_unit=1,
    Info info=INFO_NULL, Intracomm comm=COMM_SELF)
</pre>
</div>
</div>
<i>MPI_Win_create</i>
. This buffer can be an ordinary array,
  or it can be created with 
<tt>MPI_Alloc_mem</tt>
.
  (In the former case, it may not be possible to lock the window;
  section&nbsp;
<a href="http://pages.tacc.utexas.edu/~eijkhout/pcse/html/mpi-onesided.html#Passivetargetsynchronization">9.4</a>
.)
<li>
You can let MPI do the allocation, so that MPI can perform various
  optimizations regarding placement of the memory. The user code then
  receives the pointer to the data from MPI. This can again be done in two ways:
<!-- environment: itemize start embedded generator -->
</p>
<!-- environment block purpose: [[ environment=itemize ]] -->
<itemize>
<ul>
<!-- TranslatingLineGenerator itemize ['itemize'] -->
<li>
Use 
<div class="card">
  <div class="card-header" id="headingOne">
    <h5 class="mb-0">
      <button class="btn btn-link" data-toggle="collapse" data-target="#MPI_Win_allocate" aria-expanded="false" aria-controls="MPI_Win_allocate">
        Routine reference: MPI_Win_allocate
      </button>
    </h5>
  </div>
  <div id="MPI_Win_allocate" class="collapse">
  <pre>
Semantics:
MPI_WIN_ALLOCATE(size, disp_unit, info, comm, baseptr, win)

Input parameters:
size: size of local window in bytes (non-negative integer)
disp_unit local unit size for displacements, in bytes (positive
integer)
info: info argument (handle)
comm: intra-communicator (handle)

Output parameters:
baseptr: address of local allocated window segment (choice)
win: window object returned by the call (handle)

C:
int MPI_Win_allocate
   (MPI_Aint size, int disp_unit, MPI_Info info,
    MPI_Comm comm, void *baseptr, MPI_Win *win)

Fortran:
MPI_Win_allocate
   (size, disp_unit, info, comm, baseptr, win, ierror)
USE, INTRINSIC :: ISO_C_BINDING, ONLY : C_PTR
INTEGER(KIND=MPI_ADDRESS_KIND), INTENT(IN) :: size
INTEGER, INTENT(IN) :: disp_unit
TYPE(MPI_Info), INTENT(IN) :: info
TYPE(MPI_Comm), INTENT(IN) :: comm
TYPE(C_PTR), INTENT(OUT) :: baseptr
TYPE(MPI_Win), INTENT(OUT) :: win
INTEGER, OPTIONAL, INTENT(OUT) :: ierror
</pre>
</div>
</div>
<i>MPI_Win_allocate</i>
 to create the data and the
    window in one call.
<li>
If a communicator is on a shared memory (see
    section&nbsp;
<a href="http://pages.tacc.utexas.edu/~eijkhout/pcse/html/mpi-shared.html#Recognizingsharedmemory">12.1</a>
) you can create a window in that
    shared memory with 
<tt>MPI_Win_allocate_shared</tt>
.
    This will be useful for
    
<i>MPI shared memory</i>

<!-- index -->
;
    see chapter&nbsp;
<a href="http://pages.tacc.utexas.edu/~eijkhout/pcse/html/mpi-shared.html">MPI topic: Shared memory</a>
.
</ul>
</itemize>
<!-- environment: itemize end embedded generator -->
<li>
Finally, you can create a window with
<tt>MPI_Win_create_dynamic</tt>
 which postpones the allocation;
  see section&nbsp;
<a href="http://pages.tacc.utexas.edu/~eijkhout/pcse/html/mpi-onesided.html#Dynamicallyattachedmemory">9.5.2</a>
.
</ol>
</enumerate>
<!-- environment: enumerate end embedded generator -->
<p name="switchToTextMode">

First of all, 
<tt>MPI_Win_create</tt>
creates a window from a pointer to memory.
The data array must not be 
<tt>PARAMETER</tt>
 or 
<tt>static const</tt>
.
</p>

<p name="switchToTextMode">
The size parameter is measured in bytes. In&nbsp;C this can be done
with the 
<tt>sizeof</tt>
 operator;
<div class="card">
  <div class="card-header" id="headingOne">
    <h5 class="mb-0">
      <button class="btn btn-link" data-toggle="collapse" data-target="#windowsizeof" aria-expanded="false" aria-controls="windowsizeof">
        C Code: windowsizeof
      </button>
    </h5>
  </div>
  <div id="windowsizeof" class="collapse">
  <pre>
// putfencealloc.c
MPI_Win the_window;
int *window_data;
MPI_Win_allocate(2*sizeof(int),sizeof(int),
		   MPI_INFO_NULL,comm,
		   &window_data,&the_window);
</pre>
</div>
</div>
for doing this calculation in Fortran, see section&nbsp;
<a href="http://pages.tacc.utexas.edu/~eijkhout/pcse/html/mpi.html#Assumed-shapearrays">15.3.1</a>
.
</p>

<!-- environment: pythonnote start embedded generator -->
<!-- environment block purpose: [[ environment=pythonnote ]] -->
<remark>
<b>Python note</b>
<!-- TranslatingLineGenerator pythonnote ['pythonnote'] -->
<p name="switchToTextMode">
  For computing the displacement in bytes,
  here is a good way for finding the size of 
<i>numpy</i>
 datatypes:
<div class="card">
  <div class="card-header" id="headingOne">
    <h5 class="mb-0">
      <button class="btn btn-link" data-toggle="collapse" data-target="#windispp" aria-expanded="false" aria-controls="windispp">
        Python Code: windispp
      </button>
    </h5>
  </div>
  <div id="windispp" class="collapse">
  <pre>
## putfence.py
intsize = np.dtype('int').itemsize
window_data = np.zeros(2,dtype=np.int)
win = MPI.Win.Create(window_data,intsize,comm=comm)
</pre>
</div>
</div>
</remark>
<!-- environment: pythonnote end embedded generator -->
<p name="switchToTextMode">

Next, one can obtain the memory from MPI by using
which has the data pointer as output. Note the 
<tt>void*</tt>
 in the
C&nbsp;signature; it is still necessary to pass a pointer to a pointer:
<!-- environment: lstlisting start embedded generator -->
</p>
<!-- environment block purpose: [[ environment=lstlisting ]] -->
<lstlisting>
<pre>
double *window_data;
MPI_Win_allocate( ... &window_data ... );
</pre>
</lstlisting>
<!-- environment: lstlisting end embedded generator -->
<p name="switchToTextMode">
The routine 
<div class="card">
  <div class="card-header" id="headingOne">
    <h5 class="mb-0">
      <button class="btn btn-link" data-toggle="collapse" data-target="#MPI_Alloc_mem" aria-expanded="false" aria-controls="MPI_Alloc_mem">
        Routine reference: MPI_Alloc_mem
      </button>
    </h5>
  </div>
  <div id="MPI_Alloc_mem" class="collapse">
  <pre>
int MPI_Alloc_mem(MPI_Aint size, MPI_Info info, void *baseptr)
</pre>
</div>
</div>
<i>MPI_Alloc_mem</i>
 performs only the allocation
part of 
<tt>MPI_Win_allocate</tt>
, after which you need to
<tt>MPI_Win_create</tt>
.
<!-- environment: itemize start embedded generator -->
</p>
<!-- environment block purpose: [[ environment=itemize ]] -->
<itemize>
<ul>
<!-- TranslatingLineGenerator itemize ['itemize'] -->
<li>
  An error of 
<tt>MPI_ERR_NO_MEM</tt>
 indicates that
  no memory could be allocated.
\begin{mpifournote}
{Info key for alignment}
<li>
    Allocated memory can be aligned by specifying an 
<tt>MPI_Info</tt>
 key
    of 
<tt>mpi_minimum_memory_alignment</tt>
.
\end{mpifournote}
</ul>
</itemize>
<!-- environment: itemize end embedded generator -->
<p name="switchToTextMode">

This memory is freed with
<!-- environment: lstlisting start embedded generator -->
</p>
<!-- environment block purpose: [[ environment=lstlisting ]] -->
<lstlisting>
<pre>
MPI_Free_mem()
</pre>
</lstlisting>
<!-- environment: lstlisting end embedded generator -->
<p name="switchToTextMode">
These calls reduce to 
<tt>malloc</tt>
 and 
<tt>free</tt>
 if there is no special
memory area; SGI is an example where such memory does exist.
</p>

<p name="switchToTextMode">
There will be more discussion of window memory in section&nbsp;
<a href="http://pages.tacc.utexas.edu/~eijkhout/pcse/html/mpi-onesided.html#Memorymodels">9.5.1</a>
.
</p>

<!-- environment: pythonnote start embedded generator -->
<!-- environment block purpose: [[ environment=pythonnote ]] -->
<remark>
<b>Python note</b>
<!-- TranslatingLineGenerator pythonnote ['pythonnote'] -->
<p name="switchToTextMode">
  Unlike in&nbsp;C, the python window allocate call does not return a pointer
  to the buffer memory, but an  <tt>MPI.memory</tt>  object.
  Should you need the bare memory, there are the following options:
<!-- environment: itemize start embedded generator -->
</p>
<!-- environment block purpose: [[ environment=itemize ]] -->
<itemize>
<ul>
<!-- TranslatingLineGenerator itemize ['itemize'] -->
<li>
Window objects expose the Python buffer interface. So you can do Pythonic things like
<!-- environment: lstlisting start embedded generator -->
</p>
<!-- environment block purpose: [[ environment=lstlisting ]] -->
<lstlisting>
<pre>
mview = memoryview(win)
array = numpy.frombuffer(win, dtype='i4')
</pre>
</lstlisting>
<!-- environment: lstlisting end embedded generator -->
<li>
  If you really want the raw base pointer (as an integer), you can do any of these:
<!-- environment: lstlisting start embedded generator -->
</p>
<!-- environment block purpose: [[ environment=lstlisting ]] -->
<lstlisting>
<pre>
base, size, disp_unit = win.atts
base = win.Get_attr(MPI.WIN_BASE)
</pre>
</lstlisting>
<!-- environment: lstlisting end embedded generator -->
<li>
You can use mpi4py's builtin memoryview/buffer-like type, but I
  do not recommend it, much better to use NumPy as above:
<!-- environment: lstlisting start embedded generator -->
</p>
<!-- environment block purpose: [[ environment=lstlisting ]] -->
<lstlisting>
<pre>
mem = win.tomemory() # type(mem) is MPI.memory, similar to memoryview, but quite limited in functionality
base = mem.address
size = mem.nbytes
</pre>
</lstlisting>
<!-- environment: lstlisting end embedded generator -->
</ul>
</itemize>
<!-- environment: itemize end embedded generator -->
</remark>
<!-- environment: pythonnote end embedded generator -->
<p name="switchToTextMode">

<!-- index -->
</p>

<h3><a id="Addressarithmetic">9.1.2</a> Address arithmetic</h3>
<p name=crumbs>
crumb trail:  > <a href="mpi-onesided.html">mpi-onesided</a> > <a href="mpi-onesided.html#Windows">Windows</a> > <a href="mpi-onesided.html#Addressarithmetic">Address arithmetic</a>
</p>
<p name="switchToTextMode">

Working with windows involves a certain amount of arithmetic
on addresses, meaning&nbsp;
<tt>MPI_Aint</tt>
.
See 
<tt>MPI_Aint_add</tt>
 and 
<tt>MPI_Aint_diff</tt>
in section&nbsp;
<a href="http://pages.tacc.utexas.edu/~eijkhout/pcse/html/mpi-data.html#Byteaddressingtype">6.2.4</a>
.
</p>

<!-- index -->
<p name="switchToTextMode">

<h2><a id="Activetargetsynchronization:epochs">9.2</a> Active target synchronization: epochs</h2>
<p name=crumbs>
crumb trail:  > <a href="mpi-onesided.html">mpi-onesided</a> > <a href="mpi-onesided.html#Activetargetsynchronization:epochs">Active target synchronization: epochs</a>
</p>

</p>

<p name="switchToTextMode">
One-sided communication has an obvious complication over two-sided: if
you do a put call instead of a send, how does the recipient know that
the data is there? This process of letting the target know the state
of affairs is called `synchronization', and there are various
mechanisms for it. First of all we will consider 
  target synchronization}. Here the target knows when the transfer
may happen (the 
<i>communication epoch</i>
), but does not do
any data-related calls.
</p>

<p name="switchToTextMode">
In this section we look at the first mechanism,
which is to use a 
<i>fence</i>
 operation: 
<div class="card">
  <div class="card-header" id="headingOne">
    <h5 class="mb-0">
      <button class="btn btn-link" data-toggle="collapse" data-target="#MPI_Win_fence" aria-expanded="false" aria-controls="MPI_Win_fence">
        Routine reference: MPI_Win_fence
      </button>
    </h5>
  </div>
  <div id="MPI_Win_fence" class="collapse">
  <pre>
Semantics:
MPI_WIN_FENCE(assert, win)
IN assert: program assertion (integer)
IN win: window object (handle)

C:
int MPI_Win_fence(int assert, MPI_Win win)

F:
MPI_Win_fence(assert, win, ierror)
INTEGER, INTENT(IN) :: assert
TYPE(MPI_Win), INTENT(IN) :: win
INTEGER, OPTIONAL, INTENT(OUT) :: ierror

Python:
win.Fence(self, int assertion=0)
</pre>
</div>
</div>
<i>MPI_Win_fence</i>
.
This operation is collective on the communicator of the window.
(Another, more sophisticated mechanism for active target synchronization
is discussed in section&nbsp;
<a href="http://pages.tacc.utexas.edu/~eijkhout/pcse/html/mpi-onesided.html#Non-globaltargetsynchronization">9.2.2</a>
.)
</p>

<p name="switchToTextMode">
The interval between two fences is known as an 
<i>epoch</i>
.
Roughly speaking, in an epoch you can make one-sided communication calls,
and after the concluding fence all these communications are concluded.
<!-- environment: lstlisting start embedded generator -->
</p>
<!-- environment block purpose: [[ environment=lstlisting ]] -->
<lstlisting>
<pre>
MPI_Win_fence(0,win);
MPI_Get( /* operands */, win);
MPI_Win_fence(0, win);
// the `got' data is available
</pre>
</lstlisting>
<!-- environment: lstlisting end embedded generator -->
<p name="switchToTextMode">
In between the two fences the window is exposed,
and while it is you should not access it locally.
If you absolutely need to access it
locally, you can use an 
<span title="acronym" ><i>RMA</i></span>
 operation for that. Also, there can be only one
remote process that does a 
<tt>put</tt>
; multiple 
<tt>accumulate</tt>
 accesses are allowed.
</p>

<p name="switchToTextMode">
Fences are, together with other window calls, collective operations. That means they
imply some amount of synchronization between processes. Consider:
<!-- environment: lstlisting start embedded generator -->
</p>
<!-- environment block purpose: [[ environment=lstlisting ]] -->
<lstlisting>
<pre>
MPI_Win_fence( ... win ... ); // start an epoch
if (mytid==0) // do lots of work
MPI_Win_fence( ... win ... ); // end the epoch
</pre>
</lstlisting>
<!-- environment: lstlisting end embedded generator -->
<p name="switchToTextMode">
and assume that all processes execute the first fence more or less at the same time.
The zero process does work before it can do the second fence call, but all other
processes can call it immediately. However, they can not finish that second fence call
until all one-sided communication is finished, which means they wait for the zero process.
</p>

<!-- environment: figure start embedded generator -->
<!-- environment block purpose: [[ environment=figure ]] -->
<figure>
<float mode=figure>
<!-- TranslatingLineGenerator figure ['figure'] -->
<img src="graphics/lonestar-twonode-put.jpg" width=800></img>
<p name="switchToTextMode">
  \caption{A trace of a one-sided communication epoch where process zero only originates
  a one-sided transfer}

</float>
</figure>
<!-- environment: figure end embedded generator -->
<p name="switchToTextMode">

As a further restriction, you can not mix 
<tt>MPI_Get</tt>
 with 
<tt>MPI_Put</tt>
or 
<tt>MPI_Accumulate</tt>
 calls in a single epoch. Hence, we can
characterize an epoch as an 
<i>access epoch</i>
 on the
origin, and as an 
<i>exposure epoch</i>
 on the target.
</p>

<h3><a id="Fenceassertions">9.2.1</a> Fence assertions</h3>
<p name=crumbs>
crumb trail:  > <a href="mpi-onesided.html">mpi-onesided</a> > <a href="mpi-onesided.html#Activetargetsynchronization:epochs">Active target synchronization: epochs</a> > <a href="mpi-onesided.html#Fenceassertions">Fence assertions</a>
</p>
<p name="switchToTextMode">

You can give various hints to the system about this epoch versus the ones
before and after through the 
<tt>assert</tt>
 parameter.
<!-- environment: itemize start embedded generator -->
</p>
<!-- environment block purpose: [[ environment=itemize ]] -->
<itemize>
<ul>
<!-- TranslatingLineGenerator itemize ['itemize'] -->
<li>
<tt>MPI_MODE_NOSTORE</tt>
  This value can be specified or not per process.
<li>
<tt>MPI_MODE_NOPUT</tt>
  This value can be specified or not per process.
<li>
<tt>MPI_MODE_NOPRECEDE</tt>
  This value has to be specified or not the same on all processes.
<li>
<tt>MPI_MODE_NOSUCCEED</tt>
  This value has to be specified or not the same on all processes.
</ul>
</itemize>
<!-- environment: itemize end embedded generator -->
<p name="switchToTextMode">

Example:
<!-- environment: lstlisting start embedded generator -->
</p>
<!-- environment block purpose: [[ environment=lstlisting ]] -->
<lstlisting>
<pre>
MPI_Win_fence((MPI_MODE_NOPUT | MPI_MODE_NOPRECEDE), win);
MPI_Get( /* operands */, win);
MPI_Win_fence(MPI_MODE_NOSUCCEED, win);
</pre>
</lstlisting>
<!-- environment: lstlisting end embedded generator -->
<p name="switchToTextMode">

Assertions are an integer parameter: you can combine assertions by
adding them or using logical-or.
The value zero is always correct. For further information, see
section&nbsp;
<a href="http://pages.tacc.utexas.edu/~eijkhout/pcse/html/mpi-onesided.html#Assertions">9.6</a>
.
</p>

<h3><a id="Non-globaltargetsynchronization">9.2.2</a> Non-global target synchronization</h3>
<p name=crumbs>
crumb trail:  > <a href="mpi-onesided.html">mpi-onesided</a> > <a href="mpi-onesided.html#Activetargetsynchronization:epochs">Active target synchronization: epochs</a> > <a href="mpi-onesided.html#Non-globaltargetsynchronization">Non-global target synchronization</a>
</p>

<p name="switchToTextMode">

The `fence' mechanism (section&nbsp;
<a href="http://pages.tacc.utexas.edu/~eijkhout/pcse/html/mpi-onesided.html#Activetargetsynchronization:epochs">9.2</a>
) uses a global synchronization on the
communicator of the window, giving a program a 
<span title="acronym" ><i>BSP</i></span>
 like character.
As such it is good for applications where
the processes are largely synchronized, but it may
lead to performance inefficiencies if processors are not in step which each other.
Also, global synchronization may have hardware support, making this less
restrictive than it may at first seem.
</p>

<p name="switchToTextMode">
There is a mechanism that is more fine-grained, by using synchronization only
on a processor 
<i>group</i>
. This takes four different calls, two for starting
and two for ending the epoch, separately for target and origin.
<!-- environment: figure start embedded generator -->
</p>
<!-- environment block purpose: [[ environment=figure ]] -->
<figure>
<float mode=figure>
<!-- TranslatingLineGenerator figure ['figure'] -->
<img src="graphics/postwait.jpeg" width=800></img>
<p name="caption">
FIGURE 9.4: Window locking calls in fine-grained active target synchronization
</p>

</float>
</figure>
<!-- environment: figure end embedded generator -->
<p name="switchToTextMode">

You start and complete an 
<i>exposure epoch</i>
 with
<tt>MPI_Win_post</tt>
&nbsp;/ 
<tt>MPI_Win_wait</tt>
:
<!-- environment: lstlisting start embedded generator -->
</p>
<!-- environment block purpose: [[ environment=lstlisting ]] -->
<lstlisting>
<pre>
int MPI_Win_post(MPI_Group group, int assert, MPI_Win win)
int MPI_Win_wait(MPI_Win win)
</pre>
</lstlisting>
<!-- environment: lstlisting end embedded generator -->
<p name="switchToTextMode">
In other words, this turns your window into the 
<i>target</i>
 for a remote access.
(There is a non-blocking version 
<tt>MPI_Win_test</tt>
of 
<tt>MPI_Win_wait</tt>
.
See also 
<tt>MPI_Win_complete</tt>
.)
</p>

<p name="switchToTextMode">
You start and complete an 
<i>access epoch</i>
 with%
<tt>MPI_Win_start</tt>
&nbsp;/ 
<tt>MPI_Win_complete</tt>
:
<!-- environment: lstlisting start embedded generator -->
</p>
<!-- environment block purpose: [[ environment=lstlisting ]] -->
<lstlisting>
<pre>
int MPI_Win_start(MPI_Group group, int assert, MPI_Win win)
int MPI_Win_complete(MPI_Win win)
</pre>
</lstlisting>
<!-- environment: lstlisting end embedded generator -->
<p name="switchToTextMode">
In other words, these calls border the access to a remote window, with the current processor
being the 
<i>origin</i>
 of the remote access.
</p>

<p name="switchToTextMode">
In the following snippet a single processor puts data on one
other. Note that they both have their own definition of the group, and
that the receiving process only does the post and wait calls.
<div class="card">
  <div class="card-header" id="headingOne">
    <h5 class="mb-0">
      <button class="btn btn-link" data-toggle="collapse" data-target="#postwaittwo" aria-expanded="false" aria-controls="postwaittwo">
        C Code: postwaittwo
      </button>
    </h5>
  </div>
  <div id="postwaittwo" class="collapse">
  <pre>
// postwaitwin.c
if (procno==origin) {
  MPI_Group_incl(all_group,1,&target,&two_group);
// access
  MPI_Win_start(two_group,0,the_window);
  MPI_Put( /* data on origin: */   &my_number, 1,MPI_INT,
           /* data on target: */   target,0,   1,MPI_INT,
	       the_window);
  MPI_Win_complete(the_window);
}

if (procno==target) {
  MPI_Group_incl(all_group,1,&origin,&two_group);
// exposure
  MPI_Win_post(two_group,0,the_window);
  MPI_Win_wait(the_window);
}
</pre>
</div>
</div>
</p>

<p name="switchToTextMode">
Both pairs of operations declare a
<i>group of processors</i>
; see section&nbsp;
<a href="http://pages.tacc.utexas.edu/~eijkhout/pcse/html/mpi-comm.html#Processgroups">7.5.1</a>
for how to get such a group from a communicator.
On an origin processor you would specify a group that includes the targets
you will interact with, on a target processor you specify a group
that includes the possible origins.
</p>

<h2><a id="Put,get,accumulate">9.3</a> Put, get, accumulate</h2>
<p name=crumbs>
crumb trail:  > <a href="mpi-onesided.html">mpi-onesided</a> > <a href="mpi-onesided.html#Put,get,accumulate">Put, get, accumulate</a>
</p>

<p name="switchToTextMode">

We will now look at the first three routines for doing one-sided
operations: the Put, Get, and Accumulate call. (We will look at
so-called `atomic' operations in section&nbsp;
<a href="http://pages.tacc.utexas.edu/~eijkhout/pcse/html/mpi-onesided.html#Atomicoperations">9.3.7</a>
.)
These calls are somewhat
similar to a Send, Receive and Reduce, except that of course only one
process makes a call.
Since one process does all the work, its calling sequence contains
both a description of the data on the origin (the calling process) and
the target (the affected other process).
</p>

<p name="switchToTextMode">
As in the two-sided case, 
<tt>MPI_PROC_NULL</tt>
 can be used as
a target rank.
</p>

<p name="switchToTextMode">
The Put/Get/Accumulate routines have an 
<tt>MPI_Op</tt>
argument that can be any of the usual operators, but no
user-defined ones (see section&nbsp;
<a href="http://pages.tacc.utexas.edu/~eijkhout/pcse/html/mpi-collective.html#Pre-definedoperators">3.10.1</a>
).
</p>

<h3><a id="Put">9.3.1</a> Put</h3>
<p name=crumbs>
crumb trail:  > <a href="mpi-onesided.html">mpi-onesided</a> > <a href="mpi-onesided.html#Put,get,accumulate">Put, get, accumulate</a> > <a href="mpi-onesided.html#Put">Put</a>
</p>

<p name="switchToTextMode">

The 
<div class="card">
  <div class="card-header" id="headingOne">
    <h5 class="mb-0">
      <button class="btn btn-link" data-toggle="collapse" data-target="#MPI_Put" aria-expanded="false" aria-controls="MPI_Put">
        Routine reference: MPI_Put
      </button>
    </h5>
  </div>
  <div id="MPI_Put" class="collapse">
  <pre>
C:
int MPI_Put(
  const void *origin_addr, int origin_count, MPI_Datatype origin_datatype,
  int target_rank,
  MPI_Aint target_disp, int target_count, MPI_Datatype target_datatype,
  MPI_Win win)

Semantics:
IN origin_addr: initial address of origin buffer (choice)
IN origin_count: number of entries in origin buffer (non-negative integer)
IN origin_datatype: datatype of each entry in origin buffer (handle)
IN target_rank: rank of target (non-negative integer)
IN target_disp: displacement from start of window to target buffer (non-negative integer)
IN target_count: number of entries in target buffer (non-negative integer)
IN target_datatype: datatype of each entry in target buffer (handle)
IN win: window object used for communication (handle)

Fortran:
MPI_Put(origin_addr, origin_count, origin_datatype,
  target_rank, target_disp, target_count, target_datatype, win, ierror)
TYPE(*), DIMENSION(..), INTENT(IN), ASYNCHRONOUS :: origin_addr
INTEGER, INTENT(IN) :: origin_count, target_rank, target_count
TYPE(MPI_Datatype), INTENT(IN) :: origin_datatype, target_datatype
INTEGER(KIND=MPI_ADDRESS_KIND), INTENT(IN) :: target_disp
TYPE(MPI_Win), INTENT(IN) :: win
INTEGER, OPTIONAL, INTENT(OUT) :: ierror

Python:

win.Put(self, origin, int target_rank, target=None)
</pre>
</div>
</div>
<i>MPI_Put</i>
 call can be considered as a one-sided
send. As such, it needs to specify
<!-- environment: itemize start embedded generator -->
</p>
<!-- environment block purpose: [[ environment=itemize ]] -->
<itemize>
<ul>
<!-- TranslatingLineGenerator itemize ['itemize'] -->
<li>
the target rank
<li>
the data to be sent from the origin, and
<li>
the location where it is to be written on the target.
</ul>
</itemize>
<!-- environment: itemize end embedded generator -->
<p name="switchToTextMode">

The description of the data on the origin is the usual trio of
buffer/count/datatype. However, the description of the data on the
target is more complicated. It has a count and a datatype, but instead
of an address it has a
<i>displacement</i>
<!-- index -->
 with respect to the
start of the window on the target. This displacement can be given in
bytes, so its type is 
<tt>MPI_Aint</tt>
, but strictly speaking
it is a multiple of the displacement unit that was specified in the
window definition.
</p>

<p name="switchToTextMode">
Specifically, data is written starting at
\[
 \mathtt{window\_base} + \mathtt{target\_disp}\times \mathtt{disp\_unit}. 
\]
</p>

<img src="graphics/windowdisp.png" width=800></img>
<p name="switchToTextMode">

Here is a single put operation. Note that the window create and window fence calls
are collective, so they have to be performed on all processors
of the communicator that was used in the create call.
<div class="card">
  <div class="card-header" id="headingOne">
    <h5 class="mb-0">
      <button class="btn btn-link" data-toggle="collapse" data-target="#putfence" aria-expanded="false" aria-controls="putfence">
        C Code: putfence
      </button>
    </h5>
  </div>
  <div id="putfence" class="collapse">
  <pre>
// putfence.c
MPI_Win the_window;
MPI_Win_create
  (&window_data,2*sizeof(int),sizeof(int),
   MPI_INFO_NULL,comm,&the_window);
MPI_Win_fence(0,the_window);
if (procno==0) {
  MPI_Put
    ( /* data on origin: */   &my_number, 1,MPI_INT,
	/* data on target: */   other,1,    1,MPI_INT,
	the_window);
}
MPI_Win_fence(0,the_window);
MPI_Win_free(&the_window);
</pre>
</div>
</div>
</p>

<!-- environment: fortrannote start embedded generator -->
<!-- environment block purpose: [[ environment=fortrannote ]] -->
<remark>
<b>Fortran note</b>
<p name="remark">
<!-- TranslatingLineGenerator fortrannote ['fortrannote'] -->
  The 
<tt>disp_unit</tt>
 variable is declared as an integer of `kind'
<tt>MPI_ADDRESS_KIND</tt>
:
<div class="card">
  <div class="card-header" id="headingOne">
    <h5 class="mb-0">
      <button class="btn btn-link" data-toggle="collapse" data-target="#fdisplacementtype" aria-expanded="false" aria-controls="fdisplacementtype">
        Fortran Code: fdisplacementtype
      </button>
    </h5>
  </div>
  <div id="fdisplacementtype" class="collapse">
  <pre>
!! putfence.F90
  integer(kind=MPI_ADDRESS_KIND) :: target_displacement
     target_displacement = 1
     call MPI_Put( my_number, 1,MPI_INTEGER, &
          other,target_displacement, &
          1,MPI_INTEGER, &
          the_window)
</pre>
</div>
</div>
</p>

<p name="switchToTextMode">
Prior to \fstandard{2008},
specifying a literal constant, such as&nbsp;
<tt>0</tt>
, could lead to bizarre
runtime errors; the solution was to specify a zero-valued variable
of the right type.
With the 
<tt>mpi_f08</tt>
 module this
is no longer allowed. Instead you get an error such as
<!-- environment: verbatim start embedded generator -->
</p>
<!-- environment block purpose: [[ environment=verbatim ]] -->
<verbatim>
<pre>
error #6285: There is no matching specific subroutine for this generic subroutine call.   [MPI_PUT]
</pre>
</verbatim>
<!-- environment: verbatim end embedded generator -->
</remark>
<!-- environment: fortrannote end embedded generator -->
<p name="switchToTextMode">
{Displacement unit}
</p>

<!-- environment: exercise start embedded generator -->
<!-- environment block purpose: [[ environment=exercise ]] -->
<exercise>
<b>Exercise</b>
<p name="exercise">
<!-- TranslatingLineGenerator exercise ['exercise'] -->

  Revisit exercise&nbsp;
<a href="http://pages.tacc.utexas.edu/~eijkhout/pcse/html/mpi-ptp.html#Serialization">4.1.4.3</a>
 and solve it using
<tt>MPI_Put</tt>
.
<!-- skeleton start: rightput -->
<button id="runBtnrightput">Compile and run rightput</button>
<div id="editorDivrightput" 
     style="height:125px;border:1px solid black; 
     resize:vertical; overflow: hidden;"></div>
<pre id="outputPrerightput"></pre>
<script name="defSkeletonrightput">
let examplerightput = new Example("runBtnrightput",
    "editorDivrightput", "outputPrerightput", 
    "skeletons/rightput.c", 
    "mpicc skeletons/rightput.c && mpiexec -n 4 ./a.out" );
examplerightput.initialize();
</script>
<!-- skeleton end: rightput -->
</p name="exercise">
</exercise>
<!-- environment: exercise end embedded generator -->
<p name="switchToTextMode">

<!-- environment: exercise start embedded generator -->
</p>
<!-- environment block purpose: [[ environment=exercise ]] -->
<exercise>
<b>Exercise</b>
<p name="exercise">
<!-- TranslatingLineGenerator exercise ['exercise'] -->

  Write code where:
<!-- environment: itemize start embedded generator -->
</p>
<!-- environment block purpose: [[ environment=itemize ]] -->
<itemize>
<ul>
<!-- TranslatingLineGenerator itemize ['itemize'] -->
<li>
    process&nbsp;0 computes a random number&nbsp;$r$
<li>
if $r&lt;.5$, zero writes in the window on&nbsp;1;
<li>
if $r\geq .5$, zero writes in the window on&nbsp;2.
</ul>
</itemize>
<!-- environment: itemize end embedded generator -->
<!-- skeleton start: randomput -->
<button id="runBtnrandomput">Compile and run randomput</button>
<div id="editorDivrandomput" 
     style="height:125px;border:1px solid black; 
     resize:vertical; overflow: hidden;"></div>
<pre id="outputPrerandomput"></pre>
<script name="defSkeletonrandomput">
let examplerandomput = new Example("runBtnrandomput",
    "editorDivrandomput", "outputPrerandomput", 
    "skeletons/randomput.c", 
    "mpicc skeletons/randomput.c && mpiexec -n 4 ./a.out" );
examplerandomput.initialize();
</script>
<!-- skeleton end: randomput -->
</exercise>
<!-- environment: exercise end embedded generator -->
<!-- environment: answer start embedded generator -->
<!-- environment block purpose: [[ environment=answer ]] -->
<answer>


</answer>
<!-- environment: answer end embedded generator -->
<p name="switchToTextMode">

<h3><a id="Get">9.3.2</a> Get</h3>
<p name=crumbs>
crumb trail:  > <a href="mpi-onesided.html">mpi-onesided</a> > <a href="mpi-onesided.html#Put,get,accumulate">Put, get, accumulate</a> > <a href="mpi-onesided.html#Get">Get</a>
</p>
</p>

<p name="switchToTextMode">
The 
<div class="card">
  <div class="card-header" id="headingOne">
    <h5 class="mb-0">
      <button class="btn btn-link" data-toggle="collapse" data-target="#MPI_Get" aria-expanded="false" aria-controls="MPI_Get">
        Routine reference: MPI_Get
      </button>
    </h5>
  </div>
  <div id="MPI_Get" class="collapse">
  <pre>
C:
int MPI_Get(
  const void *origin_addr, int origin_count, MPI_Datatype origin_datatype,
  int target_rank,
  MPI_Aint target_disp, int target_count, MPI_Datatype target_datatype,
  MPI_Win win)

Semantics:
IN origin_addr: initial address of origin buffer (choice)
IN origin_count: number of entries in origin buffer (non-negative integer)
IN origin_datatype: datatype of each entry in origin buffer (handle)
IN target_rank: rank of target (non-negative integer)
IN target_disp: displacement from start of window to target buffer (non-negative integer)
IN target_count: number of entries in target buffer (non-negative integer)
IN target_datatype: datatype of each entry in target buffer (handle)
IN win: window object used for communication (handle)

Fortran:
MPI_Get(origin_addr, origin_count, origin_datatype,
  target_rank, target_disp, target_count, target_datatype, win, ierror)
TYPE(*), DIMENSION(..), INTENT(IN), ASYNCHRONOUS :: origin_addr
INTEGER, INTENT(IN) :: origin_count, target_rank, target_count
TYPE(MPI_Datatype), INTENT(IN) :: origin_datatype, target_datatype
INTEGER(KIND=MPI_ADDRESS_KIND), INTENT(IN) :: target_disp
TYPE(MPI_Win), INTENT(IN) :: win
INTEGER, OPTIONAL, INTENT(OUT) :: ierror

Python:

win.Get(self, origin, int target_rank, target=None)
</pre>
</div>
</div>
<i>MPI_Get</i>
 call is very similar.
</p>

<p name="switchToTextMode">
Example:
<div class="card">
  <div class="card-header" id="headingOne">
    <h5 class="mb-0">
      <button class="btn btn-link" data-toggle="collapse" data-target="#getfence" aria-expanded="false" aria-controls="getfence">
        C Code: getfence
      </button>
    </h5>
  </div>
  <div id="getfence" class="collapse">
  <pre>
// getfence.c
MPI_Win_create(&other_number,2*sizeof(int),sizeof(int),
               MPI_INFO_NULL,comm,&the_window);
MPI_Win_fence(0,the_window);
if (procno==0) {
  MPI_Get( /* data on origin: */   &my_number, 1,MPI_INT,
	       /* data on target: */   other,1,    1,MPI_INT,
	       the_window);
}
MPI_Win_fence(0,the_window);
</pre>
</div>
</div>
We make a null window on processes that do not participate.
<div class="card">
  <div class="card-header" id="headingOne">
    <h5 class="mb-0">
      <button class="btn btn-link" data-toggle="collapse" data-target="#getfencep" aria-expanded="false" aria-controls="getfencep">
        Python Code: getfencep
      </button>
    </h5>
  </div>
  <div id="getfencep" class="collapse">
  <pre>
## getfence.py
if procid==0 or procid==nprocs-1:
    win_mem = np.empty( 1,dtype=np.float64 )
    win = MPI.Win.Create( win_mem,comm=comm )
else:
    win = MPI.Win.Create( None,comm=comm )

# put data on another process
win.Fence()
if procid==0 or procid==nprocs-1:
    putdata = np.empty( 1,dtype=np.float64 )
    putdata[0] = mydata
    print("[%d] putting %e" % (procid,mydata))
    win.Put( putdata,other )
win.Fence()
</pre>
</div>
</div>
</p>

<h3><a id="Putandgetexample:haloupdate">9.3.3</a> Put and get example: halo update</h3>
<p name=crumbs>
crumb trail:  > <a href="mpi-onesided.html">mpi-onesided</a> > <a href="mpi-onesided.html#Put,get,accumulate">Put, get, accumulate</a> > <a href="mpi-onesided.html#Putandgetexample:haloupdate">Put and get example: halo update</a>
</p>
<p name="switchToTextMode">

<!-- environment: wrapfigure start embedded generator -->
</p>
<!-- environment block purpose: [[ environment=wrapfigure ]] -->
<wrapfigure>
<b>UNKNOWN</b>
<!-- TranslatingLineGenerator wrapfigure ['wrapfigure'] -->
<img src="graphics/core-update.jpeg" width=800></img>
</wrapfigure>
<!-- environment: wrapfigure end embedded generator -->
<p name="switchToTextMode">
{r}{3in}
As an example, let's look at 
<i>halo update</i>
.
The array&nbsp;
<tt>A</tt>
 is updated using the local values and the halo
that comes from bordering processors, either through Put or Get operations.
</p>

<p name="switchToTextMode">
In a first version we separate computation and communication.
Each iteration has two fences. Between the two fences in the loop body
we do the 
<tt>MPI_Put</tt>
 operation; between the second and and first one
of the next iteration there is only computation, so we add the

<tt>NOPRECEDE</tt>
 and 
<tt>NOSUCCEED</tt>
 assertions.
The 
<tt>NOSTORE</tt>
 assertion
states that the local window was not updated: the Put operation only
works on remote windows.
<!-- environment: lstlisting start embedded generator -->
</p>
<!-- environment block purpose: [[ environment=lstlisting ]] -->
<lstlisting>
<pre>
for ( .... ) {
  update(A);
  MPI_Win_fence(MPI_MODE_NOPRECEDE, win);
  for(i=0; i &lt; toneighbors; i++)
    MPI_Put( ... );
  MPI_Win_fence((MPI_MODE_NOSTORE | MPI_MODE_NOSUCCEED), win);
  }
</pre>
</lstlisting>
<!-- environment: lstlisting end embedded generator -->
<p name="switchToTextMode">
For much more about
assertions, see section&nbsp;
<a href="http://pages.tacc.utexas.edu/~eijkhout/pcse/html/mpi-onesided.html#Assertions">9.6</a>
 below.
</p>

<p name="switchToTextMode">
Next, we split the update in the core part, which can be done purely
from local values, and the boundary, which needs local and halo
values. Update of the core can overlap the communication of the halo.
<!-- environment: lstlisting start embedded generator -->
</p>
<!-- environment block purpose: [[ environment=lstlisting ]] -->
<lstlisting>
<pre>
for ( .... ) {
  update_boundary(A);
  MPI_Win_fence((MPI_MODE_NOPUT | MPI_MODE_NOPRECEDE), win);
  for(i=0; i &lt; fromneighbors; i++)
    MPI_Get( ... );
  update_core(A);
  MPI_Win_fence(MPI_MODE_NOSUCCEED, win);
  }
</pre>
</lstlisting>
<!-- environment: lstlisting end embedded generator -->
<p name="switchToTextMode">
The 
<tt>NOPRECEDE</tt>
 and 
<tt>NOSUCCEED</tt>
 assertions still hold, but the

<tt>Get</tt>
 operation implies that instead of 
<tt>NOSTORE</tt>
 in the
second fence, we use 
<tt>NOPUT</tt>
 in the first.
</p>

<h3><a id="Accumulate">9.3.4</a> Accumulate</h3>
<p name=crumbs>
crumb trail:  > <a href="mpi-onesided.html">mpi-onesided</a> > <a href="mpi-onesided.html#Put,get,accumulate">Put, get, accumulate</a> > <a href="mpi-onesided.html#Accumulate">Accumulate</a>
</p>
<p name="switchToTextMode">

A&nbsp;third one-sided routine
is 
<div class="card">
  <div class="card-header" id="headingOne">
    <h5 class="mb-0">
      <button class="btn btn-link" data-toggle="collapse" data-target="#MPI_Accumulate" aria-expanded="false" aria-controls="MPI_Accumulate">
        Routine reference: MPI_Accumulate
      </button>
    </h5>
  </div>
  <div id="MPI_Accumulate" class="collapse">
  <pre>
C:
int MPI_Accumulate
   (const void *origin_addr, int origin_count,MPI_Datatype origin_datatype,
    int target_rank,MPI_Aint target_disp, int target_count,MPI_Datatype target_datatype,
    MPI_Op op, MPI_Win win)
int MPI_Raccumulate
   (const void *origin_addr, int origin_count,MPI_Datatype origin_datatype,
    int target_rank,MPI_Aint target_disp, int target_count,MPI_Datatype target_datatype,
    MPI_Op op, MPI_Win win,MPI_Request *request)

Input Parameters

origin_addr : Initial address of buffer (choice).
origin_count : Number of entries in buffer (nonnegative integer).
origin_datatype : Data type of each buffer entry (handle).
target_rank : Rank of target (nonnegative integer).
target_disp : Displacement from start of window to beginning of target buffer (nonnegative integer).
target_count : Number of entries in target buffer (nonnegative integer).
target_datatype : Data type of each entry in target buffer (handle).
op : Reduce operation (handle).
win : Window object (handle).

Output Parameter

MPI_Raccumulate: RMA request
IERROR (Fortran only): Error status (integer).

Fortran:

MPI_ACCUMULATE
   (ORIGIN_ADDR, ORIGIN_COUNT, ORIGIN_DATATYPE,
    TARGET_RANK,TARGET_DISP, TARGET_COUNT, TARGET_DATATYPE,
    OP, WIN, IERROR)
<type> ORIGIN_ADDR(*)
INTEGER(KIND=MPI_ADDRESS_KIND) :: TARGET_DISP
INTEGER :: ORIGIN_COUNT, ORIGIN_DATATYPE,
           TARGET_RANK, TARGET_COUNT,TARGET_DATATYPE,
           OP, WIN, IERROR
MPI_RACCUMULATE
   (ORIGIN_ADDR, ORIGIN_COUNT, ORIGIN_DATATYPE,
    TARGET_RANK,TARGET_DISP, TARGET_COUNT, TARGET_DATATYPE,
    OP, WIN, REQUEST, IERROR)
<type> ORIGIN_ADDR(*)
INTEGER(KIND=MPI_ADDRESS_KIND) :: TARGET_DISP
INTEGER :: ORIGIN_COUNT, ORIGIN_DATATYPE, TARGET_RANK, TARGET_COUNT, TARGET_DATATYPE,
           OP, WIN, REQUEST, IERROR

Python:
MPI.Win.Accumulate(self, origin, int target_rank, target=None, Op op=SUM)
</pre>
</div>
</div>
<i>MPI_Accumulate</i>
 which does a reduction operation on the results
that are being put.
</p>

<p name="switchToTextMode">
Accumulate is an atomic reduction with remote result.
This means that multiple accumulates to a single target
gives the correct result.
As with 
<tt>MPI_Reduce</tt>
, the
order in which the operands are accumulated is undefined.
</p>

<p name="switchToTextMode">
The same predefined operators are available, but no
user-defined ones. There is one extra operator: 
<tt>MPI_REPLACE</tt>
,
this has the effect that only the last result to arrive is retained.
</p>

<!-- environment: exercise start embedded generator -->
<!-- environment block purpose: [[ environment=exercise ]] -->
<exercise>
<b>Exercise</b>
<p name="exercise">
<!-- TranslatingLineGenerator exercise ['exercise'] -->
  Implement an `all-gather' operation using one-sided communication:
  each processor stores a single number, and you want each processor
  to build up an array that contains the values from all
  processors. Note that you do not need a special case for a processor
  collecting its own value: doing `communication' between a processor
  and itself is perfectly legal.
</p name="exercise">
</exercise>
<!-- environment: exercise end embedded generator -->
<p name="switchToTextMode">

<!-- environment: exercise start embedded generator -->
</p>
<!-- environment block purpose: [[ environment=exercise ]] -->
<exercise>
<b>Exercise</b>
<p name="exercise">
<!-- TranslatingLineGenerator exercise ['exercise'] -->

</p>

<p name="switchToTextMode">
  Implement a shared counter:
<!-- environment: itemize start embedded generator -->
</p>
<!-- environment block purpose: [[ environment=itemize ]] -->
<itemize>
<ul>
<!-- TranslatingLineGenerator itemize ['itemize'] -->
<li>
One process maintains a counter;
<li>
Iterate: all others at random moments update this counter.
<li>
When the counter is no longer positive, everyone stops iterating.
</ul>
</itemize>
<!-- environment: itemize end embedded generator -->
<p name="switchToTextMode">
  The problem here is data synchronization: does everyone see the
  counter the same way?
</p name="exercise">
</exercise>
<!-- environment: exercise end embedded generator -->
<p name="switchToTextMode">

<h3><a id="OrderingandcoherenceofRMAoperations">9.3.5</a> Ordering and coherence of RMA operations</h3>
<p name=crumbs>
crumb trail:  > <a href="mpi-onesided.html">mpi-onesided</a> > <a href="mpi-onesided.html#Put,get,accumulate">Put, get, accumulate</a> > <a href="mpi-onesided.html#OrderingandcoherenceofRMAoperations">Ordering and coherence of RMA operations</a>
</p>
</p>

<p name="switchToTextMode">
There are few guarantees about what happens inside one epoch.
<!-- environment: itemize start embedded generator -->
</p>
<!-- environment block purpose: [[ environment=itemize ]] -->
<itemize>
<ul>
<!-- TranslatingLineGenerator itemize ['itemize'] -->
<li>
No ordering of Get and Put/Accumulate operations: if you do
  both, there is no guarantee whether the Get will find the value
  before or after the update.
<li>
No ordering of multiple Puts. It is safer to do an Accumulate.
</ul>
</itemize>
<!-- environment: itemize end embedded generator -->
<p name="switchToTextMode">
The following operations are well-defined inside one epoch:
<!-- environment: itemize start embedded generator -->
</p>
<!-- environment block purpose: [[ environment=itemize ]] -->
<itemize>
<ul>
<!-- TranslatingLineGenerator itemize ['itemize'] -->
<li>
Instead of multiple Put operations, use Accumulate with
<tt>MPI_REPLACE</tt>
.
<li>
<tt>MPI_Get_accumulate</tt>
 with
<tt>MPI_NO_OP</tt>
 is safe.
<li>
Multiple Accumulate operations from one origin are done in
  program order by default. To allow reordering, for instance to have
  all reads happen after all writes, use the info parameter
  when the window is created; section&nbsp;
<a href="http://pages.tacc.utexas.edu/~eijkhout/pcse/html/mpi-onesided.html#Windowusagehints">9.5.3</a>
.
</ul>
</itemize>
<!-- environment: itemize end embedded generator -->
<p name="switchToTextMode">

<h3><a id="Request-basedoperations">9.3.6</a> Request-based operations</h3>
<p name=crumbs>
crumb trail:  > <a href="mpi-onesided.html">mpi-onesided</a> > <a href="mpi-onesided.html#Put,get,accumulate">Put, get, accumulate</a> > <a href="mpi-onesided.html#Request-basedoperations">Request-based operations</a>
</p>
</p>

<p name="switchToTextMode">
Analogous to 
<tt>MPI_Isend</tt>
 there are request based one-sided operations:
<div class="card">
  <div class="card-header" id="headingOne">
    <h5 class="mb-0">
      <button class="btn btn-link" data-toggle="collapse" data-target="#MPI_Rput" aria-expanded="false" aria-controls="MPI_Rput">
        Routine reference: MPI_Rput
      </button>
    </h5>
  </div>
  <div id="MPI_Rput" class="collapse">
  <pre>
C:
int MPI_Rput(
  const void *origin_addr, int origin_count, MPI_Datatype origin_datatype,
  int target_rank, MPI_Aint target_disp, int target_count, MPI_Datatype target_datatype,
  MPI_Win win, MPI_Request *request)

Semantics:
IN origin_addr: initial address of origin buffer (choice)
IN origin_count: number of entries in origin buffer (non-negative integer)
IN origin_datatype: datatype of each entry in origin buffer (handle)
IN target_rank: rank of target (non-negative integer)
IN target_disp: displacement from start of window to target buffer (non-negative integer)
IN target_count: number of entries in target buffer (non-negative integer)
IN target_datatype: datatype of each entry in target buffer (handle)
IN win: window object used for communication (handle)
OUT request: RMA request (handle)
</pre>
</div>
</div>
<i>MPI_Rput</i>
and similarly 
<tt>MPI_Rget</tt>
 and
<tt>MPI_Raccumulate</tt>
and 
<tt>MPI_Rget_accumulate</tt>
.
</p>

<p name="switchToTextMode">
These only apply to passive target synchronization.
Any 
<tt>MPI_Win_flush...</tt>
 call also terminates these transfers.
</p>

<h3><a id="Atomicoperations">9.3.7</a> Atomic operations</h3>
<p name=crumbs>
crumb trail:  > <a href="mpi-onesided.html">mpi-onesided</a> > <a href="mpi-onesided.html#Put,get,accumulate">Put, get, accumulate</a> > <a href="mpi-onesided.html#Atomicoperations">Atomic operations</a>
</p>

<!-- index -->
<p name="switchToTextMode">

One-sided calls are said to emulate shared memory in MPI, but
the put and get calls are not enough for certain scenarios with shared
data. Consider the scenario where:
</p>

<!-- environment: itemize start embedded generator -->
<!-- environment block purpose: [[ environment=itemize ]] -->
<itemize>
<ul>
<!-- TranslatingLineGenerator itemize ['itemize'] -->
<li>
One process stores a table of work descriptors, and a pointer to
  the first unprocessed descriptor;
<li>
Each process reads the pointer, reads the corresponding
  descriptor, and increments the pointer; and
<li>
A process that has read a descriptor then executes the
  corresponding task.
</ul>
</itemize>
<!-- environment: itemize end embedded generator -->
<p name="switchToTextMode">

The problem is that reading and updating the pointer is not an
<i>atomic operation</i>
it is possible that multiple processes get hold of the same value;
conversely, multiple updates of the pointer may lead to work
descriptors being skipped.
These different overall behaviors, depending on precise timing of lower level events,
are called a 
<i>race condition</i>
.
</p>

<p name="switchToTextMode">
In \mpistandard{3} some atomic routines have been added.
Both 
<div class="card">
  <div class="card-header" id="headingOne">
    <h5 class="mb-0">
      <button class="btn btn-link" data-toggle="collapse" data-target="#MPI_Fetch_and_op" aria-expanded="false" aria-controls="MPI_Fetch_and_op">
        Routine reference: MPI_Fetch_and_op
      </button>
    </h5>
  </div>
  <div id="MPI_Fetch_and_op" class="collapse">
  <pre>
Semantics:

MPI_FETCH_AND_OP(origin_addr, result_addr, datatype, target_rank,
    target_disp, op, win)
IN origin_addr: initial address of buffer (choice)
OUT result_addr: initial address of result buffer (choice)
IN datatype: datatype of the entry in origin, result, and target buffers
(handle)
IN target_rank: rank of target (non-negative integer)
IN target_disp: displacement from start of window to beginning of target
buffer (non-negative integer)
IN op: reduce operation (handle)
IN win: window object (handle)

C:
int MPI_Fetch_and_op
   (const void *origin_addr, void *result_addr,
    MPI_Datatype datatype, int target_rank, MPI_Aint target_disp,
    MPI_Op op, MPI_Win win)

Fortran:
MPI_Fetch_and_op(origin_addr, result_addr, datatype, target_rank,
    target_disp, op, win, ierror)
TYPE(*), DIMENSION(..), INTENT(IN), ASYNCHRONOUS :: origin_addr
TYPE(*), DIMENSION(..), ASYNCHRONOUS :: result_addr
TYPE(MPI_Datatype), INTENT(IN) :: datatype
INTEGER, INTENT(IN) :: target_rank
INTEGER(KIND=MPI_ADDRESS_KIND), INTENT(IN) :: target_disp
TYPE(MPI_Op), INTENT(IN) :: op
TYPE(MPI_Win), INTENT(IN) :: win
INTEGER, OPTIONAL, INTENT(OUT) :: ierror
</pre>
</div>
</div>
<i>MPI_Fetch_and_op</i>
 and 
<div class="card">
  <div class="card-header" id="headingOne">
    <h5 class="mb-0">
      <button class="btn btn-link" data-toggle="collapse" data-target="#MPI_Get_accumulate" aria-expanded="false" aria-controls="MPI_Get_accumulate">
        Routine reference: MPI_Get_accumulate
      </button>
    </h5>
  </div>
  <div id="MPI_Get_accumulate" class="collapse">
  <pre>
C:
int MPI_Get_accumulate
   (const void *origin_addr, int origin_count,MPI_Datatype origin_datatype,
    void *result_addr, int result_count, MPI_Datatype result_datatype,
    int target_rank,
    MPI_Aint target_disp, int target_count, MPI_Datatype target_datatype,
    MPI_Op op, MPI_Win win)

Input Parameters
origin_addr : initial address of buffer (choice)
origin_count : number of entries in buffer (nonnegative integer)
origin_datatype : datatype of each buffer entry (handle)

result_addr : initial address of result buffer (choice)
result_count : number of entries in result buffer (non-negative integer)
result_datatype : datatype of each entry in result buffer (handle)
target_rank : rank of target (nonnegative integer)
target_disp : displacement from start of window to beginning
    of target buffer (nonnegative integer)
target_count : number of entries in target buffer (nonnegative integer)
target_datatype : datatype of each entry in target buffer (handle)
op : predefined reduce operation (handle)
win : window object (handle)
</pre>
</div>
</div>
<i>MPI_Get_accumulate</i>
atomically retrieve data from the window indicated,
and apply an operator, combining the data on the target
with the data on the origin.
Unlike Put and Get, it is safe to have multiple atomic operations
in the same epoch.
</p>

<p name="switchToTextMode">
Both routines perform the same operations: return data before the
operation, then atomically update data on the target, but
<tt>MPI_Get_accumulate</tt>
 is more flexible in data type
handling. The more simple routine, 
<tt>MPI_Fetch_and_op</tt>
,
which operates on only a single element,
allows for faster implementations, in particular through hardware support.
</p>

<p name="switchToTextMode">
Use of 
<tt>MPI_NO_OP</tt>
 as the 
<tt>MPI_Op</tt>
turns these routines into an atomic Get. Similarly, using
<tt>MPI_REPLACE</tt>
 turns them into an atomic Put.
</p>

<!-- environment: exercise start embedded generator -->
<!-- environment block purpose: [[ environment=exercise ]] -->
<exercise>
<b>Exercise</b>
<p name="exercise">
<!-- TranslatingLineGenerator exercise ['exercise'] -->

  Redo exercise&nbsp;
<a href="http://pages.tacc.utexas.edu/~eijkhout/pcse/html/mpi-onesided.html#Accumulate">9.3.4</a>
 using 
<tt>MPI_Fetch_and_op</tt>
. The
  problem is again to make sure all processes have the same view of
  the shared counter.
</p>

<p name="switchToTextMode">
  Does it work to make the fetch-and-op conditional? Is there a way to
  do it unconditionally? What should the `break' test be, seeing that
  multiple processes can update the counter at the same time?
</p name="exercise">
</exercise>
<!-- environment: exercise end embedded generator -->
<p name="switchToTextMode">

<!-- environment: example start embedded generator -->
</p>
<!-- environment block purpose: [[ environment=example ]] -->
<example>
<b>Example</b>
<p name="example">
<!-- TranslatingLineGenerator example ['example'] -->
  A root process has a table of data; the other processes do
  atomic gets and update of that data using
<i>passive target synchronization</i>
 through 
<tt>MPI_Win_lock</tt>
.
<div class="card">
  <div class="card-header" id="headingOne">
    <h5 class="mb-0">
      <button class="btn btn-link" data-toggle="collapse" data-target="#fetchop" aria-expanded="false" aria-controls="fetchop">
        C Code: fetchop
      </button>
    </h5>
  </div>
  <div id="fetchop" class="collapse">
  <pre>
// passive.cxx
if (procno==repository) {
// Repository processor creates a table of inputs
// and associates that with the window
}
if (procno!=repository) {
  float contribution=(float)procno,table_element;
  int loc=0;
  MPI_Win_lock(MPI_LOCK_EXCLUSIVE,repository,0,the_window);
// read the table element by getting the result from adding zero
  MPI_Fetch_and_op
    (&contribution,&table_element,MPI_FLOAT,
     repository,loc,MPI_SUM,the_window);
  MPI_Win_unlock(repository,the_window);
}
</pre>
</div>
</div>
<div class="card">
  <div class="card-header" id="headingOne">
    <h5 class="mb-0">
      <button class="btn btn-link" data-toggle="collapse" data-target="#fetchopp" aria-expanded="false" aria-controls="fetchopp">
        Python Code: fetchopp
      </button>
    </h5>
  </div>
  <div id="fetchopp" class="collapse">
  <pre>
## passive.py
if procid==repository:
    # repository process creates a table of inputs
    # and associates it with the window
    win_mem = np.empty( ninputs,dtype=np.float32 )
    win = MPI.Win.Create( win_mem,comm=comm )
else:
    # everyone else has an empty window
    win = MPI.Win.Create( None,comm=comm )
if procid!=repository:
    contribution = np.empty( 1,dtype=np.float32 )
    contribution[0] = 1.*procid
    table_element = np.empty( 1,dtype=np.float32 )
    win.Lock( repository,lock_type=MPI.LOCK_EXCLUSIVE )
    win.Fetch_and_op( contribution,table_element,repository,0,MPI.SUM)
    win.Unlock( repository )
</pre>
</div>
</div>
</p name="example">
</example>
<!-- environment: example end embedded generator -->
<p name="switchToTextMode">

Finally, 
<div class="card">
  <div class="card-header" id="headingOne">
    <h5 class="mb-0">
      <button class="btn btn-link" data-toggle="collapse" data-target="#MPI_Compare_and_swap" aria-expanded="false" aria-controls="MPI_Compare_and_swap">
        Routine reference: MPI_Compare_and_swap
      </button>
    </h5>
  </div>
  <div id="MPI_Compare_and_swap" class="collapse">
  <pre>
C:
int MPI_Compare_and_swap
   (const void *origin_addr, const void *compare_addr,
    void *result_addr, MPI_Datatype datatype,
    int target_rank, MPI_Aint target_disp,
    MPI_Win win)

Input Parameters

origin_addr : initial address of buffer (choice)
compare_addr : initial address of compare buffer (choice)
result_addr : initial address of result buffer (choice)
datatype : datatype of the entry in origin, result, and target buffers (handle)
target_rank : rank of target (nonnegative integer)
target_disp : displacement from start of window to beginning
    of target buffer (non-negative integer)
win : window object (handle)
</pre>
</div>
</div>
<i>MPI_Compare_and_swap</i>
 swaps the origin and
target data if the target data equals some comparison value.
</p>

<h4><a id="Acasestudyinatomicoperations">9.3.7.1</a> A case study in atomic operations</h4>
<p name=crumbs>
crumb trail:  > <a href="mpi-onesided.html">mpi-onesided</a> > <a href="mpi-onesided.html#Put,get,accumulate">Put, get, accumulate</a> > <a href="mpi-onesided.html#Atomicoperations">Atomic operations</a> > <a href="mpi-onesided.html#Acasestudyinatomicoperations">A case study in atomic operations</a>
</p>
<p name="switchToTextMode">

Let us consider an example where a process,
identified by  <tt>counter_process</tt> ,
has a table of work descriptors,
and all processes, including the counter process,
take items from it to work on.
To avoid duplicate work, the counter process has as counter
that indicates the highest numbered available item.
The part of this application that we simulate is this:
<!-- environment: enumerate start embedded generator -->
</p>
<!-- environment block purpose: [[ environment=enumerate ]] -->
<enumerate>
<ol>
<!-- TranslatingLineGenerator enumerate ['enumerate'] -->
<li>
a process reads the counter, to find an available work item; and
<li>
subsequently decrements the counter by one.
</ol>
</enumerate>
<!-- environment: enumerate end embedded generator -->
<p name="switchToTextMode">

We initialize the window content, under the separate memory model:
<div class="card">
  <div class="card-header" id="headingOne">
    <h5 class="mb-0">
      <button class="btn btn-link" data-toggle="collapse" data-target="#countdowninitput" aria-expanded="false" aria-controls="countdowninitput">
        C Code: countdowninitput
      </button>
    </h5>
  </div>
  <div id="countdowninitput" class="collapse">
  <pre>
// countdownop.c
MPI_Win_fence(0,the_window);
if (procno==counter_process)
  MPI_Put(&counter_init,1,MPI_INT,
          counter_process,0,1,MPI_INT,
          the_window);
MPI_Win_fence(0,the_window);
</pre>
</div>
</div>
</p>

<p name="switchToTextMode">
We start by considering the naive approach, where we execute the above scheme
literally with 
<tt>MPI_Get</tt>
 and 
<tt>MPI_Put</tt>
:
<div class="card">
  <div class="card-header" id="headingOne">
    <h5 class="mb-0">
      <button class="btn btn-link" data-toggle="collapse" data-target="#countdowngetput" aria-expanded="false" aria-controls="countdowngetput">
        C Code: countdowngetput
      </button>
    </h5>
  </div>
  <div id="countdowngetput" class="collapse">
  <pre>
// countdownput.c
MPI_Win_fence(0,the_window);
int counter_value;
MPI_Get( &counter_value,1,MPI_INT,
         counter_process,0,1,MPI_INT,
         the_window);
MPI_Win_fence(0,the_window);
if (i_am_available) {
  my_counter_values[ n_my_counter_values++ ] = counter_value;
  total_decrement++;
  int decrement = -1;
  counter_value += decrement;
  MPI_Put
    ( &counter_value,   1,MPI_INT,
      counter_process,0,1,MPI_INT,
      the_window);
}
MPI_Win_fence(0,the_window);
</pre>
</div>
</div>
</p>

<p name="switchToTextMode">
This scheme is correct if only process
has a true value for  <tt>i_am_available</tt> :
that processes `owns' the current counter values,
and it correctly updates the counter
through the 
<tt>MPI_Put</tt>
 operation.
However, if more than one process is available,
they get duplicate counter values, and the update
is also incorrect.
If we run this program, we see that the counter did not get
decremented by the total number of `put' calls.
</p>

<!-- environment: exercise start embedded generator -->
<!-- environment block purpose: [[ environment=exercise ]] -->
<exercise>
<b>Exercise</b>
<p name="exercise">
<!-- TranslatingLineGenerator exercise ['exercise'] -->
  Supposing only one process is available, what is the function
  of the middle of the three fences? Can it be omitted?
</p name="exercise">
</exercise>
<!-- environment: exercise end embedded generator -->
<!-- environment: answer start embedded generator -->
<!-- environment block purpose: [[ environment=answer ]] -->
<answer>


</answer>
<!-- environment: answer end embedded generator -->
<p name="switchToTextMode">

We can fix the decrement of the counter by using 
<tt>MPI_Accumulate</tt>
for the counter update, since it is atomic:
multiple updates in the same epoch all get processed.
<div class="card">
  <div class="card-header" id="headingOne">
    <h5 class="mb-0">
      <button class="btn btn-link" data-toggle="collapse" data-target="#countdowngetacc" aria-expanded="false" aria-controls="countdowngetacc">
        C Code: countdowngetacc
      </button>
    </h5>
  </div>
  <div id="countdowngetacc" class="collapse">
  <pre>
// countdownacc.c
MPI_Win_fence(0,the_window);
int counter_value;
MPI_Get( &counter_value,1,MPI_INT,
         counter_process,0,1,MPI_INT,
         the_window);
MPI_Win_fence(0,the_window);
if (i_am_available) {
  my_counter_values[n_my_counter_values++] = counter_value;
  total_decrement++;
  int decrement = -1;
  MPI_Accumulate
    ( &decrement,       1,MPI_INT,
      counter_process,0,1,MPI_INT,
      MPI_SUM,
      the_window);
}
MPI_Win_fence(0,the_window);
</pre>
</div>
</div>
</p>

<p name="switchToTextMode">
This scheme still suffers from the problem that processes will obtain duplicate
counter values. The true solution is to combine the `get' and `put' operations
into one atomic action; in this case 
<tt>MPI_Fetch_and_op</tt>
:
<div class="card">
  <div class="card-header" id="headingOne">
    <h5 class="mb-0">
      <button class="btn btn-link" data-toggle="collapse" data-target="#fetchopfence" aria-expanded="false" aria-controls="fetchopfence">
        C Code: fetchopfence
      </button>
    </h5>
  </div>
  <div id="fetchopfence" class="collapse">
  <pre>
MPI_Win_fence(0,the_window);
int
  counter_value;
if (i_am_available) {
  int
    decrement = -1;
  total_decrement++;
  MPI_Fetch_and_op
    ( /* operate with data from origin: */   &decrement,
      /* retrieve data from target:     */   &counter_value,
      MPI_INT, counter_process, 0, MPI_SUM,
      the_window);
}
MPI_Win_fence(0,the_window);
if (i_am_available) {
  my_counter_values[n_my_counter_values++] = counter_value;
}
</pre>
</div>
</div>
</p>

<p name="switchToTextMode">
Now, if there are multiple accesses, each retrieves the counter value
and updates it in one atomic, that is, indivisible, action.
</p>

<!-- index -->
<p name="switchToTextMode">

<h2><a id="Passivetargetsynchronization">9.4</a> Passive target synchronization</h2>
<p name=crumbs>
crumb trail:  > <a href="mpi-onesided.html">mpi-onesided</a> > <a href="mpi-onesided.html#Passivetargetsynchronization">Passive target synchronization</a>
</p>

</p>

<p name="switchToTextMode">
In 
<i>passive target synchronization</i>
 only the origin is
actively involved: the target makes no calls whatsoever.
This means that the origin process remotely locks the window
on the target, performs a one-sided transfer, and releases the window
by unlocking it again.
</p>

<p name="switchToTextMode">
During an access epoch, also called an
<i>passive target epoch</i>
 in this case
(the concept of `exposure epoch' makes no sense with passive target synchronization),
a&nbsp;process can initiate and finish a one-sided
transfer. Typically it will lock the window with
<div class="card">
  <div class="card-header" id="headingOne">
    <h5 class="mb-0">
      <button class="btn btn-link" data-toggle="collapse" data-target="#MPI_Win_lock" aria-expanded="false" aria-controls="MPI_Win_lock">
        Routine reference: MPI_Win_lock
      </button>
    </h5>
  </div>
  <div id="MPI_Win_lock" class="collapse">
  <pre>
C:
int MPI_Win_lock(int lock_type, int rank, int assert, MPI_Win win)

Input Parameters:
lock_type - Indicates whether other processes may access the target window at the
    same time (if MPI_LOCK_SHARED) or not (MPI_LOCK_EXCLUSIVE)
rank - rank of locked window (nonnegative integer)
assert - Used to optimize this call; zero may be used as a default. (integer)
win - window object (handle)

Python:
MPI.Win.Lock(self,
    int rank, int lock_type=LOCK_EXCLUSIVE, int assertion=0)
</pre>
</div>
</div>
<i>MPI_Win_lock</i>
:
</p>

<!-- environment: lstlisting start embedded generator -->
<!-- environment block purpose: [[ environment=lstlisting ]] -->
<lstlisting>
<pre>
if (rank == 0) {
  MPI_Win_lock (MPI_LOCK_EXCLUSIVE, 1, 0, win);
  MPI_Put (outbuf, n, MPI_INT, 1, 0, n, MPI_INT, win);
  MPI_Win_unlock (1, win);
}
</pre>
</lstlisting>
<!-- environment: lstlisting end embedded generator -->
<p name="switchToTextMode">

<!-- environment: remark start embedded generator -->
</p>
<!-- environment block purpose: [[ environment=remark ]] -->
<remark>
<b>Remark</b>
<p name="remark">
<!-- TranslatingLineGenerator remark ['remark'] -->
  The possibility to lock a window is not guaranteed for windows
  that are not created (possibly internally) by 
<tt>MPI_Alloc_mem</tt>
,
  that is, all but 
<tt>MPI_Win_create</tt>
.
</p name="remark">
</remark>
<!-- environment: remark end embedded generator -->
<p name="switchToTextMode">

<h3><a id="Locktypes">9.4.1</a> Lock types</h3>
<p name=crumbs>
crumb trail:  > <a href="mpi-onesided.html">mpi-onesided</a> > <a href="mpi-onesided.html#Passivetargetsynchronization">Passive target synchronization</a> > <a href="mpi-onesided.html#Locktypes">Lock types</a>
</p>
</p>

<p name="switchToTextMode">
A lock is needed to start an 
<i>access epoch</i>
, that is,
for an origin to acquire the capability to access a target.
You can either acquire a lock on a specific process with 
<tt>MPI_Win_lock</tt>
,
or on all processes (in a communicator) with 
<tt>MPI_Win_lock_all</tt>
.
Unlike 
<tt>MPI_Win_fence</tt>
, this is not a collective call.
Also, it is possible to have multiple access epochs through 
<tt>MPI_Win_lock</tt>
active simultaenously.
</p>

<p name="switchToTextMode">
The two lock types are:
<!-- environment: itemize start embedded generator -->
</p>
<!-- environment block purpose: [[ environment=itemize ]] -->
<itemize>
<ul>
<!-- TranslatingLineGenerator itemize ['itemize'] -->
<li>
<tt>MPI_LOCK_SHARED</tt>
: multiple processes can access
  the window on the same rank.
  If multiple processes perform a 
<tt>MPI_Get</tt>
 call there
  is no problem; with 
<tt>MPI_Put</tt>
 and similar calls
  there is a consistency problem; see below.
<li>
<tt>MPI_LOCK_EXCLUSIVE</tt>
: an origin gets exclusive access to the
  window on a certain target.
  Unlike the shared lock, this has no consistency problems.
</ul>
</itemize>
<!-- environment: itemize end embedded generator -->
<p name="switchToTextMode">

You can only specify a lock type in 
<tt>MPI_Win_lock</tt>
;
<tt>MPI_Win_lock_all</tt>
 is always shared.
</p>

<p name="switchToTextMode">
To unlock a window, use
<div class="card">
  <div class="card-header" id="headingOne">
    <h5 class="mb-0">
      <button class="btn btn-link" data-toggle="collapse" data-target="#MPI_Win_unlock" aria-expanded="false" aria-controls="MPI_Win_unlock">
        Routine reference: MPI_Win_unlock
      </button>
    </h5>
  </div>
  <div id="MPI_Win_unlock" class="collapse">
  <pre>
C:

Py:
MPI.Win.Unlock(self, int rank)
MPI.Win.Unlock_all(self)
</pre>
</div>
</div>
<i>MPI_Win_unlock</i>
, % includes unlock_all
respectively 
<tt>MPI_Win_unlock_all</tt>
.
</p>

<!-- environment: exercise start embedded generator -->
<!-- environment block purpose: [[ environment=exercise ]] -->
<exercise>
<b>Exercise</b>
<p name="exercise">
<!-- TranslatingLineGenerator exercise ['exercise'] -->

  Investigate atomic updates using passive target synchronization.
  Use 
<tt>MPI_Win_lock</tt>
 with an exclusive lock, which
  means that each process only acquires the lock when it absolutely has to.
<!-- environment: itemize start embedded generator -->
</p>
<!-- environment block purpose: [[ environment=itemize ]] -->
<itemize>
<ul>
<!-- TranslatingLineGenerator itemize ['itemize'] -->
<li>
All processs but one update a window:
<!-- environment: lstlisting start embedded generator -->
</p>
<!-- environment block purpose: [[ environment=lstlisting ]] -->
<lstlisting>
<pre>
int one=1;
MPI_Fetch_and_op(&one, &readout,
    MPI_INT, repo, zero_disp, MPI_SUM,
    the_win);
</pre>
</lstlisting>
<!-- environment: lstlisting end embedded generator -->
<li>
while the remaining process spins until the others have performed their update.
</ul>
</itemize>
<!-- environment: itemize end embedded generator -->
<p name="switchToTextMode">
  Use an atomic operation for the latter process to read out the shared value.\\
  Can you replace the exclusive lock with a shared one?
<!-- skeleton start: lockfetch -->
<button id="runBtnlockfetch">Compile and run lockfetch</button>
<div id="editorDivlockfetch" 
     style="height:125px;border:1px solid black; 
     resize:vertical; overflow: hidden;"></div>
<pre id="outputPrelockfetch"></pre>
<script name="defSkeletonlockfetch">
let examplelockfetch = new Example("runBtnlockfetch",
    "editorDivlockfetch", "outputPrelockfetch", 
    "skeletons/lockfetch.c", 
    "mpicc skeletons/lockfetch.c && mpiexec -n 4 ./a.out" );
examplelockfetch.initialize();
</script>
<!-- skeleton end: lockfetch -->
</p name="exercise">
</exercise>
<!-- environment: exercise end embedded generator -->
<p name="switchToTextMode">

<!-- environment: exercise start embedded generator -->
</p>
<!-- environment block purpose: [[ environment=exercise ]] -->
<exercise>
<b>Exercise</b>
<p name="exercise">
<!-- TranslatingLineGenerator exercise ['exercise'] -->

  As exercise&nbsp;
<a href="http://pages.tacc.utexas.edu/~eijkhout/pcse/html/mpi-onesided.html#Locktypes">9.4.1</a>
, but now use a shared lock:
  all processes acquire the lock simultaneously and keep it as long as is needed.
</p>

<p name="switchToTextMode">
  The problem here is that coherence between window buffers and local variables is
  now not forced by a fence or releasing a lock. Use 
<tt>MPI_Win_flush_local</tt>
 to
  force coherence of a window (on another process) and the local variable from
  
<tt>MPI_Fetch_and_op</tt>
.
<!-- skeleton start: lockfetchshared -->
<button id="runBtnlockfetchshared">Compile and run lockfetchshared</button>
<div id="editorDivlockfetchshared" 
     style="height:125px;border:1px solid black; 
     resize:vertical; overflow: hidden;"></div>
<pre id="outputPrelockfetchshared"></pre>
<script name="defSkeletonlockfetchshared">
let examplelockfetchshared = new Example("runBtnlockfetchshared",
    "editorDivlockfetchshared", "outputPrelockfetchshared", 
    "skeletons/lockfetchshared.c", 
    "mpicc skeletons/lockfetchshared.c && mpiexec -n 4 ./a.out" );
examplelockfetchshared.initialize();
</script>
<!-- skeleton end: lockfetchshared -->
</p name="exercise">
</exercise>
<!-- environment: exercise end embedded generator -->
<p name="switchToTextMode">

<h3><a id="Lockall">9.4.2</a> Lock all</h3>
<p name=crumbs>
crumb trail:  > <a href="mpi-onesided.html">mpi-onesided</a> > <a href="mpi-onesided.html#Passivetargetsynchronization">Passive target synchronization</a> > <a href="mpi-onesided.html#Lockall">Lock all</a>
</p>

</p>

<p name="switchToTextMode">
To lock the windows of all processes in the group of the windows, use
<div class="card">
  <div class="card-header" id="headingOne">
    <h5 class="mb-0">
      <button class="btn btn-link" data-toggle="collapse" data-target="#MPI_Win_lock_all" aria-expanded="false" aria-controls="MPI_Win_lock_all">
        Routine reference: MPI_Win_lock_all
      </button>
    </h5>
  </div>
  <div id="MPI_Win_lock_all" class="collapse">
  <pre>
C:
int MPI_Win_lock( int assert, MPI_Win win)

Input Parameters:
assert - Used to optimize this call; zero may be used as a default. (integer)
win - window object (handle)
</pre>
</div>
</div>
<i>MPI_Win_lock_all</i>
. This is not a collective call:
the `all' part refers to the fact that one process is locking the
window on all processes.
<!-- environment: itemize start embedded generator -->
</p>
<!-- environment block purpose: [[ environment=itemize ]] -->
<itemize>
<ul>
<!-- TranslatingLineGenerator itemize ['itemize'] -->
<li>
  The assertion value can be zero, or 
<tt>MPI_MODE_NOCHECK</tt>
,
  which asserts that no other process will acquire a competing lock.
<li>
There is no `locktype' parameter: this is a shared lock.
</ul>
</itemize>
<!-- environment: itemize end embedded generator -->
<p name="switchToTextMode">

The corresponding unlock is
<tt>MPI_Win_unlock_all</tt>
.
</p>

<p name="switchToTextMode">
The expected use of a `lock/unlock all' is that they surround
an extended epoch with get/put and flush calls.
</p>

<h3><a id="Completionandconsistencyinpassivetargetsynchronization">9.4.3</a> Completion and consistency in passive target synchronization</h3>
<p name=crumbs>
crumb trail:  > <a href="mpi-onesided.html">mpi-onesided</a> > <a href="mpi-onesided.html#Passivetargetsynchronization">Passive target synchronization</a> > <a href="mpi-onesided.html#Completionandconsistencyinpassivetargetsynchronization">Completion and consistency in passive target synchronization</a>
</p>
<p name="switchToTextMode">

In one-sided transfer one should keep straight the multiple instances
of the data, and the various 
<i>completion</i>
s that effect
their 
<i>consistency</i>

<!-- index -->
.
<!-- environment: itemize start embedded generator -->
</p>
<!-- environment block purpose: [[ environment=itemize ]] -->
<itemize>
<ul>
<!-- TranslatingLineGenerator itemize ['itemize'] -->
<li>
The user data. This is the buffer that is passed to a 
<tt>Put</tt>
 or
  
<tt>Get</tt>
 call. For instance, after a 
<tt>Put</tt>
 call, but still in an
  access epoch, the user buffer is not safe to reuse. Making sure the
  buffer has been transferred is called 
<i>local completion</i>
.
<li>
The window data. While this may be publicly accessible, it is
  not necessarily always consistent with internal copies.
<li>
The remote data. Even a successful 
<tt>Put</tt>
 does not guarantee
  that the other process has received the data. A&nbsp;successful transfer
  is a 
<i>remote completion</i>
.
</ul>
</itemize>
<!-- environment: itemize end embedded generator -->
<p name="switchToTextMode">

As observed, 
<span title="acronym" ><i>RMA</i></span>
 operations are nonblocking, so we need
mechanisms to ensure that an operation is completed,
and to ensure 
<i>consistency</i>

<!-- index -->
 of the
user and window data.
</p>

<p name="switchToTextMode">
Completion of the 
<span title="acronym" ><i>RMA</i></span>
 operations in a  passive target epoch
is ensured with
<tt>MPI_Win_unlock</tt>
 or 
<tt>MPI_Win_unlock_all</tt>
,
similar to the use of 
<tt>MPI_Win_fence</tt>
in active target synchronization.
</p>

<p name="switchToTextMode">
If the passive target epoch is of greater duration,
and no unlock operation is used to ensure completion,
the following calls are available.
</p>

<!-- environment: remark start embedded generator -->
<!-- environment block purpose: [[ environment=remark ]] -->
<remark>
<b>Remark</b>
<p name="remark">
<!-- TranslatingLineGenerator remark ['remark'] -->
  Using flush routines with active target synchronization
  (or generally outside a passive target epoch) you are
  likely to get a message
<!-- environment: verbatim start embedded generator -->
</p>
<!-- environment block purpose: [[ environment=verbatim ]] -->
<verbatim>
<pre>
Wrong synchronization of RMA calls
</pre>
</verbatim>
<!-- environment: verbatim end embedded generator -->
</remark>
<!-- environment: remark end embedded generator -->
<p name="switchToTextMode">

<h4><a id="Localcompletion">9.4.3.1</a> Local completion</h4>
<p name=crumbs>
crumb trail:  > <a href="mpi-onesided.html">mpi-onesided</a> > <a href="mpi-onesided.html#Passivetargetsynchronization">Passive target synchronization</a> > <a href="mpi-onesided.html#Completionandconsistencyinpassivetargetsynchronization">Completion and consistency in passive target synchronization</a> > <a href="mpi-onesided.html#Localcompletion">Local completion</a>
</p>
</p>

<p name="switchToTextMode">
The call 
<div class="card">
  <div class="card-header" id="headingOne">
    <h5 class="mb-0">
      <button class="btn btn-link" data-toggle="collapse" data-target="#MPI_Win_flush_local" aria-expanded="false" aria-controls="MPI_Win_flush_local">
        Routine reference: MPI_Win_flush_local
      </button>
    </h5>
  </div>
  <div id="MPI_Win_flush_local" class="collapse">
  <pre>
Synopsis:
MPI_WIN_FLUSH_LOCAL(rank, win)
Input arguments:
rank: rank of target window (non-negative integer)
win : window object (handle)

C:
int MPI_Win_flush_local(int rank, MPI_Win win)

Fortran:
MPI_Win_flush_local(rank, win, ierror)
INTEGER, INTENT(IN) :: rank
TYPE(MPI_Win), INTENT(IN) :: win
INTEGER, OPTIONAL, INTENT(OUT) :: ierror
MPI_WIN_FLUSH_LOCAL(RANK, WIN, IERROR)
INTEGER RANK, WIN, IERROR

Synopsis:
MPI_WIN_FLUSH_LOCAL_ALL(win)
Input arguments:
win : window object (handle)

C:
int MPI_Win_flush_local_all(MPI_Win win)

Fortran:
MPI_Win_flush_local_all(win, ierror)
TYPE(MPI_Win), INTENT(IN) :: win
INTEGER, OPTIONAL, INTENT(OUT) :: ierror
MPI_WIN_FLUSH_LOCAL_ALL(WIN, IERROR)
INTEGER WIN, IERROR
</pre>
</div>
</div>
<i>MPI_Win_flush_local</i>
ensure that all operations with a given target is completed at the origin.
For instance, for calls to 
<tt>MPI_Get</tt>
 or
<tt>MPI_Fetch_and_op</tt>
 the local result is available after
the 
<tt>MPI_Win_flush_local</tt>
.
</p>

<p name="switchToTextMode">
With 
<tt>MPI_Win_flush_local_all</tt>
 local operations are
concluded for all targets. This will typically be used
with 
<tt>MPI_Win_lock_all</tt>
 (section&nbsp;
<a href="http://pages.tacc.utexas.edu/~eijkhout/pcse/html/mpi-onesided.html#Lockall">9.4.2</a>
).
</p>

<h4><a id="Remotecompletion">9.4.3.2</a> Remote completion</h4>
<p name=crumbs>
crumb trail:  > <a href="mpi-onesided.html">mpi-onesided</a> > <a href="mpi-onesided.html#Passivetargetsynchronization">Passive target synchronization</a> > <a href="mpi-onesided.html#Completionandconsistencyinpassivetargetsynchronization">Completion and consistency in passive target synchronization</a> > <a href="mpi-onesided.html#Remotecompletion">Remote completion</a>
</p>
<p name="switchToTextMode">

The calls
<div class="card">
  <div class="card-header" id="headingOne">
    <h5 class="mb-0">
      <button class="btn btn-link" data-toggle="collapse" data-target="#MPI_Win_flush" aria-expanded="false" aria-controls="MPI_Win_flush">
        Routine reference: MPI_Win_flush
      </button>
    </h5>
  </div>
  <div id="MPI_Win_flush" class="collapse">
  <pre>
Synopsis
MPI_WIN_FLUSH(rank, win)
Input arguments:
rank : rank of target window (non-negative integer)
win : window object (handle)

C:
int MPI_Win_flush(int rank, MPI_Win win)

Fortran:
MPI_Win_flush(rank, win, ierror)
INTEGER, INTENT(IN) :: rank
TYPE(MPI_Win), INTENT(IN) :: win
INTEGER, OPTIONAL, INTENT(OUT) :: ierror
MPI_WIN_FLUSH(RANK, WIN, IERROR)
INTEGER RANK, WIN, IERROR

Synopsis:
MPI_WIN_FLUSH_ALL(win)
Input arguments:
win : window object (handle)

C:
int MPI_Win_flush_all(MPI_Win win)

Fortran:
MPI_Win_flush_all(win, ierror)
TYPE(MPI_Win), INTENT(IN) :: win
INTEGER, OPTIONAL, INTENT(OUT) :: ierror
MPI_WIN_FLUSH_ALL(WIN, IERROR)
INTEGER WIN, IERROR
</pre>
</div>
</div>
<i>MPI_Win_flush</i>
 and
<tt>MPI_Win_flush_all</tt>
effect completion of all outstanding 
<span title="acronym" ><i>RMA</i></span>
 operations
on the target, so that
other processes can access its data.
This is useful for 
<tt>MPI_Put</tt>
 operations,
but can also be used for atomic operations
such as 
<tt>MPI_Fetch_and_op</tt>
.
</p>

<h4><a id="Windowsynchronization">9.4.3.3</a> Window synchronization</h4>
<p name=crumbs>
crumb trail:  > <a href="mpi-onesided.html">mpi-onesided</a> > <a href="mpi-onesided.html#Passivetargetsynchronization">Passive target synchronization</a> > <a href="mpi-onesided.html#Completionandconsistencyinpassivetargetsynchronization">Completion and consistency in passive target synchronization</a> > <a href="mpi-onesided.html#Windowsynchronization">Window synchronization</a>
</p>
<p name="switchToTextMode">

Under the
<i>separate memory model</i>
<!-- index -->
,
the user code can hold a buffer that is not coherent with the internal
window data. The call 
<tt>MPI_Win_sync</tt>
 synchronizes
private and public copies of the window.
</p>

<h2><a id="Moreaboutwindowmemory">9.5</a> More about window memory</h2>
<p name=crumbs>
crumb trail:  > <a href="mpi-onesided.html">mpi-onesided</a> > <a href="mpi-onesided.html#Moreaboutwindowmemory">More about window memory</a>
</p>
<p name="switchToTextMode">

<h3><a id="Memorymodels">9.5.1</a> Memory models</h3>
<p name=crumbs>
crumb trail:  > <a href="mpi-onesided.html">mpi-onesided</a> > <a href="mpi-onesided.html#Moreaboutwindowmemory">More about window memory</a> > <a href="mpi-onesided.html#Memorymodels">Memory models</a>
</p>

</p>

<p name="switchToTextMode">
You may think that the window memory is the same as the buffer you
pass to 
<tt>MPI_Win_create</tt>
 or that you get from
<tt>MPI_Win_allocate</tt>
 (section&nbsp;
<a href="http://pages.tacc.utexas.edu/~eijkhout/pcse/html/mpi-onesided.html#Windowcreationandallocation">9.1.1</a>
).
This is not necessarily true, and the
actual state of affairs is called the
<i>memory model</i>
<!-- index -->
<!-- index -->
.
There are two memory models:
<!-- environment: itemize start embedded generator -->
</p>
<!-- environment block purpose: [[ environment=itemize ]] -->
<itemize>
<ul>
<!-- TranslatingLineGenerator itemize ['itemize'] -->
<li>
Under the 
<i>unified</i>

<!-- index -->
 memory
  model, the buffer in process space is indeed the window memory,
  or at least they are kept 
<i>coherent</i>

<!-- index -->
.
  This
  means that after 
<i>completion</i>

<!-- index -->
 of an
  epoch you can read the window contents from the buffer.
  To get this, the window needs to be created with
<tt>MPI_Win_allocate_shared</tt>
.
  This memory model is required for MPI shared memory; chapter&nbsp;
<a href="http://pages.tacc.utexas.edu/~eijkhout/pcse/html/mpi-shared.html">MPI topic: Shared memory</a>
.
<li>
Under the 
<i>separate</i>

<!-- index -->
 memory
  model, the buffer in process space is the
<i>private window</i>
 and the target of put/get operations
  is the 
<i>public window</i>
 and the two are not the same
  and are not kept coherent. Under this model, you need to do an
  explicit get to read the window contents.
</ul>
</itemize>
<!-- environment: itemize end embedded generator -->
<p name="switchToTextMode">

You can query the model of a window
using the 
<tt>MPI_Win_get_attr</tt>
 call
with the 
<tt>MPI_WIN_MODEL</tt>
 keyword:
<!-- environment: lstlisting start embedded generator -->
</p>
<!-- environment block purpose: [[ environment=lstlisting ]] -->
<lstlisting>
<pre>
int *memory_model;
MPI_Win_get_attr(win, MPI_WIN_MODEL, &memory_model, &flag);
</pre>
</lstlisting>
<!-- environment: lstlisting end embedded generator -->
<p name="switchToTextMode">
with possible values:
<!-- environment: itemize start embedded generator -->
</p>
<!-- environment block purpose: [[ environment=itemize ]] -->
<itemize>
<ul>
<!-- TranslatingLineGenerator itemize ['itemize'] -->
<li>
<tt>MPI_WIN_SEPARATE</tt>
,
<li>
<tt>MPI_WIN_UNIFIED</tt>
,
</ul>
</itemize>
<!-- environment: itemize end embedded generator -->
<p name="switchToTextMode">

</p>

<p name="switchToTextMode">
(Window models can be queried as attributes; see section&nbsp;
<a href="http://pages.tacc.utexas.edu/~eijkhout/pcse/html/mpi-onesided.html#Windowinformation">9.5.4</a>
.)
</p>

<h3><a id="Dynamicallyattachedmemory">9.5.2</a> Dynamically attached memory</h3>
<p name=crumbs>
crumb trail:  > <a href="mpi-onesided.html">mpi-onesided</a> > <a href="mpi-onesided.html#Moreaboutwindowmemory">More about window memory</a> > <a href="mpi-onesided.html#Dynamicallyattachedmemory">Dynamically attached memory</a>
</p>

<p name="switchToTextMode">

In section&nbsp;
<a href="http://pages.tacc.utexas.edu/~eijkhout/pcse/html/mpi-onesided.html#Windowcreationandallocation">9.1.1</a>
 we looked at simple ways to create a
window and its memory.
</p>

<p name="switchToTextMode">
It is also possible to have windows where the size is dynamically set.
Create a dynamic window with
<div class="card">
  <div class="card-header" id="headingOne">
    <h5 class="mb-0">
      <button class="btn btn-link" data-toggle="collapse" data-target="#MPI_Win_create_dynamic" aria-expanded="false" aria-controls="MPI_Win_create_dynamic">
        Routine reference: MPI_Win_create_dynamic
      </button>
    </h5>
  </div>
  <div id="MPI_Win_create_dynamic" class="collapse">
  <pre>
int MPI_Win_create_dynamic(MPI_Info info, MPI_Comm comm, MPI_Win *win)

Input Parameters
info : info argument (handle)
comm : communicator (handle)

Output Parameters
win : window object returned by the call (handle)
</pre>
</div>
</div>
<i>MPI_Win_create_dynamic</i>
and attach
memory to the window with
<div class="card">
  <div class="card-header" id="headingOne">
    <h5 class="mb-0">
      <button class="btn btn-link" data-toggle="collapse" data-target="#MPI_Win_attach" aria-expanded="false" aria-controls="MPI_Win_attach">
        Routine reference: MPI_Win_attach
      </button>
    </h5>
  </div>
  <div id="MPI_Win_attach" class="collapse">
  <pre>
Semantics:
MPI_Win_attach(win, base, size)

Input Parameters:
win : window object (handle)
base : initial address of memory to be attached
size : size of memory to be attached in bytes

C:
int MPI_Win_attach(MPI_Win win, void *base, MPI_Aint size)

Fortran:
MPI_Win_attach(win, base, size, ierror)
TYPE(MPI_Win), INTENT(IN) :: win
TYPE(*), DIMENSION(..), ASYNCHRONOUS :: base
INTEGER(KIND=MPI_ADDRESS_KIND), INTENT(IN) :: size
INTEGER, OPTIONAL, INTENT(OUT) :: ierror
</pre>
</div>
</div>
<i>MPI_Win_attach</i>
.
</p>

<p name="switchToTextMode">
At first sight, the code looks like splitting up a 
<tt>MPI_Win_create</tt>
call into separate creation of the window and declaration of the buffer:
<div class="card">
  <div class="card-header" id="headingOne">
    <h5 class="mb-0">
      <button class="btn btn-link" data-toggle="collapse" data-target="#winattach" aria-expanded="false" aria-controls="winattach">
        C Code: winattach
      </button>
    </h5>
  </div>
  <div id="winattach" class="collapse">
  <pre>
// windynamic.c
MPI_Win_create_dynamic(MPI_INFO_NULL,comm,&the_window);
if (procno==data_proc)
  window_buffer = (int*) malloc( 2*sizeof(int) );
  MPI_Win_attach(the_window,window_buffer,2*sizeof(int));
</pre>
</div>
</div>
(where the 
<tt>window_buffer</tt>
 represents memory that has been allocated.)
</p>

<p name="switchToTextMode">
However, there is an important difference in how the window is addressed
in 
<span title="acronym" ><i>RMA</i></span>
 operations.
With all other window models, the displacement parameter is measured relative
in units from the start of the buffer, here the displacement
is an absolute address. This means that we need to get the address
of the window buffer with 
<tt>MPI_Get_address</tt>
 and
communicate it to the other processes:
<div class="card">
  <div class="card-header" id="headingOne">
    <h5 class="mb-0">
      <button class="btn btn-link" data-toggle="collapse" data-target="#addrbcast" aria-expanded="false" aria-controls="addrbcast">
        C Code: addrbcast
      </button>
    </h5>
  </div>
  <div id="addrbcast" class="collapse">
  <pre>
MPI_Aint data_address;
if (procno==data_proc) {
  MPI_Get_address(window_buffer,&data_address);
}
MPI_Bcast(&data_address,1,MPI_LONG,data_proc,comm);
</pre>
</div>
</div>
</p>

<p name="switchToTextMode">
Location of the data, that is, the displacement parameter,
is then given as an absolute location
of the start of the buffer plus a count in bytes;
in other words, the 
<i>displacement unit</i>
 is&nbsp;1.
In this example we use 
<tt>MPI_Get</tt>
 to find the second
integer in a window buffer:
<div class="card">
  <div class="card-header" id="headingOne">
    <h5 class="mb-0">
      <button class="btn btn-link" data-toggle="collapse" data-target="#windynamicget" aria-expanded="false" aria-controls="windynamicget">
        C Code: windynamicget
      </button>
    </h5>
  </div>
  <div id="windynamicget" class="collapse">
  <pre>
MPI_Aint disp = data_address+1*sizeof(int);
MPI_Get( /* data on origin: */           retrieve, 1,MPI_INT,
	       /* data on target: */ data_proc,disp,     1,MPI_INT,
	       the_window);
</pre>
</div>
</div>
</p>

<p name="switchToTextMode">
Notes.
<!-- environment: itemize start embedded generator -->
</p>
<!-- environment block purpose: [[ environment=itemize ]] -->
<itemize>
<ul>
<!-- TranslatingLineGenerator itemize ['itemize'] -->
<li>
  The attached memory can be released with
<div class="card">
  <div class="card-header" id="headingOne">
    <h5 class="mb-0">
      <button class="btn btn-link" data-toggle="collapse" data-target="#MPI_Win_detach" aria-expanded="false" aria-controls="MPI_Win_detach">
        Routine reference: MPI_Win_detach
      </button>
    </h5>
  </div>
  <div id="MPI_Win_detach" class="collapse">
  <pre>
Semantics:
MPI_Win_detach(win, base)

Input parameters:
win : window object (handle)
base : initial address of memory to be detached

C:
int MPI_Win_detach(MPI_Win win, const void *base)

Fortran:
MPI_Win_detach(win, base, ierror)
TYPE(MPI_Win), INTENT(IN) :: win
TYPE(*), DIMENSION(..), ASYNCHRONOUS :: base
INTEGER, OPTIONAL, INTENT(OUT) :: ierror
</pre>
</div>
</div>
<i>MPI_Win_detach</i>
.
<li>
The above fragments show that an origin process has the actual
  address of the window buffer. It is an error to use this if the
  buffer is not attached to a window.
<li>
In particular, one has to make sure that the attach call is
  concluded before performing 
<span title="acronym" ><i>RMA</i></span>
 operations on the window.
</ul>
</itemize>
<!-- environment: itemize end embedded generator -->
<p name="switchToTextMode">

<h3><a id="Windowusagehints">9.5.3</a> Window usage hints</h3>
<p name=crumbs>
crumb trail:  > <a href="mpi-onesided.html">mpi-onesided</a> > <a href="mpi-onesided.html#Moreaboutwindowmemory">More about window memory</a> > <a href="mpi-onesided.html#Windowusagehints">Window usage hints</a>
</p>

</p>

<p name="switchToTextMode">
The following keys can be passed as info argument:
<!-- environment: itemize start embedded generator -->
</p>
<!-- environment block purpose: [[ environment=itemize ]] -->
<itemize>
<ul>
<!-- TranslatingLineGenerator itemize ['itemize'] -->
<li>
<tt>no_locks</tt>
: if set to true, passive target synchronization
  (section&nbsp;
<a href="http://pages.tacc.utexas.edu/~eijkhout/pcse/html/mpi-onesided.html#Passivetargetsynchronization">9.4</a>
) will not be used on this window.
<li>
<tt>accumulate_ordering</tt>
: a comma-separated list of
  the keywords 
<tt>rar</tt>
, 
<tt>raw</tt>
,
<tt>war</tt>
, 
<tt>waw</tt>
 can be specified. This
  indicates that reads or writes from 
<tt>MPI_Accumulate</tt>
 or
<tt>MPI_Get_accumulate</tt>
 can be reordered, subject to
  certain constraints.
<li>
<tt>accumulate_ops</tt>
: the value 
<tt>same_op</tt>
  indicates that concurrent Accumulate calls use the same operator;
<tt>same_op_no_op</tt>
 indicates the same operator or
<tt>MPI_NO_OP</tt>
.
</ul>
</itemize>
<!-- environment: itemize end embedded generator -->
<p name="switchToTextMode">

<h3><a id="Windowinformation">9.5.4</a> Window information</h3>
<p name=crumbs>
crumb trail:  > <a href="mpi-onesided.html">mpi-onesided</a> > <a href="mpi-onesided.html#Moreaboutwindowmemory">More about window memory</a> > <a href="mpi-onesided.html#Windowinformation">Window information</a>
</p>

</p>

<p name="switchToTextMode">
The 
<tt>MPI_Info</tt>
 parameter
(see section&nbsp;
<a href="http://pages.tacc.utexas.edu/~eijkhout/pcse/html/mpi.html#Infoobjects">15.1.1</a>
 for info objects)
can be used to pass implementation-dependent
information.
</p>

<p name="switchToTextMode">
A number of attributes are stored with a window when it is created.
<!-- environment: itemize start embedded generator -->
</p>
<!-- environment block purpose: [[ environment=itemize ]] -->
<itemize>
<ul>
<!-- TranslatingLineGenerator itemize ['itemize'] -->
<li>
<tt>MPI_WIN_BASE</tt>
 for
  obtaining a pointer to the start of the window area:
<!-- environment: lstlisting start embedded generator -->
</p>
<!-- environment block purpose: [[ environment=lstlisting ]] -->
<lstlisting>
<pre>
void *base;
MPI_Win_get_attr(win, MPI_WIN_BASE, &base, &flag)
</pre>
</lstlisting>
<!-- environment: lstlisting end embedded generator -->
<li>
<tt>MPI_WIN_SIZE</tt>
 and 
<tt>MPI_WIN_DISP_UNIT</tt>
 for
  obtaining the size and 
<i>window displacement unit</i>
:
<!-- environment: lstlisting start embedded generator -->
</p>
<!-- environment block purpose: [[ environment=lstlisting ]] -->
<lstlisting>
<pre>
MPI_Aint *size;
MPI_Win_get_attr(win, MPI_WIN_SIZE, &size, &flag),
int *disp_unit;
MPI_Win_get_attr(win, MPI_WIN_DISP_UNIT, &disp_unit, &flag),
</pre>
</lstlisting>
<!-- environment: lstlisting end embedded generator -->
<li>
<tt>MPI_WIN_CREATE_FLAVOR</tt>
 for determining
the type of create call used:
<!-- environment: lstlisting start embedded generator -->
</p>
<!-- environment block purpose: [[ environment=lstlisting ]] -->
<lstlisting>
<pre>
int *create_kind;
MPI_Win_get_attr(win, MPI_WIN_CREATE_FLAVOR, &create_kind, &flag)
</pre>
</lstlisting>
<!-- environment: lstlisting end embedded generator -->
<p name="switchToTextMode">
with possible values:
<!-- environment: itemize start embedded generator -->
</p>
<!-- environment block purpose: [[ environment=itemize ]] -->
<itemize>
<ul>
<!-- TranslatingLineGenerator itemize ['itemize'] -->
<li>
<tt>MPI_WIN_FLAVOR_CREATE</tt>
 if the window was create
  with 
<tt>MPI_Win_create</tt>
;
<li>
<tt>MPI_WIN_FLAVOR_ALLOCATE</tt>
 if the window was create
  with 
<tt>MPI_Win_allocate</tt>
;
<li>
<tt>MPI_WIN_FLAVOR_DYNAMIC</tt>
 if the window was create
  with 
<tt>MPI_Win_create_dynamic</tt>
. In this case the base is
<tt>MPI_BOTTOM</tt>
 and the size is zero;
<li>
<tt>MPI_WIN_FLAVOR_SHARED</tt>
 if the window was create
  with 
<tt>MPI_Win_allocate_shared</tt>
;
</ul>
</itemize>
<!-- environment: itemize end embedded generator -->
<li>
<tt>MPI_WIN_MODEL</tt>
 for
  querying the window memory model; see section&nbsp;
<a href="http://pages.tacc.utexas.edu/~eijkhout/pcse/html/mpi-onesided.html#Memorymodels">9.5.1</a>
.
</ul>
</itemize>
<!-- environment: itemize end embedded generator -->
<p name="switchToTextMode">

Get the group of processes (see section&nbsp;
<a href="http://pages.tacc.utexas.edu/~eijkhout/pcse/html/mpi-comm.html#Communicatorsandgroups">7.5</a>
)
associated with a window:
<!-- environment: lstlisting start embedded generator -->
</p>
<!-- environment block purpose: [[ environment=lstlisting ]] -->
<lstlisting>
<pre>
int MPI_Win_get_group(MPI_Win win, MPI_Group *group)
</pre>
</lstlisting>
<!-- environment: lstlisting end embedded generator -->
<p name="switchToTextMode">

Window information objects (see section&nbsp;
<a href="http://pages.tacc.utexas.edu/~eijkhout/pcse/html/mpi.html#Infoobjects">15.1.1</a>
)
can be set and retrieved:
<!-- environment: lstlisting start embedded generator -->
</p>
<!-- environment block purpose: [[ environment=lstlisting ]] -->
<lstlisting>
<pre>
int MPI_Win_set_info(MPI_Win win, MPI_Info info)
</pre>
</lstlisting>
<!-- environment: lstlisting end embedded generator -->
<!-- environment: lstlisting start embedded generator -->
<!-- environment block purpose: [[ environment=lstlisting ]] -->
<lstlisting>
<pre>
int MPI_Win_get_info(MPI_Win win, MPI_Info *info_used)
</pre>
</lstlisting>
<!-- environment: lstlisting end embedded generator -->
<p name="switchToTextMode">

<h2><a id="Assertions">9.6</a> Assertions</h2>
<p name=crumbs>
crumb trail:  > <a href="mpi-onesided.html">mpi-onesided</a> > <a href="mpi-onesided.html#Assertions">Assertions</a>
</p>

</p>

<p name="switchToTextMode">
The routines
<!-- environment: itemize start embedded generator -->
</p>
<!-- environment block purpose: [[ environment=itemize ]] -->
<itemize>
<ul>
<!-- TranslatingLineGenerator itemize ['itemize'] -->
<li>
(Active target synchronization)
<tt>MPI_Win_fence</tt>
,
<tt>MPI_Win_post</tt>
,
<tt>MPI_Win_start</tt>
;
<li>
(Passive target synchronization)
<tt>MPI_Win_lock</tt>
,
<tt>MPI_Win_lockall</tt>
,
</ul>
</itemize>
<!-- environment: itemize end embedded generator -->
<p name="switchToTextMode">
take an argument
through which assertions can be passed about the activity before, after, and during the epoch.
The value zero is always allowed, by you can make your program more efficient by specifying
one or more of the following, combined by bitwise OR in C/C++ or

<tt>IOR</tt>
 in Fortran.
</p>

<!-- environment: itemize start embedded generator -->
<!-- environment block purpose: [[ environment=itemize ]] -->
<itemize>
<ul>
<!-- TranslatingLineGenerator itemize ['itemize'] -->
<li>
<tt>MPI_Win_start</tt>
 Supports the option:
<!-- environment: itemize start embedded generator -->
</p>
<!-- environment block purpose: [[ environment=itemize ]] -->
<itemize>
<ul>
<!-- TranslatingLineGenerator itemize ['itemize'] -->
<li>
<tt>MPI_MODE_NOCHECK</tt>
 the matching calls to 
<tt>MPI_Win_post</tt>
 have already
    completed on all target processes when the call to 
<tt>MPI_Win_start</tt>
 is
    made. The nocheck option can be specified in a start call if and
    only if it is specified in each matching post call. This is similar
    to the optimization of ``ready-send'' that may save a handshake when
    the handshake is implicit in the code. (However, ready-send is
    matched by a regular receive, whereas both start and post must
    specify the nocheck option.)
</ul>
</itemize>
<!-- environment: itemize end embedded generator -->
<li>
<tt>MPI_Win_post</tt>
 supports the following options:
<!-- environment: itemize start embedded generator -->
</p>
<!-- environment block purpose: [[ environment=itemize ]] -->
<itemize>
<ul>
<!-- TranslatingLineGenerator itemize ['itemize'] -->
<li>
<tt>MPI_MODE_NOCHECK</tt>
 the matching calls to 
<tt>MPI_Win_start</tt>
 have not
    yet occurred on any origin processes when the call to 
<tt>MPI_Win_post</tt>
    is made. The nocheck option can be specified by a post call if and
    only if it is specified by each matching start call.
<li>
<tt>MPI_MODE_NOSTORE</tt>
 the local window was not updated by local
    stores (or local get or receive calls) since last
    synchronization. This may avoid the need for cache synchronization
    at the post call.
<li>
<tt>MPI_MODE_NOPUT</tt>
 the local window will not be updated by put or
    accumulate calls after the post call, until the ensuing (wait)
    synchronization. This may avoid the need for cache synchronization
    at the wait call.
</ul>
</itemize>
<!-- environment: itemize end embedded generator -->
<li>
<tt>MPI_Win_fence</tt>
 supports the following options:
<!-- environment: itemize start embedded generator -->
</p>
<!-- environment block purpose: [[ environment=itemize ]] -->
<itemize>
<ul>
<!-- TranslatingLineGenerator itemize ['itemize'] -->
<li>
<tt>MPI_MODE_NOSTORE</tt>
 the local window was not updated by local
    stores (or local get or receive calls) since last synchronization.
<li>
<tt>MPI_MODE_NOPUT</tt>
 the local window will not be updated by put or
    accumulate calls after the fence call, until the ensuing (fence)
    synchronization.
<li>
<tt>MPI_MODE_NOPRECEDE</tt>
 the fence does not complete any sequence of
    locally issued RMA calls. If this assertion is given by any
    process in the window group, then it must be given by all
    processes in the group.
<li>
<tt>MPI_MODE_NOSUCCEED</tt>
 the fence does not start any
    sequence of locally issued RMA calls. If the assertion is given by
    any process in the window group, then it must be given by all
    processes in the group.
</ul>
</itemize>
<!-- environment: itemize end embedded generator -->
<li>
<tt>MPI_Win_lock</tt>
 and 
<tt>MPI_Win_lock_all</tt>
  support the following option:
<!-- environment: itemize start embedded generator -->
</p>
<!-- environment block purpose: [[ environment=itemize ]] -->
<itemize>
<ul>
<!-- TranslatingLineGenerator itemize ['itemize'] -->
<li>
<tt>MPI_MODE_NOCHECK</tt>
 no other process holds, or will attempt to
    acquire a conflicting lock, while the caller holds the window
    lock. This is useful when mutual exclusion is achieved by other
    means, but the coherence operations that may be attached to the
    lock and unlock calls are still required.
</ul>
</itemize>
<!-- environment: itemize end embedded generator -->
</ul>
</itemize>
<!-- environment: itemize end embedded generator -->
<p name="switchToTextMode">

<h2><a id="Implementation">9.7</a> Implementation</h2>
<p name=crumbs>
crumb trail:  > <a href="mpi-onesided.html">mpi-onesided</a> > <a href="mpi-onesided.html#Implementation">Implementation</a>
</p>
<!-- index -->
</p>

<p name="switchToTextMode">
You may wonder how one-sided communication is realized\footnote{For
  more on this subject, see&nbsp;
<a href="http://pages.tacc.utexas.edu/~eijkhout/pcse/html/bibliography.html#thakur:ijhpca-sync">[thakur:ijhpca-sync]</a>
.}. Can a processor
somehow get at another processor's data? Unfortunately, no.
</p>

<p name="switchToTextMode">
Active target synchronization is implemented in terms of two-sided communication.
Imagine that the first fence operation does nothing, unless it concludes prior
one-sided operations. The Put and Get calls do nothing involving communication,
except for marking with what processors they exchange data.
The concluding fence is where everything happens: first a global operation
determines which targets need to issue send or receive calls, then the
actual sends and receive are executed.
</p>

<!-- environment: exercise start embedded generator -->
<!-- environment block purpose: [[ environment=exercise ]] -->
<exercise>
<b>Exercise</b>
<p name="exercise">
<!-- TranslatingLineGenerator exercise ['exercise'] -->
  Assume that only Get operations are performed during an epoch.
  Sketch how these are translated to send/receive pairs.
  The problem here is how the senders find out that they need to send.
  Show that you can solve this with an 
<tt>MPI_Reduce_scatter</tt>
 call.
</p name="exercise">
</exercise>
<!-- environment: exercise end embedded generator -->
<p name="switchToTextMode">

The previous paragraph noted that a collective operation was necessary
to determine the two-sided traffic. Since collective operations induce
some amount of synchronization, you may want to limit this.
</p>

<!-- environment: exercise start embedded generator -->
<!-- environment block purpose: [[ environment=exercise ]] -->
<exercise>
<b>Exercise</b>
<p name="exercise">
<!-- TranslatingLineGenerator exercise ['exercise'] -->
  Argue that the mechanism with window post/wait/start/complete operations
  still needs a collective, but that this is less burdensome.
</p name="exercise">
</exercise>
<!-- environment: exercise end embedded generator -->
<!-- environment: answer start embedded generator -->
<!-- environment block purpose: [[ environment=answer ]] -->
<answer>


</answer>
<!-- environment: answer end embedded generator -->
<p name="switchToTextMode">

Passive target synchronization needs another mechanism entirely.  Here
the target process needs to have a background task (process, thread,
daemon,&hellip;) running that listens for requests to lock the
window. This can potentially be expensive.
</p>

<!-- index -->
<!-- index -->
<p name="switchToTextMode">

\newpage
<h2><a id="Reviewquestions">9.8</a> Review questions</h2>
<p name=crumbs>
crumb trail:  > <a href="mpi-onesided.html">mpi-onesided</a> > <a href="mpi-onesided.html#Reviewquestions">Review questions</a>
</p>
</p>

<p name="switchToTextMode">
Find all the errors in this code.
<!-- environment: lstlisting start embedded generator -->
</p>
<!-- environment block purpose: [[ environment=lstlisting ]] -->
<lstlisting>
<pre>
#include &lt;mpi.h&gt;
#include &lt;stdio.h&gt;
#include &lt;stdlib.h&gt;


#define MASTER 0


int main(int argc, char *argv[])
{
  MPI_Init(&argc, &argv);
  MPI_Comm comm = MPI_COMM_WORLD;
  int r, p;
  MPI_Comm_rank(comm, &r);
  MPI_Comm_size(comm, &p);
  printf("Hello from %d\n", r);
  int result[1] = {0};
  //int assert = MPI_MODE_NOCHECK;
  int assert = 0;
  int one = 1;
  MPI_Win win_res;
  MPI_Win_allocate(1 * sizeof(MPI_INT), sizeof(MPI_INT), MPI_INFO_NULL, comm, &result[0], &win_res);
  MPI_Win_lock_all(assert, win_res);
  if (r == MASTER) {
    result[0] = 0;
    do{
      MPI_Fetch_and_op(&result, &result , MPI_INT, r, 0, MPI_NO_OP, win_res);
      printf("result: %d\n", result[0]);
    } while(result[0] != 4);
    printf("Master is done!\n");
  } else {
    MPI_Fetch_and_op(&one, &result, MPI_INT, 0, 0, MPI_SUM, win_res);
  }
  MPI_Win_unlock_all(win_res);
  MPI_Win_free(&win_res);
  MPI_Finalize();
  return 0;
</pre>
</lstlisting>
<!-- environment: lstlisting end embedded generator -->
</div>
<a href="index.html">Back to Table of Contents</a>
