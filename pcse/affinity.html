<html>
<head>
<link href="ihpsc.css" rel="stylesheet" type="text/css">
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/css/bootstrap.min.css" integrity="sha384-Gn5384xqQ1aoWXA+058RXPxPg6fy4IWvTNh0E263XmFcJlSAwiGgFAW/dAiS6JXm" crossorigin="anonymous">

  <script src="https://code.jquery.com/jquery-3.2.1.slim.min.js" integrity="sha384-KJ3o2DKtIkvYIK3UENzmM7KCkRr/rE9/Qpg6aAZGJwFDMVNA/GpGFF93hXpG5KkN" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.12.9/umd/popper.min.js" integrity="sha384-ApNbgh9B+Y1QKtv3Rn7W3mgPxhU9K/ScQsAP7hUibX39j7fakFPskvXusvfa0b4Q" crossorigin="anonymous"></script>
  <script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/js/bootstrap.min.js" integrity="sha384-JZR6Spejh4U02d8jOt6vLEHfe/JQGiRRSQQxSfFWpi1MquVdAyjUar5+76PVCmYl" crossorigin="anonymous"></script>

  <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

  <script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {inlineMath: [['$','$']]}
  });
  MathJax.Hub.Config({
    TeX: { equationNumbers: { autoNumber: "AMS" } }
  });
  </script>

  <link rel="stylesheet"
      href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.13.1/styles/default.min.css">
  <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.13.1/highlight.min.js"></script>
  <script>hljs.initHighlightingOnLoad();</script>
</head>

<script type="application/javascript" src="http://ccrs.cac.cornell.edu:8080//ace/ace.js" charset="utf-8"></script>
<script type="application/javascript" src="http://ccrs.cac.cornell.edu:8080//target/web-client-jsdeps.js"></script>
<!-- include application -->
<script type="application/javascript" src="http://ccrs.cac.cornell.edu:8080//target/web-client-opt.js"></script>

<script type="application/javascript">
  // First we declare some metadata, primarily to describe
  // the container environment.
  var ccrsApiNamespace = "org.xsede.jobrunner.model.ModelApi";
  var mpiExampleMetaJson = {
    // CHANGE: for now, leave the appended string as .SysJobMetaData;
    //         other options will be supported in the future
    "$type": ccrsApiNamespace + ".SysJobMetaData",
    // CHANGE: shell to use implicitly when running commands in the container
    "shell": ["bash"],
    // CHANGE: should currently be one of: .NixOS, .Singularity
    "containerType": {
      "$type":  ccrsApiNamespace + ".NixOS"
    },
    // CHANGE: Specify for NixOS for all jobs, or for Singularity when resuming existing jobs
    "containerId": ["vicOpenMPI"],
    // CHANGE: Specify the singularity image name
    "image": [],
    // Directories on the host to mount in the container, if any:
    "binds": [],
    // Only for singularity:
    "overlay": [],
    // CHANGE: should be filled in dynamically to contain the (student) user,
    //         but this is a demo, so we use a static user name:
    "user": "test0",
    "address": [],
    "hostname": [],
    "url": window.location.href
  };
  var mpiExampleMeta = CCRS.sysJobMetaData(mpiExampleMetaJson);
</script>

<div class="container">
  <div class="row">
    <div class="col-12">
      <div class="pagehead">
        <h1>Process and thread affinity</h1>
        <h5>Experimental html version of downloadable textbook, see http://www.tacc.utexas.edu/~eijkhout/istc/istc.html</h5>
      </div>
    </div>
  </div>
  <div>


\[
\newcommand\inv{^{-1}}\newcommand\invt{^{-t}}
\newcommand\bbP{\mathbb{P}}
\newcommand\bbR{\mathbb{R}}
\newcommand\defined{
  \mathrel{\lower 5pt \hbox{${\equiv\atop\mathrm{\scriptstyle D}}$}}}
\]


44.1 : <a href="affinity.html#Whatdoesthehardwarelooklike?">What does the hardware look like?</a><br>
44.2 : <a href="affinity.html#Affinitycontrol">Affinity control</a><br>
<a href="index.html">Back to Table of Contents</a>
<h1>44 Process and thread affinity</h1>
<!-- TranslatingLineGenerator file ['file'] -->
</p>

<!-- index -->
<p name="switchToTextMode">

In the preceeding chapters we mostly considered all MPI nodes or
OpenMP thread as being in one flat pool.
However, for high performance you need to worry about 
<i>affinity</i>
:
the question of which process or thread is placed where, and how
efficiently they can interact.
</p>

<!-- environment: figure start embedded generator -->
<!-- environment block purpose: [[ environment=figure ]] -->
<figure>
<float mode=figure>
<!-- TranslatingLineGenerator figure ['figure'] -->
<img src="graphics/ranger-numa.jpg" width=800></img>
<p name="caption">
FIGURE 44.1: The NUMA structure of a Ranger node
</p>

</float>
</figure>
<!-- environment: figure end embedded generator -->
<p name="switchToTextMode">

Here are some situations where you affinity becomes a concern.
<!-- environment: itemize start embedded generator -->
</p>
<!-- environment block purpose: [[ environment=itemize ]] -->
<itemize>
<ul>
<!-- TranslatingLineGenerator itemize ['itemize'] -->
<li>
In pure MPI mode processes that are on the same node can
  typically communicate faster than processes on different
  nodes. Since processes are typically placed sequentially, this means
  that a scheme where process~$p$ interacts mostly with $p+1$ will be
  efficient, while communication with large jumps will be less so.
<li>
If the cluster network has a structure
  (
<i>processor grid</i>
 as opposed to 
<i>fat-tree</i>
),
  placement of processes has an effect on program efficiency.  MPI
  tries to address this with 
<i>graph topology</i>
;
  section~
<a href="http://pages.tacc.utexas.edu/~eijkhout/pcse/html/mpi-topo.html#Distributedgraphtopology">11.2</a>
.
<li>
Even on a single node there can be
  asymmetries. Figure~
44.1
 illustrates the structure
  of the four sockets of the 
<i>Ranger</i>
 supercomputer (no
  longer in production). Two cores have no direct connection.
</p>

<p name="switchToTextMode">
  This asymmetry affects both MPI processes and threads on that node.
<li>
Another problem with multi-socket designs is that each socket
  has memory attached to it. While every socket can address all the
  memory on the node, its local memory is faster to access. This
  asymmetry becomes quite visible in the 
<i>first-touch</i>
  phenomemon; section~
<a href="http://pages.tacc.utexas.edu/~eijkhout/pcse/html/omp-affinity.html#First-touch">24.2</a>
.
<li>
If a node has fewer MPI processes than there are cores, you want
  to be in control of their placement. Also, the operating system can
  migrate processes, which is detrimental to performance since it
  negates data locality. For this reason, utilities such as
<tt>numactl</tt>
<!-- environment: tacc start embedded generator -->
</p>
<!-- environment block purpose: [[ environment=tacc ]] -->
<tacc>

<p name="tacc">
<!-- TranslatingLineGenerator tacc ['tacc'] -->
(and at TACC 
<tt>tacc_affinity</tt>
)
</p name="tacc">

</tacc>
<!-- environment: tacc end embedded generator -->
<p name="switchToTextMode">
  can be used to 
<i>pin a thread</i>
 or process to a specific core.
<li>
Processors with 
<i>hyperthreading</i>
 or
<i>hardware threads</i>
 introduce another level or worry
  about where threads go.
</ul>
</itemize>
<!-- environment: itemize end embedded generator -->
<p name="switchToTextMode">

<h2><a id="Whatdoesthehardwarelooklike?">44.1</a> What does the hardware look like?</h2>
<p name=crumbs>
crumb trail:  > <a href="affinity.html">affinity</a> > <a href="affinity.html#Whatdoesthehardwarelooklike?">What does the hardware look like?</a>
</p>
</p>

<p name="switchToTextMode">
If you want to optimize affinity, you should first know what the
hardware looks like. The 
 utility is valuable
here~
<a href="http://pages.tacc.utexas.edu/~eijkhout/pcse/html/bibliography.html#goglin:hwloc">[goglin:hwloc]</a>
 (
<a href=https://www.open-mpi.org/projects/hwloc/>https://www.open-mpi.org/projects/hwloc/</a>
).
</p>

<!-- environment: figure start embedded generator -->
<!-- environment block purpose: [[ environment=figure ]] -->
<figure>
<float mode=figure>
<!-- TranslatingLineGenerator figure ['figure'] -->
<img src="graphics/stampede-compute." width=800></img>
<p name="caption">
FIGURE 44.2: Structure of a Stampede compute node
</p>

</float>
</figure>
<!-- environment: figure end embedded generator -->
<p name="switchToTextMode">

<!-- environment: figure start embedded generator -->
</p>
<!-- environment block purpose: [[ environment=figure ]] -->
<figure>
<float mode=figure>
<!-- TranslatingLineGenerator figure ['figure'] -->
<img src="graphics/stampede-largemem." width=800></img>
<p name="caption">
FIGURE 44.3: Structure of a Stampede largemem four-socket compute node
</p>

</float>
</figure>
<!-- environment: figure end embedded generator -->
<p name="switchToTextMode">

<!-- environment: figure start embedded generator -->
</p>
<!-- environment block purpose: [[ environment=figure ]] -->
<figure>
<float mode=figure>
<!-- TranslatingLineGenerator figure ['figure'] -->
<img src="graphics/ls5." width=800></img>
<p name="caption">
FIGURE 44.4: Structure of a Lonestar5 compute node
</p>

</float>
</figure>
<!-- environment: figure end embedded generator -->
<p name="switchToTextMode">

Figure~
44.2
 depicts a
<i>Stampede compute node</i>
, which is a two-socket
<i>Intel Sandybridge</i>
 design;
figure~
44.3
 shows a
<i>Stampede largemem node</i>
, which is a four-socket design.
Finally, figure~
44.4
 shows a
<i>Lonestar5</i>
 compute node, a~two-socket design with 12-core
<i>Intel Haswell</i>
 processors with two hardware threads
each.
</p>

<h2><a id="Affinitycontrol">44.2</a> Affinity control</h2>
<p name=crumbs>
crumb trail:  > <a href="affinity.html">affinity</a> > <a href="affinity.html#Affinitycontrol">Affinity control</a>
</p>
<p name="switchToTextMode">

See chapter~
<a href="http://pages.tacc.utexas.edu/~eijkhout/pcse/html/omp-affinity.html">OpenMP topic: Affinity</a>
 for OpenMP affinity control.
</p>

<!-- index -->
</div>
<a href="index.html">Back to Table of Contents</a>
