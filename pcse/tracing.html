<html>
<head>
<link href="ihpsc.css" rel="stylesheet" type="text/css">
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/css/bootstrap.min.css" integrity="sha384-Gn5384xqQ1aoWXA+058RXPxPg6fy4IWvTNh0E263XmFcJlSAwiGgFAW/dAiS6JXm" crossorigin="anonymous">

  <script src="https://code.jquery.com/jquery-3.2.1.slim.min.js" integrity="sha384-KJ3o2DKtIkvYIK3UENzmM7KCkRr/rE9/Qpg6aAZGJwFDMVNA/GpGFF93hXpG5KkN" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.12.9/umd/popper.min.js" integrity="sha384-ApNbgh9B+Y1QKtv3Rn7W3mgPxhU9K/ScQsAP7hUibX39j7fakFPskvXusvfa0b4Q" crossorigin="anonymous"></script>
  <script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/js/bootstrap.min.js" integrity="sha384-JZR6Spejh4U02d8jOt6vLEHfe/JQGiRRSQQxSfFWpi1MquVdAyjUar5+76PVCmYl" crossorigin="anonymous"></script>

  <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

  <script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {inlineMath: [['$','$']]}
  });
  MathJax.Hub.Config({
    TeX: { equationNumbers: { autoNumber: "AMS" } }
  });
  </script>

  <link rel="stylesheet"
      href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.13.1/styles/default.min.css">
  <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.13.1/highlight.min.js"></script>
  <script>hljs.initHighlightingOnLoad();</script>
</head>

<script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
<script src="http://ccrs.cac.cornell.edu:8080/client.0.1.js"></script>
<style>
</style>

<script type="application/javascript">
  // First we declare some metadata, primarily to describe
  // the container environment.
  var ccrsApiNamespace = "org.xsede.jobrunner.model.ModelApi";
  var mpiExampleMetaJson = {
    // CHANGE: for now, leave the appended string as .SysJobMetaData;
    //         other options will be supported in the future
    "$type": ccrsApiNamespace + ".SysJobMetaData",
    // CHANGE: shell to use implicitly when running commands in the container
    "shell": ["bash"],
    // CHANGE: should currently be one of: .NixOS, .Singularity
    "containerType": {
      "$type":  ccrsApiNamespace + ".NixOS"
    },
    // CHANGE: Specify for NixOS for all jobs, or for Singularity when resuming existing jobs
    "containerId": ["vicOpenMPI"],
    // CHANGE: Specify the singularity image name
    "image": [],
    // Directories on the host to mount in the container, if any:
    "binds": [],
    // Only for singularity:
    "overlay": [],
    // CHANGE: should be filled in dynamically to contain the (student) user,
    //         but this is a demo, so we use a static user name:
    "user": "test0",
    "address": [],
    "hostname": [],
    "url": window.location.href
  };
  var mpiExampleMeta = CCRS.sysJobMetaData(mpiExampleMetaJson);
</script>

<div class="container">
  <div class="row">
    <div class="col-12">
      <div class="pagehead">
        <h1>Tracing, timing, and profiling</h1>
        <h5>Experimental html version of downloadable textbook, see http://www.tacc.utexas.edu/~eijkhout/istc/istc.html</h5>
      </div>
    </div>
  </div>
  <div>


\[
\newcommand\inv{^{-1}}\newcommand\invt{^{-t}}
\newcommand\bbP{\mathbb{P}}
\newcommand\bbR{\mathbb{R}}
\newcommand\defined{
  \mathrel{\lower 5pt \hbox{${\equiv\atop\mathrm{\scriptstyle D}}$}}}
\]


50.1 : <a href="tracing.html#Timing">Timing</a><br>
50.1.1 : <a href="tracing.html#Paralleltiming">Parallel timing</a><br>
50.2 : <a href="tracing.html#Tau">Tau</a><br>
50.2.1 : <a href="tracing.html#Instrumentation">Instrumentation</a><br>
50.2.2 : <a href="tracing.html#Running">Running</a><br>
50.2.3 : <a href="tracing.html#Output">Output</a><br>
50.2.4 : <a href="tracing.html#Examples">Examples</a><br>
50.2.4.1 : <a href="tracing.html#Bucketbrigade">Bucket brigade</a><br>
50.2.4.2 : <a href="tracing.html#Butterflyexchange">Butterfly exchange</a><br>
<a href="index.html">Back to Table of Contents</a>
<h1>50 Tracing, timing, and profiling</h1>
<!-- TranslatingLineGenerator file ['file'] -->
<p name="switchToTextMode">

<h2><a id="Timing">50.1</a> Timing</h2>
<p name=crumbs>
crumb trail:  > <a href="tracing.html">tracing</a> > <a href="tracing.html#Timing">Timing</a>
</p>
</p>

<p name="switchToTextMode">
Many systems have their own timers:
<!-- environment: itemize start embedded generator -->
</p>
<!-- environment block purpose: [[ environment=itemize ]] -->
<itemize>
<ul>
<!-- TranslatingLineGenerator itemize ['itemize'] -->
<li>
MPI see section~
<a href="http://pages.tacc.utexas.edu/~eijkhout/pcse/html/mpi.html#Timing">15.6.1</a>
;
<li>
OpenMP see section~
<a href="http://pages.tacc.utexas.edu/~eijkhout/pcse/html/openmp.html#Timing">29.2</a>
;
<li>
PETSc see section~
<a href="http://pages.tacc.utexas.edu/~eijkhout/pcse/html/petsc-tools.html#Timingandprofiling">39.4</a>
.
</ul>
</itemize>
<!-- environment: itemize end embedded generator -->
<p name="switchToTextMode">

<h3><a id="Paralleltiming">50.1.1</a> Parallel timing</h3>
<p name=crumbs>
crumb trail:  > <a href="tracing.html">tracing</a> > <a href="tracing.html#Timing">Timing</a> > <a href="tracing.html#Paralleltiming">Parallel timing</a>
</p>
</p>

<p name="switchToTextMode">
Timing parallel operations is fraught with peril,
as processes or threads can interact with each other.
This means that you may be measuring the wait time
induced by synchronization.
Sometimes that is actually what you want,
as in the case of a 
<i>ping-pong</i>
 operation;
section~
<a href="http://pages.tacc.utexas.edu/~eijkhout/pcse/html/mpi-ptp.html#Example:ping-pong">4.1.1</a>
.
</p>

<p name="switchToTextMode">
Other times, this is not what you want.
Consider the code
<!-- environment: lstlisting start embedded generator -->
</p>
<!-- environment block purpose: [[ environment=lstlisting ]] -->
<lstlisting>
<pre>
if (procno==0)
  do_big_setup();
t = timer();
mpi_some_collective();
duration = timer() - t;
</pre>
</lstlisting>
<!-- environment: lstlisting end embedded generator -->
<p name="switchToTextMode">

<!-- environment: figure start embedded generator -->
</p>
<!-- environment block purpose: [[ environment=figure ]] -->
<figure>
<float mode=figure>
<!-- TranslatingLineGenerator figure ['figure'] -->
<p name="switchToTextMode">
  \hbox\bgroup
<img src="graphics/timenobarrier.png" width=800></img>
<img src="graphics/timebarrier.png" width=800></img>
  \egroup
<p name="caption">
FIGURE 50.1: Timing a parallel code without and with barrier
</p>

</float>
</figure>
<!-- environment: figure end embedded generator -->
<p name="switchToTextMode">

Figure&nbsp;
50.1
 illustrates this:
<!-- environment: itemize start embedded generator -->
</p>
<!-- environment block purpose: [[ environment=itemize ]] -->
<itemize>
<ul>
<!-- TranslatingLineGenerator itemize ['itemize'] -->
<li>
in the naive scenario, processes other than zero start the collective immediately,
  but process zero first does the setup;
<li>
all processes presumably finish more or less together.
</ul>
</itemize>
<!-- environment: itemize end embedded generator -->
<p name="switchToTextMode">
On the non-zero processes we now get a time measurement,
which we intended to be just the collective operation,
that includes the setup time of process zero.
</p>

<p name="switchToTextMode">
The solution is to put a barrier around the section that you want to time;
see again figure&nbsp;
50.1
.
</p>

<!-- TranslatingLineGenerator file ['file'] -->
<p name="switchToTextMode">

<h2><a id="Tau">50.2</a> Tau</h2>
<p name=crumbs>
crumb trail:  > <a href="tracing.html">tracing</a> > <a href="tracing.html#Tau">Tau</a>
</p>

</p>

<!-- index -->
<p name="switchToTextMode">

TAU~
<a href=http://www.cs.uoregon.edu/Research/tau/home.php>http://www.cs.uoregon.edu/Research/tau/home.php</a>
 is a utility
for profiling and tracing your parallel programs. Profiling is the
gathering and displaying of bulk statistics, for instance showing you
which routines take the most time, or whether communication takes a
large portion of your runtime. When you get concerned about
performance, a good profiling tool is indispensible.
</p>

<p name="switchToTextMode">
Tracing is the construction and displaying of time-dependent
information on  your program run, for instance showing you if one
process lags behind others. For understanding a program's behaviour,
and the reasons behind profiling statistics, a tracing tool can be
very insightful.
</p>

<h3><a id="Instrumentation">50.2.1</a> Instrumentation</h3>
<p name=crumbs>
crumb trail:  > <a href="tracing.html">tracing</a> > <a href="tracing.html#Tau">Tau</a> > <a href="tracing.html#Instrumentation">Instrumentation</a>
</p>
<p name="switchToTextMode">

Unlike such tools as 
<i>VTune</i>
 which profile your binary as-is,
TAU works by adding 
<i>instrumentation</i>
 to your code: in
effect it is a source-to-source translator that takes your code and
turns it into one that generates run-time statistics.
</p>

<p name="switchToTextMode">
This instrumentation is largely done for you; you mostly need to recompile
your code with a script that does the source-to-source translation,
and subsequently compiles that instrumented code.
You could for instance have the following in your makefile:
<!-- environment: verbatim start embedded generator -->
</p>
<!-- environment block purpose: [[ environment=verbatim ]] -->
<verbatim>
<pre>
ifdef TACC_TAU_DIR
  CC = tau_cc.sh
else
  CC = mpicc
endif


% : %.c
&lt;TAB&gt;${CC} -o $@ $^
</pre>
</verbatim>
<!-- environment: verbatim end embedded generator -->
<p name="switchToTextMode">
If TAU is to be used (which we detect here by checking for the environment variable
<tt>TACC_TAU_DIR</tt>
), we define the 
<tt>CC</tt>
 variable as
one of the TAU compilation scripts; otherwise we set it to a regular MPI compiler.
</p>

<p name="switchToTextMode">
\begin{istc}
To use 
<i>TAU</i>
 on 
<i>TACC</i>

<!-- index -->
 resources,
do 
<tt>module load tau</tt>
.
\end{istc}
</p>

<h3><a id="Running">50.2.2</a> Running</h3>
<p name=crumbs>
crumb trail:  > <a href="tracing.html">tracing</a> > <a href="tracing.html#Tau">Tau</a> > <a href="tracing.html#Running">Running</a>
</p>
<p name="switchToTextMode">

You can now run your instrumented code;
trace/profile output will be written to file
if environment variables 
<tt>TAU_PROFILE</tt>
 and/or 
<tt>TAU_TRACE</tt>
 are set:
<!-- environment: verbatim start embedded generator -->
</p>
<!-- environment block purpose: [[ environment=verbatim ]] -->
<verbatim>
<pre>
export TAU_PROFILE=1
export TAU_TRACE=1
</pre>
</verbatim>
<!-- environment: verbatim end embedded generator -->
<p name="switchToTextMode">

A TAU run can generate many files: typically at least one per process.
It is therefore advisabe to create a directory for your tracing and profiling
information. You declare them to TAU by setting the environment variables
<tt>PROFILEDIR</tt>
 and 
<tt>TRACEDIR</tt>
.
<!-- environment: verbatim start embedded generator -->
</p>
<!-- environment block purpose: [[ environment=verbatim ]] -->
<verbatim>
<pre>
mkdir tau_trace
mkdir tau_profile
export PROFILEDIR=tau_profile
export TRACEDIR=tau_trace
</pre>
</verbatim>
<!-- environment: verbatim end embedded generator -->
<p name="switchToTextMode">

The actual program invocation is then unchanged:
<!-- environment: verbatim start embedded generator -->
</p>
<!-- environment block purpose: [[ environment=verbatim ]] -->
<verbatim>
<pre>
mpirun -np 26 myprogram
</pre>
</verbatim>
<!-- environment: verbatim end embedded generator -->
<p name="switchToTextMode">

<!-- environment: taccnote start embedded generator -->
</p>
<!-- environment block purpose: [[ environment=taccnote ]] -->
<remark>
<b>TACC note</b>
<p name="remark">
<!-- TranslatingLineGenerator taccnote ['taccnote'] -->
At TACC, use 
<tt>ibrun</tt>
 without a processor count;
the count is derived from the queue submission parameters.
</p name="remark">
</remark>
<!-- environment: taccnote end embedded generator -->
<p name="switchToTextMode">

While this example uses two separate directories, there is no
harm in using the same for both.
</p>

<h3><a id="Output">50.2.3</a> Output</h3>
<p name=crumbs>
crumb trail:  > <a href="tracing.html">tracing</a> > <a href="tracing.html#Tau">Tau</a> > <a href="tracing.html#Output">Output</a>
</p>
<p name="switchToTextMode">

The tracing/profiling information is spread over many files, and hard to read as such.
Therefore, you need some further programs to consolidate and display the information.
</p>

<p name="switchToTextMode">
You view profiling information with 
<tt>paraprof</tt>
<!-- environment: verbatim start embedded generator -->
</p>
<!-- environment block purpose: [[ environment=verbatim ]] -->
<verbatim>
<pre>
paraprof tau_profile
</pre>
</verbatim>
<!-- environment: verbatim end embedded generator -->
<p name="switchToTextMode">
Viewing the traces takes a few steps:
<!-- environment: verbatim start embedded generator -->
</p>
<!-- environment block purpose: [[ environment=verbatim ]] -->
<verbatim>
<pre>
cd tau_trace
rm -f tau.trc tau.edf align.trc align.edf
tau_treemerge.pl
tau_timecorrect tau.trc tau.edf align.trc align.edf
tau2slog2 align.trc align.edf -o yourprogram.slog2
</pre>
</verbatim>
<!-- environment: verbatim end embedded generator -->
<p name="switchToTextMode">
If you skip the 
<tt>tau_timecorrect</tt>
 step, you can generate the

<tt>slog2</tt>
 file by:
<!-- environment: verbatim start embedded generator -->
</p>
<!-- environment block purpose: [[ environment=verbatim ]] -->
<verbatim>
<pre>
tau2slog2 tau.trc tau.edf -o yourprogram.slog2
</pre>
</verbatim>
<!-- environment: verbatim end embedded generator -->
<p name="switchToTextMode">

The 
<tt>slog2</tt>
 file can be viewed with 
<tt>jumpshot</tt>
:
<!-- environment: verbatim start embedded generator -->
</p>
<!-- environment block purpose: [[ environment=verbatim ]] -->
<verbatim>
<pre>
jumpshot yourprogram.slog2
</pre>
</verbatim>
<!-- environment: verbatim end embedded generator -->
<p name="switchToTextMode">

<h3><a id="Examples">50.2.4</a> Examples</h3>
<p name=crumbs>
crumb trail:  > <a href="tracing.html">tracing</a> > <a href="tracing.html#Tau">Tau</a> > <a href="tracing.html#Examples">Examples</a>
</p>
</p>

<h4><a id="Bucketbrigade">50.2.4.1</a> Bucket brigade</h4>
<p name=crumbs>
crumb trail:  > <a href="tracing.html">tracing</a> > <a href="tracing.html#Tau">Tau</a> > <a href="tracing.html#Examples">Examples</a> > <a href="tracing.html#Bucketbrigade">Bucket brigade</a>
</p>
<p name="switchToTextMode">

Let's consider a 
<i>bucket brigade</i>
 implementation of a broadcast:
each process sends its data to the next higher rank.
<!-- environment: lstlisting start embedded generator -->
</p>
<!-- environment block purpose: [[ environment=lstlisting ]] -->
<lstlisting>
<pre>
int sendto =
    ( procno&lt;nprocs-1 ? procno+1 : MPI_PROC_NULL )
    ;
int recvfrom =
    ( procno&gt;0 ? procno-1 : MPI_PROC_NULL )
    ;


MPI_Recv( leftdata,1,MPI_DOUBLE,recvfrom,0,comm,MPI_STATUS_IGNORE);
myvalue = leftdata
MPI_Send( myvalue,1,MPI_DOUBLE,sendto,0,comm);
</pre>
</lstlisting>
<!-- environment: lstlisting end embedded generator -->
<p name="switchToTextMode">

We implement the bucket brigade
with blocking sends and receives: each process waits to receive from its
predecessor, before sending to its successor.
<div class="card">
  <div class="card-header" id="headingOne">
    <h5 class="mb-0">
      <button class="btn btn-link" data-toggle="collapse" data-target="#bucketblock" aria-expanded="false" aria-controls="bucketblock">
        C Code: bucketblock
      </button>
    </h5>
  </div>
  <div id="bucketblock" class="collapse">
  <pre>
// bucketblock.c
for (int i=0; i&lt;N; i++)
  myvalue[i] = (procno+1)*(procno+1) + leftdata[i];
MPI_Send( myvalue,N,MPI_DOUBLE,sendto,0,comm);
</pre>
</div>
</div>
<!-- environment: figure start embedded generator -->
</p>
<!-- environment block purpose: [[ environment=figure ]] -->
<figure>
<float mode=figure>
<!-- TranslatingLineGenerator figure ['figure'] -->
<img src="graphics/tau-bucketblock.png" width=800></img>
<p name="caption">
FIGURE 50.2: Trace of a bucket brigade broadcast
</p>

</float>
</figure>
<!-- environment: figure end embedded generator -->
<p name="switchToTextMode">
The TAU trace of this is in figure&nbsp;
50.2
,
using 4&nbsp;nodes of 4&nbsp;ranks each.
We see that the processes within each node are fairly well synchronized,
but there is less synchronization between the nodes.
However, the bucket brigade then imposes its own synchronization on the processes
because each has to wait for its predecessor, no matter if it posted
the receive operation early.
</p>

<p name="switchToTextMode">
Next, we introduce pipelining into this operation:
each send is broken up into parts, and these parts are sent
and received with non-blocking calls.
<div class="card">
  <div class="card-header" id="headingOne">
    <h5 class="mb-0">
      <button class="btn btn-link" data-toggle="collapse" data-target="#bucketpiperecv" aria-expanded="false" aria-controls="bucketpiperecv">
        C Code: bucketpiperecv
      </button>
    </h5>
  </div>
  <div id="bucketpiperecv" class="collapse">
  <pre>
// bucketpipenonblock.c
MPI_Request rrequests[PARTS];
for (int ipart=0; ipart&lt;PARTS; ipart++) {
  MPI_Irecv
    (
     leftdata+partition_starts[ipart],partition_sizes[ipart],
     MPI_DOUBLE,recvfrom,ipart,comm,rrequests+ipart);
}
</pre>
</div>
</div>
<!-- environment: figure start embedded generator -->
</p>
<!-- environment block purpose: [[ environment=figure ]] -->
<figure>
<float mode=figure>
<!-- TranslatingLineGenerator figure ['figure'] -->
<img src="graphics/tau-bucketpipe.png" width=800></img>
<p name="caption">
FIGURE 50.3: Trace of a pipelined bucket brigade broadcast
</p>

</float>
</figure>
<!-- environment: figure end embedded generator -->
<p name="switchToTextMode">
The TAU trace is in figure&nbsp;
50.3
.
</p>

<h4><a id="Butterflyexchange">50.2.4.2</a> Butterfly exchange</h4>
<p name=crumbs>
crumb trail:  > <a href="tracing.html">tracing</a> > <a href="tracing.html#Tau">Tau</a> > <a href="tracing.html#Examples">Examples</a> > <a href="tracing.html#Butterflyexchange">Butterfly exchange</a>
</p>
<p name="switchToTextMode">

<!-- environment: figure start embedded generator -->
</p>
<!-- environment block purpose: [[ environment=figure ]] -->
<figure>
<float mode=figure>
<!-- TranslatingLineGenerator figure ['figure'] -->
<img src="graphics/butterfly8-legend.png" width=800></img>
<p name="caption">
FIGURE 50.4: Trace of a butterfly exchange
</p>

</float>
</figure>
<!-- environment: figure end embedded generator -->
<p name="switchToTextMode">

<!-- environment: figure start embedded generator -->
</p>
<!-- environment block purpose: [[ environment=figure ]] -->
<figure>
<float mode=figure>
<!-- TranslatingLineGenerator figure ['figure'] -->
<img src="graphics/butterfly8-gaps.png" width=800></img>
<p name="caption">
FIGURE 50.5: Trace of a butterfly exchange
</p>

</float>
</figure>
<!-- environment: figure end embedded generator -->
<p name="switchToTextMode">

The NAS Parallel Benchmark suite&nbsp;
<a href="http://pages.tacc.utexas.edu/~eijkhout/pcse/html/bibliography.html#nas-website">[nas-website]</a>
contains a 
<span title="acronym" ><i>CG</i></span>
 implementation
that spells out its all-reduce operations as a
<i>butterfly exchange</i>
.
</p>

<div class="card">
  <div class="card-header" id="headingOne">
    <h5 class="mb-0">
      <button class="btn btn-link" data-toggle="collapse" data-target="#nascgbutterfly" aria-expanded="false" aria-controls="nascgbutterfly">
        Fortran Code: nascgbutterfly
      </button>
    </h5>
  </div>
  <div id="nascgbutterfly" class="collapse">
  <pre>
!! cgb.f
         do i = 1, l2npcols
            call mpi_irecv( d,
     &gt;                      1,
     &gt;                      dp_type,
     &gt;                      reduce_exch_proc(i),
     &gt;                      i,
     &gt;                      mpi_comm_world,
     &gt;                      request,
     &gt;                      ierr )
            call mpi_send(  sum,
     &gt;                      1,
     &gt;                      dp_type,
     &gt;                      reduce_exch_proc(i),
     &gt;                      i,
     &gt;                      mpi_comm_world,
     &gt;                      ierr )

            call mpi_wait( request, status, ierr )

            sum = sum + d
         enddo
</pre>
</div>
</div>
<p name="switchToTextMode">

<!-- environment: figure start embedded generator -->
</p>
<!-- environment block purpose: [[ environment=figure ]] -->
<figure>
<float mode=figure>
<!-- TranslatingLineGenerator figure ['figure'] -->
<img src="graphics/cgdelay0.jpg" width=800></img>
<p name="switchToTextMode">
  \vskip\baselineskip
<img src="graphics/cgdelay1.jpg" width=800></img>
  \vskip\baselineskip
<img src="graphics/cgdelay2.jpg" width=800></img>
<p name="caption">
FIGURE 50.6: Four stages of processes waiting caused by a single lagging process
</p>

</float>
</figure>
<!-- environment: figure end embedded generator -->
<p name="switchToTextMode">

<!-- environment: figure start embedded generator -->
</p>
<!-- environment block purpose: [[ environment=figure ]] -->
<figure>
<float mode=figure>
<!-- TranslatingLineGenerator figure ['figure'] -->
<img src="graphics/cgdelay3.jpg" width=800></img>
<p name="switchToTextMode">
  \vskip\baselineskip
<img src="graphics/cgdelay4.jpg" width=800></img>
<p name="caption">
FIGURE 50.7: Four stages of processes waiting caused by a single lagging process
</p>

</float>
</figure>
<!-- environment: figure end embedded generator -->
<p name="switchToTextMode">

We recognize this structure in the TAU trace: figure&nbsp;
50.4
.
Upon closer examination, we see how this particular algorithm
induces a lot of wait time.
Figures 
50.6
 and 
50.7
 show a whole cascade of processes
waiting for each other.
50.5
.
</p>

<!-- index -->
</div>
<a href="index.html">Back to Table of Contents</a>
